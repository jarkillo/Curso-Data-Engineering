# ğŸ“š Tema 2: Airflow Intermedio - TeorÃ­a

**MÃ³dulo 6: Apache Airflow y OrquestaciÃ³n**
**Nivel:** Intermedio
**DuraciÃ³n estimada:** 6-8 horas
**Prerequisitos:** Tema 1 completado

---

## ğŸ“– Ãndice

1. [IntroducciÃ³n al Tema 2](#1-introducciÃ³n-al-tema-2)
2. [TaskGroups: OrganizaciÃ³n Visual de DAGs](#2-taskgroups-organizaciÃ³n-visual-de-dags)
3. [SubDAGs: Contexto HistÃ³rico](#3-subdags-contexto-histÃ³rico)
4. [XComs: ComunicaciÃ³n entre Tasks](#4-xcoms-comunicaciÃ³n-entre-tasks)
5. [Branching: Condicionales en DAGs](#5-branching-condicionales-en-dags)
6. [Sensors: Esperar por Condiciones](#6-sensors-esperar-por-condiciones)
7. [Dynamic DAG Generation](#7-dynamic-dag-generation)
8. [Templating con Jinja2](#8-templating-con-jinja2)
9. [Mejores PrÃ¡cticas del Tema 2](#9-mejores-prÃ¡cticas-del-tema-2)
10. [Resumen y PrÃ³ximos Pasos](#10-resumen-y-prÃ³ximos-pasos)

---

## 1. IntroducciÃ³n al Tema 2

### ğŸ“Œ Â¿QuÃ© aprendiste en el Tema 1?

En el Tema 1 aprendiste los **conceptos fundamentales** de Apache Airflow:

- âœ… **DAGs:** Flujos de trabajo dirigidos y acÃ­clicos
- âœ… **Tasks:** Unidades individuales de trabajo
- âœ… **Operators:** PythonOperator, BashOperator, DummyOperator
- âœ… **Dependencias:** Usar `>>` para definir el orden de ejecuciÃ³n
- âœ… **Scheduling:** Ejecutar DAGs periÃ³dicamente con cron
- âœ… **Webserver UI:** Monitorear y ejecutar DAGs visualmente

Estos conceptos te permiten crear **pipelines simples** que extraen, transforman y cargan datos.

---

### ğŸš€ Â¿Por quÃ© necesitamos conceptos intermedios?

A medida que tus pipelines **crecen en complejidad**, te encontrarÃ¡s con nuevos desafÃ­os:

**Problema 1: DAGs Ilegibles**
```
inicio â†’ tarea1 â†’ tarea2 â†’ tarea3 â†’ tarea4 â†’ tarea5 â†’ tarea6 â†’ tarea7 â†’ fin
```
Cuando tienes **20+ tasks**, el DAG se vuelve **imposible de leer** en el Graph View de Airflow.

**Problema 2: Tasks Aisladas**
```python
# Task 1 calcula total_ventas
def calcular_ventas():
    return 50000  # Â¿CÃ³mo paso este valor a otra task?

# Task 2 necesita el total_ventas de Task 1
def generar_reporte():
    total = ???  # Â¿CÃ³mo lo obtengo?
```
Las tasks estÃ¡n **aisladas**, no pueden compartir datos fÃ¡cilmente.

**Problema 3: Falta de Condicionales**
```python
# Â¿CÃ³mo hago if-else en un DAG?
if ventas > 10000:
    procesar_premium()
else:
    procesar_normal()
```
Los DAGs bÃ¡sicos no tienen **flujo condicional** (if-else).

**Problema 4: Esperas Activas**
```python
# Â¿CÃ³mo espero hasta que llegue un archivo?
while not archivo_existe("datos.csv"):
    time.sleep(60)  # âŒ Bloquea el worker
```
Necesitas **esperar por condiciones** sin bloquear recursos.

---

### ğŸ¯ Â¿QuÃ© aprenderÃ¡s en este tema?

En este tema aprenderÃ¡s **conceptos intermedios** que resuelven estos problemas:

| Concepto         | Problema que Resuelve                  |
| ---------------- | -------------------------------------- |
| **TaskGroups**   | DAGs con 20+ tasks ilegibles           |
| **XComs**        | Tasks que necesitan compartir datos    |
| **Branching**    | Flujos condicionales (if-else)         |
| **Sensors**      | Esperar por archivos, APIs, horarios   |
| **Dynamic DAGs** | Crear tasks automÃ¡ticamente en bucles  |
| **Templating**   | Variables dinÃ¡micas en configuraciones |

Al finalizar, podrÃ¡s construir **pipelines complejos, legibles y mantenibles** que manejan flujos condicionales, esperan por recursos externos y procesan datos de forma dinÃ¡mica.

---

## 2. TaskGroups: OrganizaciÃ³n Visual de DAGs

### ğŸ¯ El Problema: DAGs Ilegibles

Imagina que tienes un pipeline ETL con estas tasks:

```python
inicio >> extraer_ventas >> validar_ventas >> transformar_ventas >> calcular_metricas_ventas >>
extraer_clientes >> validar_clientes >> transformar_clientes >> calcular_metricas_clientes >>
combinar_datos >> generar_reporte >> enviar_email >> fin
```

En el **Graph View** de Airflow, verÃ­as **12 tasks en una sola lÃ­nea horizontal**. Es difÃ­cil entender:
- Â¿QuÃ© tasks estÃ¡n relacionadas?
- Â¿DÃ³nde empieza y termina el procesamiento de ventas?
- Â¿QuÃ© hace cada secciÃ³n del pipeline?

---

### ğŸ’¡ La SoluciÃ³n: TaskGroups

Los **TaskGroups** te permiten **agrupar tasks relacionadas** en un contenedor visual.

**AnalogÃ­a:** Es como organizar archivos en carpetas

Imagina que tienes estos archivos en tu escritorio:
```
factura_enero.pdf
factura_febrero.pdf
factura_marzo.pdf
foto_vacaciones.jpg
foto_cumpleaÃ±os.jpg
```

Los organizarÃ­as en carpetas:
```
ğŸ“ Facturas/
  - factura_enero.pdf
  - factura_febrero.pdf
  - factura_marzo.pdf
ğŸ“ Fotos/
  - foto_vacaciones.jpg
  - foto_cumpleaÃ±os.jpg
```

Los **TaskGroups** hacen lo mismo con tasks de Airflow.

---

### ğŸ“ Sintaxis de TaskGroups

```python
from airflow.utils.task_group import TaskGroup
from airflow.operators.python import PythonOperator
from datetime import datetime
from airflow import DAG

with DAG("dag_con_taskgroups", start_date=datetime(2025, 1, 1), schedule=None) as dag:

    inicio = DummyOperator(task_id="inicio")

    # TaskGroup para procesar ventas
    with TaskGroup("procesar_ventas") as grupo_ventas:
        extraer = PythonOperator(task_id="extraer", python_callable=lambda: print("Extrayendo ventas"))
        validar = PythonOperator(task_id="validar", python_callable=lambda: print("Validando ventas"))
        transformar = PythonOperator(task_id="transformar", python_callable=lambda: print("Transformando ventas"))

        extraer >> validar >> transformar

    # TaskGroup para procesar clientes
    with TaskGroup("procesar_clientes") as grupo_clientes:
        extraer = PythonOperator(task_id="extraer", python_callable=lambda: print("Extrayendo clientes"))
        validar = PythonOperator(task_id="validar", python_callable=lambda: print("Validando clientes"))
        transformar = PythonOperator(task_id="transformar", python_callable=lambda: print("Transformando clientes"))

        extraer >> validar >> transformar

    fin = DummyOperator(task_id="fin")

    # Dependencias entre grupos
    inicio >> [grupo_ventas, grupo_clientes] >> fin
```

---

### ğŸ” CÃ³mo se ve en Airflow UI

**Sin TaskGroups:**
```
inicio â†’ extraer_ventas â†’ validar_ventas â†’ transformar_ventas â†’ extraer_clientes â†’ validar_clientes â†’ transformar_clientes â†’ fin
```
(12 tasks visibles, difÃ­cil de leer)

**Con TaskGroups:**
```
inicio â†’ [ğŸ“ procesar_ventas] â†’ fin
         [ğŸ“ procesar_clientes]
```
(2 grupos + 2 tasks, mucho mÃ¡s legible)

Cuando haces clic en `ğŸ“ procesar_ventas`, se **expande** y muestra:
```
procesar_ventas.extraer â†’ procesar_ventas.validar â†’ procesar_ventas.transformar
```

---

### âœ… Ventajas de TaskGroups

| Ventaja          | DescripciÃ³n                                                                         |
| ---------------- | ----------------------------------------------------------------------------------- |
| **Legibilidad**  | DAGs mÃ¡s fÃ¡ciles de entender visualmente                                            |
| **OrganizaciÃ³n** | Agrupar tasks por funcionalidad (ETL, notificaciones, validaciones)                 |
| **Reusabilidad** | Puedes definir TaskGroups como funciones y reutilizarlos                            |
| **Namespace**    | Tasks dentro del grupo tienen prefijo `grupo.task_id` (evita colisiones de nombres) |

---

### ğŸ“¦ TaskGroups Anidados

Puedes crear **TaskGroups dentro de TaskGroups** (como carpetas dentro de carpetas):

```python
with TaskGroup("etl") as grupo_etl:

    with TaskGroup("extraccion") as grupo_extraccion:
        extraer_ventas = PythonOperator(...)
        extraer_clientes = PythonOperator(...)

    with TaskGroup("transformacion") as grupo_transformacion:
        transformar_ventas = PythonOperator(...)
        transformar_clientes = PythonOperator(...)

    with TaskGroup("carga") as grupo_carga:
        cargar_bd = PythonOperator(...)
        cargar_s3 = PythonOperator(...)

    grupo_extraccion >> grupo_transformacion >> grupo_carga
```

**Estructura visual:**
```
ğŸ“ etl/
  â”œâ”€â”€ ğŸ“ extraccion/
  â”‚   â”œâ”€â”€ extraer_ventas
  â”‚   â””â”€â”€ extraer_clientes
  â”œâ”€â”€ ğŸ“ transformacion/
  â”‚   â”œâ”€â”€ transformar_ventas
  â”‚   â””â”€â”€ transformar_clientes
  â””â”€â”€ ğŸ“ carga/
      â”œâ”€â”€ cargar_bd
      â””â”€â”€ cargar_s3
```

---

### ğŸ¨ Casos de Uso Reales

**1. ETL Multi-Fuente**
```python
with TaskGroup("etl_fuente1") as etl_1:
    # Extraer, transformar, validar fuente 1

with TaskGroup("etl_fuente2") as etl_2:
    # Extraer, transformar, validar fuente 2

with TaskGroup("consolidar") as consolidar:
    # Combinar ambas fuentes
```

**2. Notificaciones**
```python
with TaskGroup("notificaciones") as notif:
    enviar_email = EmailOperator(...)
    enviar_slack = SlackOperator(...)
    actualizar_dashboard = PythonOperator(...)
```

**3. Validaciones**
```python
with TaskGroup("validaciones") as validar:
    validar_schema = PythonOperator(...)
    validar_duplicados = PythonOperator(...)
    validar_nulos = PythonOperator(...)
```

---

## 3. SubDAGs: Contexto HistÃ³rico

### ğŸ“œ Â¿QuÃ© eran los SubDAGs?

Antes de Airflow 2.0, existÃ­an los **SubDAGs** para agrupar tasks. Funcionaban como **DAGs dentro de DAGs**.

```python
from airflow.operators.subdag import SubDagOperator

def crear_subdag(dag_parent, subdag_name, default_args):
    subdag = DAG(
        f"{dag_parent}.{subdag_name}",
        default_args=default_args,
        schedule_interval=None
    )
    # Agregar tasks al subdag...
    return subdag

# Uso en el DAG principal
subdag_task = SubDagOperator(
    task_id="mi_subdag",
    subdag=crear_subdag("dag_principal", "mi_subdag", default_args),
    dag=dag
)
```

---

### âŒ Â¿Por quÃ© se deprecaron?

Los SubDAGs tenÃ­an **problemas graves**:

**Problema 1: Deadlocks del Scheduler**
- Los SubDAGs corrÃ­an en el mismo worker que el DAG padre
- Si el worker estaba lleno, el SubDAG no podÃ­a ejecutarse
- Esto causaba **bloqueos** (deadlocks)

**Problema 2: Complejidad Innecesaria**
- RequerÃ­an crear un DAG completo separado
- DifÃ­ciles de debuggear
- Logs separados del DAG principal

**Problema 3: Performance**
- El scheduler tenÃ­a que parsear mÃºltiples DAGs
- Aumentaba el tiempo de procesamiento

---

### âœ… Alternativa Moderna: TaskGroups

**TaskGroups** reemplazan completamente a SubDAGs y resuelven todos sus problemas:

| Aspecto         | SubDAGs (deprecado)           | TaskGroups (actual)    |
| --------------- | ----------------------------- | ---------------------- |
| **Performance** | Lento (parsea mÃºltiples DAGs) | RÃ¡pido (un solo DAG)   |
| **Deadlocks**   | SÃ­ (worker pool compartido)   | No (tasks regulares)   |
| **Logs**        | Separados                     | Integrados             |
| **Complejidad** | Alta (DAG completo)           | Baja (context manager) |
| **UI**          | Confusa                       | Clara y colapsable     |

---

### ğŸ”„ Migrar de SubDAGs a TaskGroups

**Antes (SubDAG):**
```python
def crear_subdag(dag_parent, subdag_name, default_args):
    subdag = DAG(f"{dag_parent}.{subdag_name}", default_args=default_args)
    task1 = PythonOperator(task_id="task1", python_callable=func1, dag=subdag)
    task2 = PythonOperator(task_id="task2", python_callable=func2, dag=subdag)
    task1 >> task2
    return subdag

subdag_operator = SubDagOperator(task_id="subdag", subdag=crear_subdag(...))
```

**DespuÃ©s (TaskGroup):**
```python
with TaskGroup("grupo") as grupo:
    task1 = PythonOperator(task_id="task1", python_callable=func1)
    task2 = PythonOperator(task_id="task2", python_callable=func2)
    task1 >> task2
```

**Â¡Mucho mÃ¡s simple!** âœ¨

---

### ğŸ“ Â¿CuÃ¡ndo encontrarÃ¡s SubDAGs?

Si trabajas con **cÃ³digo legacy** (cÃ³digo viejo) de Airflow 1.x, podrÃ­as encontrar SubDAGs. En ese caso:

1. **Identificar:** Busca `SubDagOperator` en el cÃ³digo
2. **Entender:** Lee quÃ© hace el SubDAG
3. **Migrar:** Reescribir como TaskGroup
4. **Testear:** Verificar que funciona igual
5. **Eliminar:** Borrar el cÃ³digo viejo

**Regla de oro:** En cÃ³digo nuevo, **siempre usa TaskGroups**, nunca SubDAGs.

---

## 4. XComs: ComunicaciÃ³n entre Tasks

### ğŸ¯ El Problema: Tasks Aisladas

Por defecto, las tasks en Airflow estÃ¡n **completamente aisladas**. Cada task se ejecuta en su propio proceso (o incluso en diferentes mÃ¡quinas en producciÃ³n).

```python
def calcular_total_ventas():
    total = 50000
    print(f"Total de ventas: {total}")
    return total  # Â¿CÃ³mo accede la siguiente task a este valor?

def generar_reporte():
    total = ???  # âŒ No tengo acceso al resultado de la task anterior
    print(f"Reporte generado con total: {total}")

task1 = PythonOperator(task_id="calcular", python_callable=calcular_total_ventas)
task2 = PythonOperator(task_id="reportar", python_callable=generar_reporte)

task1 >> task2
```

---

### ğŸ’¡ La SoluciÃ³n: XComs (Cross-Communication)

**XComs** (Cross-Communications) es un mecanismo de Airflow para que las tasks **compartan pequeÃ±as cantidades de datos**.

**AnalogÃ­a:** XComs son como Post-It notes en una oficina

Imagina que trabajas en una oficina:
- **Task 1 (Ana):** Calcula el total de ventas y escribe "50,000â‚¬" en un Post-It
- **Post-It:** Ana pega el Post-It en una pizarra compartida con la etiqueta "total_ventas"
- **Task 2 (Carlos):** Lee el Post-It de la pizarra y usa ese valor para generar un reporte

XComs funciona igual: una task "pega" un dato, otra task "lee" ese dato.

---

### ğŸ“ API de XComs

**MÃ©todo 1: Return AutomÃ¡tico**

Si una funciÃ³n **retorna un valor**, Airflow automÃ¡ticamente lo guarda en XCom con la key `return_value`:

```python
def calcular_total_ventas():
    total = 50000
    return total  # âœ… Airflow guarda esto en XCom automÃ¡ticamente

task1 = PythonOperator(task_id="calcular", python_callable=calcular_total_ventas)
```

**MÃ©todo 2: xcom_push (Manual)**

Puedes guardar **mÃºltiples valores** con keys especÃ­ficas:

```python
def calcular_metricas(**context):
    ti = context["ti"]  # TaskInstance

    total = 50000
    promedio = 1250
    num_ventas = 40

    ti.xcom_push(key="total", value=total)
    ti.xcom_push(key="promedio", value=promedio)
    ti.xcom_push(key="num_ventas", value=num_ventas)

task1 = PythonOperator(task_id="calcular", python_callable=calcular_metricas)
```

---

**MÃ©todo 3: xcom_pull (Leer)**

Para **leer** un XCom de otra task:

```python
def generar_reporte(**context):
    ti = context["ti"]

    # Leer el return_value de la task "calcular"
    total = ti.xcom_pull(task_ids="calcular", key="return_value")

    # O leer keys especÃ­ficas
    promedio = ti.xcom_pull(task_ids="calcular", key="promedio")
    num_ventas = ti.xcom_pull(task_ids="calcular", key="num_ventas")

    print(f"Reporte: Total={total}, Promedio={promedio}, Cantidad={num_ventas}")

task2 = PythonOperator(task_id="reportar", python_callable=generar_reporte)
```

---

### ğŸ” Ejemplo Completo

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime

def calcular_ventas(**context):
    """Simula cÃ¡lculo de ventas y retorna el total"""
    import random
    total = random.randint(10000, 100000)
    print(f"[CALCULAR] Total de ventas: {total}")
    return total  # Se guarda en XCom con key "return_value"

def verificar_umbral(**context):
    """Lee el total de XCom y decide si supera el umbral"""
    ti = context["ti"]
    total = ti.xcom_pull(task_ids="calcular_ventas", key="return_value")

    umbral = 50000
    if total > umbral:
        print(f"[VERIFICAR] âœ… Total {total} supera umbral {umbral}")
    else:
        print(f"[VERIFICAR] âŒ Total {total} NO supera umbral {umbral}")

    # Guardar resultado de la verificaciÃ³n
    ti.xcom_push(key="supera_umbral", value=total > umbral)

def enviar_notificacion(**context):
    """Lee el resultado de verificaciÃ³n y envÃ­a notificaciÃ³n"""
    ti = context["ti"]
    total = ti.xcom_pull(task_ids="calcular_ventas", key="return_value")
    supera = ti.xcom_pull(task_ids="verificar_umbral", key="supera_umbral")

    if supera:
        print(f"[NOTIFICAR] ğŸ“§ Enviando alerta: Ventas de {total} superaron el umbral!")
    else:
        print(f"[NOTIFICAR] ğŸ“ Log normal: Ventas de {total}")

with DAG("ejemplo_xcoms", start_date=datetime(2025, 1, 1), schedule=None) as dag:

    task_calcular = PythonOperator(
        task_id="calcular_ventas",
        python_callable=calcular_ventas
    )

    task_verificar = PythonOperator(
        task_id="verificar_umbral",
        python_callable=verificar_umbral
    )

    task_notificar = PythonOperator(
        task_id="enviar_notificacion",
        python_callable=enviar_notificacion
    )

    task_calcular >> task_verificar >> task_notificar
```

---

### âš ï¸ Limitaciones de XComs

**LimitaciÃ³n 1: TamaÃ±o MÃ¡ximo**

XComs estÃ¡n pensados para **datos pequeÃ±os** (metadatos, IDs, contadores).

| Executor           | TamaÃ±o MÃ¡ximo (aprox)             |
| ------------------ | --------------------------------- |
| LocalExecutor      | 48 KB                             |
| CeleryExecutor     | 64 KB (depende de Redis/RabbitMQ) |
| KubernetesExecutor | Variable (depende del backend)    |

**âŒ NO uses XComs para:**
- DataFrames completos (usa archivos temporales o una base de datos)
- ImÃ¡genes o archivos binarios grandes
- Listas con miles de elementos

**âœ… SÃ usa XComs para:**
- IDs de registros procesados
- Contadores (nÃºmero de filas, errores, Ã©xitos)
- Paths a archivos
- Flags booleanos (True/False)
- Configuraciones pequeÃ±as

---

**LimitaciÃ³n 2: SerializaciÃ³n**

XComs solo pueden guardar datos **serializables en JSON**:

**âœ… Funciona:**
```python
ti.xcom_push(key="data", value={"total": 50000, "ventas": 40})  # Diccionario
ti.xcom_push(key="lista", value=[1, 2, 3, 4, 5])  # Lista
ti.xcom_push(key="numero", value=42)  # NÃºmero
ti.xcom_push(key="texto", value="Hola")  # String
ti.xcom_push(key="booleano", value=True)  # Boolean
```

**âŒ NO funciona:**
```python
import pandas as pd
df = pd.DataFrame({"col": [1, 2, 3]})
ti.xcom_push(key="df", value=df)  # âŒ Error: DataFrame no es serializable
```

---

**LimitaciÃ³n 3: Performance**

Cada `xcom_pull` hace una **consulta a la base de datos** de Airflow. Si haces muchas lecturas, puede ser lento.

**âŒ Malo (muchas consultas):**
```python
for i in range(100):
    valor = ti.xcom_pull(task_ids=f"task_{i}", key="resultado")
```

**âœ… Bueno (una consulta):**
```python
# Leer mÃºltiples task_ids a la vez
valores = ti.xcom_pull(task_ids=["task_1", "task_2", "task_3"], key="resultado")
```

---

### ğŸ”„ Alternativas para Datos Grandes

Si necesitas compartir **datos grandes** entre tasks:

**Alternativa 1: Archivos Temporales**
```python
import pandas as pd
from pathlib import Path

def task_1():
    df = pd.DataFrame({"col": range(10000)})
    ruta = "/tmp/datos.csv"
    df.to_csv(ruta, index=False)
    return ruta  # Compartir solo la ruta (pequeÃ±o)

def task_2(**context):
    ti = context["ti"]
    ruta = ti.xcom_pull(task_ids="task_1")
    df = pd.read_csv(ruta)  # Leer desde el archivo
    print(f"DataFrame con {len(df)} filas")
```

**Alternativa 2: Base de Datos Intermedia**
```python
def task_1():
    df = pd.DataFrame(...)
    # Guardar en PostgreSQL o similar
    df.to_sql("tabla_temp", con=engine)
    return "tabla_temp"  # Compartir solo el nombre

def task_2(**context):
    ti = context["ti"]
    tabla = ti.xcom_pull(task_ids="task_1")
    df = pd.read_sql(f"SELECT * FROM {tabla}", con=engine)
```

**Alternativa 3: S3/GCS**
```python
def task_1():
    df = pd.DataFrame(...)
    ruta_s3 = "s3://mi-bucket/temp/datos.parquet"
    df.to_parquet(ruta_s3)
    return ruta_s3  # Compartir solo la ruta
```

---

### âœ… Mejores PrÃ¡cticas con XComs

1. **Usa return para casos simples:** Si solo necesitas pasar un valor, usa `return`
2. **Usa keys descriptivas:** En lugar de "dato1", "dato2", usa "total_ventas", "num_errores"
3. **Documenta quÃ© se comparte:** Comenta quÃ© XComs produce cada task
4. **Validar antes de pull:** Verifica que el XCom existe y es del tipo esperado
5. **No abuses:** Si necesitas compartir muchos datos, usa alternativas (archivos, BD)

---

## 5. Branching: Condicionales en DAGs

### ğŸ¯ El Problema: Falta de Flujo Condicional

Los DAGs que has visto hasta ahora son **lineales** o **paralelos**, pero **no tienen condicionales**:

```python
# Lineal
A >> B >> C >> D

# Paralelo
A >> [B, C, D] >> E
```

Â¿QuÃ© pasa si quieres ejecutar **diferentes tasks segÃºn una condiciÃ³n**?

**Ejemplo del mundo real:**

```
Si ventas_totales > 10,000â‚¬:
    â†’ Enviar alerta al gerente
    â†’ Procesar con prioridad alta
Sino:
    â†’ Guardar en log normal
    â†’ Procesar con prioridad baja
```

---

### ğŸ’¡ La SoluciÃ³n: BranchPythonOperator

El **BranchPythonOperator** te permite crear **flujos condicionales** (if-else) en tus DAGs.

**AnalogÃ­a:** Es como un semÃ¡foro en una carretera

Imagina una carretera que se divide en dos:
- Si el semÃ¡foro estÃ¡ en verde a la izquierda â†’ tomas el camino izquierdo
- Si el semÃ¡foro estÃ¡ en verde a la derecha â†’ tomas el camino derecho

El **BranchPythonOperator** es ese semÃ¡foro: decide quÃ© camino tomar segÃºn una condiciÃ³n.

---

### ğŸ“ Sintaxis de BranchPythonOperator

```python
from airflow.operators.python import BranchPythonOperator

def decidir_camino(**context):
    """FunciÃ³n que decide quÃ© task ejecutar a continuaciÃ³n"""
    ti = context["ti"]
    ventas = ti.xcom_pull(task_ids="calcular_ventas")

    if ventas > 10000:
        return "procesar_premium"  # Task ID a ejecutar
    else:
        return "procesar_normal"  # Task ID a ejecutar

branch_task = BranchPythonOperator(
    task_id="decidir",
    python_callable=decidir_camino
)
```

**Reglas importantes:**
1. La funciÃ³n **debe retornar un task_id** (string) o una lista de task_ids
2. Solo las tasks retornadas se ejecutarÃ¡n
3. Las demÃ¡s tasks se **saltarÃ¡n** (estado: "skipped")

---

### ğŸ” Ejemplo Completo

```python
from airflow import DAG
from airflow.operators.python import PythonOperator, BranchPythonOperator
from airflow.operators.dummy import DummyOperator
from datetime import datetime

def calcular_ventas():
    """Simula cÃ¡lculo de ventas"""
    import random
    return random.randint(5000, 15000)

def decidir_procesamiento(**context):
    """Decide si procesar como premium o normal"""
    ti = context["ti"]
    ventas = ti.xcom_pull(task_ids="calcular_ventas")

    print(f"[BRANCH] Ventas: {ventas}")

    if ventas > 10000:
        print("[BRANCH] â†’ Ruta PREMIUM")
        return "procesar_premium"
    else:
        print("[BRANCH] â†’ Ruta NORMAL")
        return "procesar_normal"

def procesar_premium(**context):
    ti = context["ti"]
    ventas = ti.xcom_pull(task_ids="calcular_ventas")
    print(f"[PREMIUM] â­ Procesando {ventas}â‚¬ con prioridad ALTA")

def procesar_normal(**context):
    ti = context["ti"]
    ventas = ti.xcom_pull(task_ids="calcular_ventas")
    print(f"[NORMAL] ğŸ“‹ Procesando {ventas}â‚¬ con prioridad BAJA")

with DAG("ejemplo_branching", start_date=datetime(2025, 1, 1), schedule=None) as dag:

    inicio = DummyOperator(task_id="inicio")

    calcular = PythonOperator(
        task_id="calcular_ventas",
        python_callable=calcular_ventas
    )

    branch = BranchPythonOperator(
        task_id="decidir_procesamiento",
        python_callable=decidir_procesamiento
    )

    premium = PythonOperator(
        task_id="procesar_premium",
        python_callable=procesar_premium
    )

    normal = PythonOperator(
        task_id="procesar_normal",
        python_callable=procesar_normal
    )

    fin = DummyOperator(
        task_id="fin",
        trigger_rule="none_failed_min_one_success"  # â† Importante!
    )

    inicio >> calcular >> branch >> [premium, normal] >> fin
```

---

### ğŸ” Flujo Visual

```
inicio â†’ calcular_ventas â†’ decidir_procesamiento
                                    â”œâ”€â”€â†’ (ventas > 10000) procesar_premium â†’ fin
                                    â””â”€â”€â†’ (ventas â‰¤ 10000) procesar_normal â†’ fin
```

**Â¿QuÃ© pasa en ejecuciÃ³n?**

Si ventas = 12,000:
- âœ… inicio: success
- âœ… calcular_ventas: success (retorna 12,000)
- âœ… decidir_procesamiento: success (retorna "procesar_premium")
- âœ… procesar_premium: success
- â­ï¸ procesar_normal: **skipped** (no se ejecutÃ³)
- âœ… fin: success

---

### âš™ï¸ Trigger Rules: Manejar Tasks Saltadas

Por defecto, una task solo se ejecuta si **todas** sus upstream tasks tienen Ã©xito. Pero con branching, algunas tasks se **saltan**.

**Problema:**
```python
inicio >> branch >> [task_a, task_b] >> fin
```

Si `branch` retorna solo `task_a`:
- âœ… task_a: success
- â­ï¸ task_b: skipped
- â“ fin: Â¿Se ejecuta o no?

**SoluciÃ³n:** Usar **trigger_rule** en la task `fin`:

```python
fin = DummyOperator(
    task_id="fin",
    trigger_rule="none_failed_min_one_success"
)
```

---

**Trigger Rules Comunes:**

| Trigger Rule                  | Se ejecuta si...                                                        |
| ----------------------------- | ----------------------------------------------------------------------- |
| `all_success`                 | **Todas** las upstream tasks fueron exitosas (default)                  |
| `all_failed`                  | **Todas** las upstream tasks fallaron                                   |
| `all_done`                    | **Todas** las upstream tasks terminaron (sin importar el estado)        |
| `one_success`                 | **Al menos una** upstream task fue exitosa                              |
| `one_failed`                  | **Al menos una** upstream task fallÃ³                                    |
| `none_failed`                 | **Ninguna** upstream task fallÃ³ (incluye skipped)                       |
| `none_failed_min_one_success` | **Al menos una** exitosa y **ninguna** fallida (âœ… ideal para branching) |
| `none_skipped`                | **Ninguna** upstream task fue saltada                                   |
| `always`                      | **Siempre** se ejecuta (sin importar nada)                              |

---

### ğŸ”€ Branching con MÃºltiples Caminos

Puedes retornar **varios task_ids** para ejecutar mÃºltiples tasks:

```python
def decidir_multiple(**context):
    ti = context["ti"]
    ventas = ti.xcom_pull(task_ids="calcular_ventas")

    if ventas > 50000:
        return ["enviar_email_gerente", "enviar_slack_ceo", "actualizar_dashboard"]
    elif ventas > 10000:
        return ["enviar_email_equipo"]
    else:
        return ["guardar_log"]

branch = BranchPythonOperator(task_id="decidir", python_callable=decidir_multiple)
```

**Flujo:**
```
decidir
  â”œâ”€â”€â†’ (ventas > 50000) [enviar_email_gerente, enviar_slack_ceo, actualizar_dashboard]
  â”œâ”€â”€â†’ (10000 < ventas â‰¤ 50000) enviar_email_equipo
  â””â”€â”€â†’ (ventas â‰¤ 10000) guardar_log
```

---

### âœ… Mejores PrÃ¡cticas de Branching

1. **Funciones de decisiÃ³n claras:** La lÃ³gica del branch debe ser simple y bien documentada
2. **Loggear la decisiÃ³n:** Usa `print()` para saber quÃ© camino se tomÃ³
3. **Usar trigger_rules:** Siempre configurar trigger_rule en tasks despuÃ©s del branch
4. **Evitar branches anidados:** Si necesitas muchos if-else, considera refactorizar
5. **Testing:** Testear que cada camino del branch funciona correctamente

---

## 6. Sensors: Esperar por Condiciones

### ğŸ¯ El Problema: Esperas Activas Ineficientes

Imagina que necesitas procesar un archivo que se genera cada hora por un sistema externo:

**SoluciÃ³n Ingenua (âŒ Mala):**
```python
import time
import os

def esperar_archivo():
    while not os.path.exists("datos.csv"):
        print("Archivo no existe, esperando...")
        time.sleep(60)  # âŒ Bloquea un worker durante todo el tiempo!
    print("Archivo encontrado, procesando...")

task = PythonOperator(task_id="esperar", python_callable=esperar_archivo)
```

**Problemas:**
1. **Bloquea un worker:** El worker no puede ejecutar otras tasks mientras espera
2. **Desperdicia recursos:** Consume CPU y memoria sin hacer nada Ãºtil
3. **Sin timeout:** PodrÃ­a esperar infinitamente
4. **DifÃ­cil de monitorear:** No se ve en la UI que estÃ¡ esperando

---

### ğŸ’¡ La SoluciÃ³n: Sensors

Los **Sensors** son operators especializados en **esperar por condiciones**. Verifican periÃ³dicamente si una condiciÃ³n se cumple, y cuando lo hace, la task tiene Ã©xito.

**AnalogÃ­a:** Un Sensor es como un guardia de seguridad

Imagina un guardia de seguridad en la entrada de un edificio:
- **Cada 2 minutos** (poke_interval), el guardia verifica si llegÃ³ una persona autorizada
- Si **no ha llegado en 30 minutos** (timeout), el guardia se va (task falla)
- Si **llega la persona**, el guardia abre la puerta (task success)
- Mientras espera, **no bloquea la entrada** (no bloquea el worker en mode="reschedule")

---

### ğŸ“ FileSensor: Esperar por Archivos

El **FileSensor** espera hasta que un archivo exista en el sistema de archivos.

```python
from airflow.sensors.filesystem import FileSensor

esperar_archivo = FileSensor(
    task_id="esperar_datos",
    filepath="/ruta/absoluta/datos.csv",
    poke_interval=30,  # Verificar cada 30 segundos
    timeout=600,  # Esperar mÃ¡ximo 10 minutos (600 segundos)
    mode="reschedule"  # No bloquear el worker
)
```

**ParÃ¡metros importantes:**

| ParÃ¡metro       | DescripciÃ³n                         | Default         |
| --------------- | ----------------------------------- | --------------- |
| `filepath`      | Ruta absoluta al archivo            | Requerido       |
| `poke_interval` | Cada cuÃ¡ntos segundos verificar     | 60              |
| `timeout`       | Tiempo mÃ¡ximo de espera (segundos)  | 604800 (7 dÃ­as) |
| `mode`          | "poke" o "reschedule"               | "poke"          |
| `soft_fail`     | Si True, no falla el DAG si timeout | False           |

---

**Mode: "poke" vs "reschedule"**

**mode="poke"** (default):
- El sensor **ocupa un worker slot** durante toda la espera
- Usa menos consultas a la BD
- âœ… Bueno para esperas cortas (<5 minutos)
- âŒ Malo para esperas largas (desperdicia workers)

**mode="reschedule"**:
- El sensor **libera el worker slot** entre verificaciones
- Permite que otros tasks usen ese worker
- âœ… Bueno para esperas largas (>5 minutos)
- âš ï¸ Hace mÃ¡s consultas a la BD (una por cada poke)

**RecomendaciÃ³n:** Usa `mode="reschedule"` siempre que esperes mÃ¡s de 5 minutos.

---

### ğŸ” Ejemplo Completo con FileSensor

```python
from airflow import DAG
from airflow.sensors.filesystem import FileSensor
from airflow.operators.python import PythonOperator
from datetime import datetime

def procesar_archivo():
    import pandas as pd
    df = pd.read_csv("/tmp/datos.csv")
    print(f"[PROCESAR] Procesando {len(df)} filas")

with DAG("ejemplo_filesensor", start_date=datetime(2025, 1, 1), schedule=None) as dag:

    esperar = FileSensor(
        task_id="esperar_datos",
        filepath="/tmp/datos.csv",
        poke_interval=10,  # Cada 10 segundos
        timeout=60,  # MÃ¡ximo 1 minuto
        mode="reschedule"
    )

    procesar = PythonOperator(
        task_id="procesar_datos",
        python_callable=procesar_archivo
    )

    esperar >> procesar
```

**Â¿CÃ³mo funciona?**

1. El DAG se ejecuta
2. Task `esperar_datos` comienza
3. Cada 10 segundos, verifica si `/tmp/datos.csv` existe
4. Si existe â†’ âœ… Success â†’ ejecuta `procesar_datos`
5. Si pasan 60 segundos sin encontrarlo â†’ âŒ Fail (timeout)

---

### â° TimeSensor: Esperar hasta una Hora EspecÃ­fica

El **TimeSensor** espera hasta una hora especÃ­fica del dÃ­a.

```python
from airflow.sensors.time_sensor import TimeSensor

esperar_hora = TimeSensor(
    task_id="esperar_9am",
    target_time=datetime.time(9, 0, 0),  # 09:00:00
)
```

**Caso de uso:** Procesar datos solo despuÃ©s de las 9 AM (cuando el sistema fuente termina de cargar datos).

---

### ğŸŒ HttpSensor: Esperar por una API

El **HttpSensor** espera hasta que una API responda correctamente.

```python
from airflow.providers.http.sensors.http import HttpSensor

esperar_api = HttpSensor(
    task_id="esperar_api",
    http_conn_id="mi_api",  # Connection configurada en Airflow UI
    endpoint="/status",
    request_params={},
    response_check=lambda response: "ready" in response.text,
    poke_interval=30,
    timeout=300
)
```

---

### ğŸ”— ExternalTaskSensor: Esperar por Otro DAG

El **ExternalTaskSensor** espera hasta que una task de **otro DAG** termine.

```python
from airflow.sensors.external_task import ExternalTaskSensor

esperar_otro_dag = ExternalTaskSensor(
    task_id="esperar_dag_ventas",
    external_dag_id="procesar_ventas",
    external_task_id="cargar_bd",
    timeout=1800,  # 30 minutos
    poke_interval=60
)
```

**Caso de uso:** DAG B depende de que DAG A termine primero.

---

### âš ï¸ Cuidados con Sensors

**1. Timeouts Razonables**

âŒ Malo:
```python
sensor = FileSensor(filepath="...", timeout=86400)  # 24 horas!
```

âœ… Bueno:
```python
sensor = FileSensor(filepath="...", timeout=600)  # 10 minutos
```

**2. Poke Interval Apropiado**

âŒ Malo (demasiado frecuente):
```python
sensor = FileSensor(filepath="...", poke_interval=1)  # Cada segundo!
```

âœ… Bueno:
```python
sensor = FileSensor(filepath="...", poke_interval=30)  # Cada 30 segundos
```

**3. Usar Mode Reschedule para Esperas Largas**

âŒ Malo:
```python
sensor = FileSensor(filepath="...", timeout=3600, mode="poke")  # 1 hora bloqueando worker!
```

âœ… Bueno:
```python
sensor = FileSensor(filepath="...", timeout=3600, mode="reschedule")
```

---

### âœ… Mejores PrÃ¡cticas de Sensors

1. **Timeouts realistas:** Configura timeouts basados en expectativas reales
2. **Mode reschedule:** Usa `mode="reschedule"` para esperas >5 minutos
3. **Poke interval apropiado:** 10-60 segundos suele ser razonable
4. **Soft fail:** Usa `soft_fail=True` si la ausencia del recurso no es crÃ­tica
5. **Alertas:** Configura alertas si un sensor falla frecuentemente

---

## 7. Dynamic DAG Generation

### ğŸ¯ El Problema: Crear MÃºltiples Tasks Similares

Imagina que necesitas procesar **10 archivos CSV** diferentes, uno por cada regiÃ³n:

**SoluciÃ³n Ingenua (âŒ Malo):**
```python
procesar_madrid = PythonOperator(task_id="procesar_madrid", ...)
procesar_barcelona = PythonOperator(task_id="procesar_barcelona", ...)
procesar_valencia = PythonOperator(task_id="procesar_valencia", ...)
procesar_sevilla = PythonOperator(task_id="procesar_sevilla", ...)
# ... 10 tasks mÃ¡s!

inicio >> [procesar_madrid, procesar_barcelona, procesar_valencia, ...] >> fin
```

**Problemas:**
1. **CÃ³digo repetitivo:** Copiar-pegar 10 veces
2. **DifÃ­cil de mantener:** Si cambias algo, tienes que editar 10 lugares
3. **No escalable:** Â¿Y si maÃ±ana son 50 regiones?

---

### ğŸ’¡ La SoluciÃ³n: Dynamic DAG Generation

Puedes **generar tasks dinÃ¡micamente** usando bucles de Python:

```python
regiones = ["Madrid", "Barcelona", "Valencia", "Sevilla", "Bilbao"]

for region in regiones:
    task = PythonOperator(
        task_id=f"procesar_{region.lower()}",
        python_callable=procesar_region,
        op_kwargs={"region": region}
    )
    inicio >> task >> fin
```

**Â¡Mucho mÃ¡s limpio!** âœ¨

---

### ğŸ” Ejemplo Completo

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.dummy import DummyOperator
from datetime import datetime

def procesar_region(region: str):
    """Procesa datos de una regiÃ³n especÃ­fica"""
    print(f"[{region}] Procesando datos de la regiÃ³n {region}")
    # AquÃ­ irÃ­an las transformaciones especÃ­ficas

with DAG("ejemplo_dynamic", start_date=datetime(2025, 1, 1), schedule=None) as dag:

    inicio = DummyOperator(task_id="inicio")
    fin = DummyOperator(task_id="fin")

    regiones = ["Madrid", "Barcelona", "Valencia", "Sevilla", "Bilbao",
                "Zaragoza", "MÃ¡laga", "Murcia", "Palma", "Las_Palmas"]

    for region in regiones:
        task = PythonOperator(
            task_id=f"procesar_{region}",
            python_callable=procesar_region,
            op_kwargs={"region": region}
        )

        inicio >> task >> fin
```

**Flujo visual:**
```
inicio â†’ [procesar_Madrid, procesar_Barcelona, ..., procesar_Las_Palmas] â†’ fin
```

**âœ… Ventajas:**
- 10 tasks creadas con 5 lÃ­neas de cÃ³digo
- FÃ¡cil de mantener: cambio en un lugar
- Escalable: agregar regiones es solo editar la lista

---

### ğŸ”¢ Generar Tasks con Rangos NumÃ©ricos

```python
# Procesar 365 dÃ­as del aÃ±o
for dia in range(1, 366):
    task = PythonOperator(
        task_id=f"procesar_dia_{dia}",
        python_callable=procesar_dia,
        op_kwargs={"dia": dia}
    )
    inicio >> task >> consolidar
```

---

### ğŸ“ Generar Tasks desde Archivos en un Directorio

```python
import os
from pathlib import Path

# Leer todos los CSV de un directorio
data_dir = Path("/data/input")
archivos = list(data_dir.glob("*.csv"))

for archivo in archivos:
    task = PythonOperator(
        task_id=f"procesar_{archivo.stem}",  # .stem = nombre sin extensiÃ³n
        python_callable=procesar_archivo,
        op_kwargs={"ruta": str(archivo)}
    )
    inicio >> task >> consolidar
```

---

### âš ï¸ LÃ­mites y Cuidados

**LÃ­mite Recomendado: 50-100 Tasks**

Si generas **demasiadas tasks** (>100), el DAG se vuelve lento:
- El scheduler tarda mÃ¡s en parsear el DAG
- La UI se vuelve lenta
- MÃ¡s tareas = mÃ¡s consultas a la BD

**Alternativa para >100 Tareas:**

En lugar de crear 1000 tasks, crea **10 tasks que procesen 100 items cada una**:

```python
def procesar_batch(inicio: int, fin: int):
    for i in range(inicio, fin):
        procesar_item(i)

# 10 tasks, cada una procesa 100 items
for batch in range(10):
    task = PythonOperator(
        task_id=f"batch_{batch}",
        python_callable=procesar_batch,
        op_kwargs={"inicio": batch * 100, "fin": (batch + 1) * 100}
    )
    inicio >> task >> fin
```

---

### âœ… Mejores PrÃ¡cticas de Dynamic DAGs

1. **Listas explÃ­citas:** Define las listas al inicio del DAG, no dentro del bucle
2. **LÃ­mite de tasks:** No generes mÃ¡s de 50-100 tasks
3. **Batching:** Si necesitas muchas tasks, agrÃºpalas en batches
4. **Task IDs Ãºnicos:** AsegÃºrate de que cada task tenga un ID Ãºnico
5. **Op_kwargs:** Usa `op_kwargs` para pasar parÃ¡metros especÃ­ficos a cada task

---

## 8. Templating con Jinja2

### ğŸ¯ El Problema: Configuraciones DinÃ¡micas

Imagina que quieres procesar archivos con nombres que incluyen la **fecha de ejecuciÃ³n**:

**SoluciÃ³n Ingenua (âŒ Malo):**
```python
def procesar(**context):
    fecha = context["execution_date"].strftime("%Y-%m-%d")
    archivo = f"/data/ventas_{fecha}.csv"
    # ...
```

Tienes que acceder al contexto en cada funciÃ³n. Â¿Hay una forma mÃ¡s simple?

---

### ğŸ’¡ La SoluciÃ³n: Templating con Jinja2

Airflow usa **Jinja2** para permitirte usar **variables dinÃ¡micas** directamente en los parÃ¡metros de los operators.

**Ejemplo:**
```python
task = BashOperator(
    task_id="procesar",
    bash_command="python procesar.py /data/ventas_{{ ds }}.csv"
)
```

`{{ ds }}` se reemplaza automÃ¡ticamente por la fecha de ejecuciÃ³n en formato `YYYY-MM-DD`.

---

### ğŸ“ Variables Jinja2 Comunes

| Variable                      | DescripciÃ³n                     | Ejemplo                            |
| ----------------------------- | ------------------------------- | ---------------------------------- |
| `{{ ds }}`                    | Fecha de ejecuciÃ³n (YYYY-MM-DD) | 2025-01-15                         |
| `{{ ds_nodash }}`             | Fecha sin guiones (YYYYMMDD)    | 20250115                           |
| `{{ ts }}`                    | Timestamp completo (ISO 8601)   | 2025-01-15T10:30:00+00:00          |
| `{{ execution_date }}`        | Objeto datetime de la ejecuciÃ³n | datetime(2025, 1, 15, 10, 30)      |
| `{{ dag }}`                   | Objeto DAG                      | <DAG: mi_dag>                      |
| `{{ task }}`                  | Objeto Task                     | <Task(PythonOperator): mi_task>    |
| `{{ ti }}`                    | Objeto TaskInstance             | <TaskInstance: mi_dag.mi_task ...> |
| `{{ var.value.mi_variable }}` | Variable de Airflow             | (valor configurado en UI)          |
| `{{ var.json.mi_json.key }}`  | Variable JSON de Airflow        | (valor de una key JSON)            |

---

### ğŸ” Ejemplo con BashOperator

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG("ejemplo_templating", start_date=datetime(2025, 1, 1), schedule="@daily") as dag:

    procesar = BashOperator(
        task_id="procesar_archivo",
        bash_command="""
        echo "Procesando datos del {{ ds }}"
        python procesar.py --fecha={{ ds }} --output=/data/resultado_{{ ds_nodash }}.csv
        """
    )
```

Si se ejecuta el **2025-01-15**, el comando serÃ¡:
```bash
echo "Procesando datos del 2025-01-15"
python procesar.py --fecha=2025-01-15 --output=/data/resultado_20250115.csv
```

---

### ğŸ Templating en PythonOperator

Por defecto, PythonOperator **no hace templating** en `op_kwargs`. Debes usar `templates_dict`:

```python
def procesar_con_fecha(fecha: str, archivo: str):
    print(f"Procesando fecha: {fecha}")
    print(f"Leyendo archivo: {archivo}")

task = PythonOperator(
    task_id="procesar",
    python_callable=procesar_con_fecha,
    op_kwargs={
        "fecha": "{{ ds }}",
        "archivo": "/data/ventas_{{ ds }}.csv"
    }
)
```

**âš ï¸ Importante:** Los parÃ¡metros de `op_kwargs` **SÃ se templatian** (desde Airflow 2.0+).

---

### ğŸ§® Macros de Jinja2

Airflow incluye **macros Ãºtiles** para manipular fechas:

```python
bash_command="""
# Fecha de ayer
python procesar.py --fecha={{ macros.ds_add(ds, -1) }}

# Fecha de maÃ±ana
python procesar.py --fecha={{ macros.ds_add(ds, 1) }}

# Fecha de hace 7 dÃ­as
python procesar.py --fecha={{ macros.ds_add(ds, -7) }}

# Formato personalizado
python procesar.py --mes={{ execution_date.strftime('%B') }}
"""
```

---

### âœ… Mejores PrÃ¡cticas de Templating

1. **Usa templates para rutas:** Evita hardcodear fechas
2. **Documenta:** Comenta quÃ© variables usas y por quÃ©
3. **Verifica sintaxis:** Errores de Jinja2 solo aparecen en ejecuciÃ³n
4. **Variables de Airflow:** Usa Variables para configuraciones que cambian entre ambientes
5. **Testing:** Prueba el templating con diferentes fechas

---

## 9. Mejores PrÃ¡cticas del Tema 2

### âœ… TaskGroups

- âœ… Usa TaskGroups cuando tengas >5 tasks relacionadas
- âœ… Nombres descriptivos: `grupo_extraccion`, no `grupo1`
- âœ… No anides mÃ¡s de 2 niveles (grupo dentro de grupo dentro de grupo es confuso)
- âŒ No uses TaskGroups para 2-3 tasks (innecesario)

---

### âœ… XComs

- âœ… Solo para datos pequeÃ±os (<10 KB)
- âœ… Keys descriptivas: `total_ventas`, no `data1`
- âœ… Documenta quÃ© XComs produce cada task
- âœ… Valida que el XCom existe antes de usarlo
- âŒ No uses XComs para DataFrames completos
- âŒ No hagas muchos `xcom_pull` en bucles

---

### âœ… Branching

- âœ… Funciones de decisiÃ³n simples y documentadas
- âœ… Loggear quÃ© camino se tomÃ³
- âœ… Usar `trigger_rule` en tasks despuÃ©s del branch
- âŒ Evita branches anidados complejos
- âŒ No uses branching si un simple if en Python es suficiente

---

### âœ… Sensors

- âœ… Timeouts realistas (5-30 minutos, no 24 horas)
- âœ… `mode="reschedule"` para esperas >5 minutos
- âœ… Poke interval de 10-60 segundos
- âœ… Configura alertas si fallan frecuentemente
- âŒ No uses `poke_interval=1` (demasiado frecuente)

---

### âœ… Dynamic DAGs

- âœ… Limita a 50-100 tasks generadas
- âœ… Usa batching para procesar muchos items
- âœ… Task IDs Ãºnicos y descriptivos
- âŒ No generes >100 tasks (usa batching)
- âŒ No leas archivos externos al generar el DAG (parseo lento)

---

### âœ… Templating

- âœ… Usa templates para rutas con fechas
- âœ… Documenta quÃ© variables usas
- âœ… Usa Variables de Airflow para configuraciones
- âŒ No abuses de templates complejos (difÃ­cil de debuggear)

---

## 10. Resumen y PrÃ³ximos Pasos

### ğŸ‰ Â¡Felicitaciones!

Has completado el **Tema 2: Airflow Intermedio**. Ahora sabes:

âœ… **TaskGroups:** Organizar DAGs complejos visualmente
âœ… **XComs:** Compartir datos pequeÃ±os entre tasks
âœ… **Branching:** Crear flujos condicionales (if-else)
âœ… **Sensors:** Esperar por archivos, APIs, horarios
âœ… **Dynamic DAGs:** Generar tasks automÃ¡ticamente
âœ… **Templating:** Usar variables dinÃ¡micas con Jinja2

---

### ğŸ“š Â¿QuÃ© sigue?

**PrÃ³ximo Tema: Tema 3 - Airflow en ProducciÃ³n**

AprenderÃ¡s:
- **Variables y Connections:** Gestionar configuraciones y credenciales
- **Logs y Monitoreo:** IntegraciÃ³n con ELK, Datadog, CloudWatch
- **Testing de DAGs:** Unit tests, integration tests
- **Mejores PrÃ¡cticas Productivas:** Retries, SLAs, alertas
- **Ejecutores:** LocalExecutor, CeleryExecutor, KubernetesExecutor
- **OptimizaciÃ³n:** Paralelismo, pools, performance tuning

---

### ğŸ› ï¸ PrÃ¡ctica Recomendada

Antes de continuar al Tema 3, **practica** lo aprendido:

1. Crear un DAG con TaskGroups (agrupa 6+ tasks)
2. Usar XComs para pasar datos entre 3 tasks
3. Implementar Branching con 2 caminos
4. Usar un FileSensor para esperar un archivo
5. Generar 10 tasks dinÃ¡micamente
6. Usar templating para paths con fechas

---

### ğŸ“– Recursos Adicionales

- **DocumentaciÃ³n Oficial de Airflow:** https://airflow.apache.org/docs/
- **TaskGroups:** https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/dags.html#taskgroups
- **XComs:** https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/xcoms.html
- **Sensors:** https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/sensors.html
- **Jinja2 Templating:** https://jinja.palletsprojects.com/

---

**ğŸš€ Â¡ContinÃºa con el Tema 3: Airflow en ProducciÃ³n!**
