# ğŸ—ï¸ Proyecto PrÃ¡ctico: Data Lake Multi-Ambiente con Terraform

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un **Data Lake completo** en AWS usando **Terraform** con las mejores prÃ¡cticas de Infrastructure as Code:

- âœ… **Multi-ambiente**: Dev, Staging, Prod
- âœ… **Modular**: CÃ³digo reutilizable con mÃ³dulos
- âœ… **Validado**: Tests automÃ¡ticos con Terratest
- âœ… **Documentado**: Auto-generaciÃ³n de docs
- âœ… **Seguro**: EncriptaciÃ³n, IAM least privilege, secrets management
- âœ… **Cost-optimized**: Lifecycle policies, tags para billing

---

## ğŸ¯ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      AWS ACCOUNT                             â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  VPC (10.0.0.0/16)                    â”‚  â”‚
â”‚  â”‚                                                        â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚  â”‚
â”‚  â”‚  â”‚ Public Subnet   â”‚      â”‚ Private Subnet  â”‚       â”‚  â”‚
â”‚  â”‚  â”‚  - NAT Gateway  â”‚      â”‚  - Lambda       â”‚       â”‚  â”‚
â”‚  â”‚  â”‚  - Bastion      â”‚      â”‚  - RDS (future) â”‚       â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                S3 DATA LAKE                          â”‚   â”‚
â”‚  â”‚                                                       â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚   â”‚
â”‚  â”‚  â”‚ raw/        â”‚â”€â”€>â”‚ processed/  â”‚â”€â”€>â”‚ analytics/  â”‚â”‚   â”‚
â”‚  â”‚  â”‚ (90dâ†’Glacierâ”‚   â”‚ (30dâ†’IA)    â”‚   â”‚ (365d TTL)  â”‚â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                LAMBDA PIPELINE                        â”‚   â”‚
â”‚  â”‚  - Trigger: S3 ObjectCreated (raw/)                  â”‚   â”‚
â”‚  â”‚  - Process: Transform CSV â†’ Parquet                  â”‚   â”‚
â”‚  â”‚  - Output: S3 processed/                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              GLUE CATALOG                             â”‚   â”‚
â”‚  â”‚  - Database: data_lake                                â”‚   â”‚
â”‚  â”‚  - Tables: raw_data, processed_data                  â”‚   â”‚
â”‚  â”‚  - Crawler: Auto-discovery schemas                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              ATHENA QUERIES                           â”‚   â”‚
â”‚  â”‚  - Query processed data with SQL                     â”‚   â”‚
â”‚  â”‚  - Results â†’ analytics/                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              CLOUDWATCH MONITORING                    â”‚   â”‚
â”‚  â”‚  - Lambda logs (7 days retention)                    â”‚   â”‚
â”‚  â”‚  - Alarms: Lambda errors, S3 metrics                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Estructura del Proyecto

```
04-proyecto-practico/
â”œâ”€â”€ README.md                    â† Este archivo
â”œâ”€â”€ requirements.txt             â† Python dependencies para scripts
â”‚
â”œâ”€â”€ terraform/                   â† CÃ³digo Terraform
â”‚   â”œâ”€â”€ environments/            â† ConfiguraciÃ³n por ambiente
â”‚   â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”‚   â”‚   â””â”€â”€ backend.tf
â”‚   â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â”‚   â”œâ”€â”€ terraform.tfvars
â”‚   â”‚   â”‚   â””â”€â”€ backend.tf
â”‚   â”‚   â””â”€â”€ prod/
â”‚   â”‚       â”œâ”€â”€ main.tf
â”‚   â”‚       â”œâ”€â”€ terraform.tfvars
â”‚   â”‚       â””â”€â”€ backend.tf
â”‚   â”‚
â”‚   â””â”€â”€ modules/                 â† MÃ³dulos reutilizables
â”‚       â”œâ”€â”€ data-lake/           â† MÃ³dulo S3 buckets + lifecycle
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â”œâ”€â”€ outputs.tf
â”‚       â”‚   â””â”€â”€ README.md
â”‚       â”œâ”€â”€ lambda-etl/          â† MÃ³dulo Lambda function
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â”œâ”€â”€ outputs.tf
â”‚       â”‚   â”œâ”€â”€ lambda_function.py
â”‚       â”‚   â””â”€â”€ README.md
â”‚       â”œâ”€â”€ networking/          â† MÃ³dulo VPC + subnets
â”‚       â”‚   â”œâ”€â”€ main.tf
â”‚       â”‚   â”œâ”€â”€ variables.tf
â”‚       â”‚   â”œâ”€â”€ outputs.tf
â”‚       â”‚   â””â”€â”€ README.md
â”‚       â””â”€â”€ glue-catalog/        â† MÃ³dulo Glue database + crawler
â”‚           â”œâ”€â”€ main.tf
â”‚           â”œâ”€â”€ variables.tf
â”‚           â”œâ”€â”€ outputs.tf
â”‚           â””â”€â”€ README.md
â”‚
â”œâ”€â”€ tests/                       â† Tests de infraestructura
â”‚   â”œâ”€â”€ test_terraform_validate.py
â”‚   â”œâ”€â”€ test_terraform_format.py
â”‚   â”œâ”€â”€ test_terraform_plan.py
â”‚   â””â”€â”€ test_module_structure.py
â”‚
â”œâ”€â”€ scripts/                     â† Scripts de automatizaciÃ³n
â”‚   â”œâ”€â”€ deploy.sh                â† Despliegue automatizado
â”‚   â”œâ”€â”€ destroy.sh               â† DestrucciÃ³n segura
â”‚   â”œâ”€â”€ validate_all.sh          â† ValidaciÃ³n de todos los ambientes
â”‚   â””â”€â”€ generate_docs.sh         â† Auto-generaciÃ³n de documentaciÃ³n
â”‚
â”œâ”€â”€ docs/                        â† DocumentaciÃ³n generada
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ cost-estimation.md
â”‚   â””â”€â”€ runbook.md
â”‚
â”œâ”€â”€ .tflint.hcl                  â† ConfiguraciÃ³n de linter
â”œâ”€â”€ .pre-commit-config.yaml      â† Pre-commit hooks
â””â”€â”€ pytest.ini                   â† ConfiguraciÃ³n de pytest
```

---

## ğŸš€ Quick Start

### Prerequisitos

```bash
# 1. Instalar herramientas
brew install terraform      # macOS
# o
choco install terraform     # Windows
# o
sudo apt-get install terraform  # Linux

# 2. Configurar AWS CLI
aws configure

# 3. Instalar Python dependencies
pip install -r requirements.txt

# 4. Instalar pre-commit hooks
pre-commit install
```

### Despliegue en Dev

```bash
# 1. Navegar a ambiente dev
cd terraform/environments/dev

# 2. Inicializar Terraform
terraform init

# 3. Ver plan de ejecuciÃ³n
terraform plan

# 4. Aplicar (crear infraestructura)
terraform apply

# 5. Ver outputs
terraform output
```

### Despliegue Automatizado

```bash
# Script automatizado con validaciones
./scripts/deploy.sh dev
```

---

## ğŸ§ª Testing

Este proyecto incluye **tests automatizados** para validar la infraestructura:

### Test 1: ValidaciÃ³n de Sintaxis

```bash
# Ejecutar tests
pytest tests/test_terraform_validate.py -v

# Output esperado:
# tests/test_terraform_validate.py::test_validate_dev PASSED
# tests/test_terraform_validate.py::test_validate_staging PASSED
# tests/test_terraform_validate.py::test_validate_prod PASSED
```

### Test 2: Formato de CÃ³digo

```bash
pytest tests/test_terraform_format.py -v

# Output esperado:
# tests/test_terraform_format.py::test_format_check PASSED
```

### Test 3: Plan Sin Errores

```bash
pytest tests/test_terraform_plan.py -v

# Output esperado:
# tests/test_terraform_plan.py::test_plan_dev PASSED
```

### Test 4: Estructura de MÃ³dulos

```bash
pytest tests/test_module_structure.py -v

# Output esperado:
# tests/test_module_structure.py::test_data_lake_module_structure PASSED
# tests/test_module_structure.py::test_lambda_etl_module_structure PASSED
```

### Ejecutar Todos los Tests

```bash
pytest tests/ -v --tb=short

# O con cobertura
pytest tests/ --cov=terraform --cov-report=html
```

---

## ğŸ“Š MÃ³dulos Implementados

### 1. Data Lake Module

Crea 3 buckets S3 con lifecycle policies:
- `raw/`: Datos sin procesar (90 dÃ­as â†’ Glacier)
- `processed/`: Datos transformados (30 dÃ­as â†’ IA)
- `analytics/`: Resultados de anÃ¡lisis (365 dÃ­as TTL)

**Variables**:
- `project_name`: Nombre del proyecto
- `environment`: dev, staging, prod
- `enable_encryption`: true/false
- `raw_retention_days`: 90
- `processed_retention_days`: 365

### 2. Lambda ETL Module

FunciÃ³n Lambda que:
- Se dispara automÃ¡ticamente cuando se sube archivo a `raw/`
- Lee CSV, transforma a Parquet
- Escribe resultado en `processed/`
- Logs en CloudWatch

**Variables**:
- `function_name`: Nombre de la funciÃ³n
- `runtime`: python3.11
- `timeout`: 300
- `memory_size`: 512
- `source_bucket`: Bucket de input
- `destination_bucket`: Bucket de output

### 3. Networking Module

VPC con subnets pÃºblico/privado:
- VPC: `10.0.0.0/16`
- Public subnet: `10.0.1.0/24`
- Private subnet: `10.0.2.0/24`
- NAT Gateway
- Internet Gateway
- Route tables

**Variables**:
- `vpc_cidr`: CIDR de VPC
- `public_subnet_cidrs`: Lista de CIDRs pÃºblicos
- `private_subnet_cidrs`: Lista de CIDRs privados

### 4. Glue Catalog Module

CatÃ¡logo de Glue con:
- Database: `data_lake_<environment>`
- Crawler: Auto-discovery de schemas
- Tables: `raw_data`, `processed_data`

**Variables**:
- `database_name`: Nombre del database
- `crawler_schedule`: cron expression
- `data_location`: S3 path para crawlear

---

## ğŸ’° CÃ¡lculo de Costos

### Dev Environment (Estimado)

```
S3 Storage (50 GB total):
- Standard (10 GB nuevos/mes): $0.23
- IA (20 GB): $0.25
- Glacier (20 GB): $0.08
Total S3: $0.56/mes

Lambda (1000 invocaciones/mes):
- Free Tier cubre
Total Lambda: $0

Glue Crawler (1x/dÃ­a):
- $0.44/hora * 0.1 hora/dÃ­a * 30 dÃ­as = $1.32
Total Glue: $1.32/mes

CloudWatch Logs (100 MB):
- $0.50/GB = $0.05
Total Logs: $0.05/mes

VPC (NAT Gateway):
- $0.045/hora * 730 horas = $32.85
Total NAT: $32.85/mes

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOTAL DEV: ~$35/mes
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ Para reducir costos en dev:
- Usar NAT Instance en vez de NAT Gateway: ~$3/mes
- Desactivar crawler cuando no se use
- Usar lifecycle agresivo (30 dÃ­as â†’ Glacier)

Total Dev Optimizado: ~$5/mes
```

### Production Environment (Estimado)

```
S3 Storage (1 TB total):
- Standard (100 GB): $2.30
- IA (400 GB): $5.00
- Glacier (500 GB): $2.00
Total S3: $9.30/mes

Lambda (100K invocaciones/mes):
- Compute: $0.83
- Requests: $0.02
Total Lambda: $0.85/mes

Glue Crawler (2x/dÃ­a):
- $0.44/hora * 0.2 hora/dÃ­a * 30 dÃ­as * 2 = $5.28
Total Glue: $5.28/mes

Athena Queries (1 TB escaneado):
- $5/TB = $5
Total Athena: $5/mes

NAT Gateway (High Availability, 2 AZs):
- $0.045/hora * 730 * 2 = $65.70
- Data processing: $0.045/GB * 100GB = $4.50
Total NAT: $70.20/mes

RDS PostgreSQL (t3.micro reserved):
- $12/mes (1 year upfront)

Total Prod: ~$107.63/mes (~$1,291/aÃ±o)

Con Reserved Instances y Savings Plans:
Total Prod Optimizado: ~$75/mes (~$900/aÃ±o)
```

---

## ğŸ”’ Seguridad

### Buenas PrÃ¡cticas Implementadas

1. **EncriptaciÃ³n**:
   - S3: Server-side encryption (SSE-S3 o SSE-KMS)
   - RDS: Encryption at rest
   - Lambda: Variables de entorno encriptadas

2. **IAM Least Privilege**:
   - Roles especÃ­ficos por servicio
   - Policies con recursos explÃ­citos (no `*`)
   - Sin credenciales hardcodeadas

3. **Networking**:
   - Lambda en VPC privada
   - RDS sin acceso pÃºblico
   - Security groups restrictivos

4. **Secrets Management**:
   - AWS Secrets Manager para credenciales
   - No secrets en cÃ³digo
   - RotaciÃ³n automÃ¡tica de secrets

5. **Logging y Monitoring**:
   - CloudWatch Logs para todas las funciones
   - CloudTrail para auditorÃ­a
   - Alarms para eventos crÃ­ticos

---

## ğŸ“š Comandos Ãštiles

### Terraform

```bash
# Validar sintaxis
terraform validate

# Formatear cÃ³digo
terraform fmt -recursive

# Ver plan detallado
terraform plan -out=tfplan

# Aplicar plan guardado
terraform apply tfplan

# Ver estado
terraform show

# Listar recursos
terraform state list

# Ver output especÃ­fico
terraform output bucket_name

# Destruir infraestructura
terraform destroy

# Importar recurso existente
terraform import aws_s3_bucket.example my-bucket-name

# Refrescar estado
terraform refresh
```

### Testing

```bash
# Ejecutar test especÃ­fico
pytest tests/test_terraform_validate.py::test_validate_dev -v

# Ejecutar con verbose
pytest tests/ -vv

# Ejecutar con coverage
pytest tests/ --cov=terraform --cov-report=html

# Ver coverage report
open htmlcov/index.html
```

### Linting

```bash
# Ejecutar tflint
tflint --init
tflint terraform/

# Ejecutar checkov (security scanner)
checkov -d terraform/

# Ejecutar terraform-docs
terraform-docs markdown terraform/modules/data-lake/
```

---

## ğŸš€ CI/CD Pipeline

El proyecto incluye GitHub Actions workflow para automatizar:

1. **On Pull Request**:
   - `terraform fmt -check`
   - `terraform validate`
   - `tflint`
   - `checkov`
   - `terraform plan`
   - Comentar plan en PR

2. **On Merge to Main**:
   - Deploy a `dev` automÃ¡ticamente
   - Tag de versiÃ³n
   - Crear release notes

3. **On Release Tag**:
   - Deploy a `staging`
   - Esperar aprobaciÃ³n manual
   - Deploy a `prod`
   - Notificar en Slack

ConfiguraciÃ³n en `.github/workflows/terraform.yml`

---

## ğŸ“– DocumentaciÃ³n

### Auto-generada

```bash
# Generar documentaciÃ³n de mÃ³dulos
./scripts/generate_docs.sh

# Output en docs/
```

### Manual

- **Architecture**: `docs/architecture.md`
- **Cost Estimation**: `docs/cost-estimation.md`
- **Runbook**: `docs/runbook.md` (procedimientos operativos)

---

## ğŸ“ Aprendizajes Clave

DespuÃ©s de completar este proyecto, habrÃ¡s aprendido:

1. âœ… **Terraform Basics**: Resources, variables, outputs, state
2. âœ… **Terraform Modules**: CÃ³digo reutilizable y DRY
3. âœ… **Multi-Environment**: Workspaces, tfvars, backends
4. âœ… **Testing IaC**: pytest, terraform validate, tflint
5. âœ… **Security**: IAM, encryption, secrets management
6. âœ… **Cost Optimization**: Lifecycle policies, reserved instances
7. âœ… **CI/CD**: GitHub Actions, automated deployments
8. âœ… **Monitoring**: CloudWatch, alarms, dashboards
9. âœ… **Documentation**: Auto-generation, runbooks
10. âœ… **Best Practices**: Naming, tagging, versioning

---

## ğŸ› Troubleshooting

### Error: "Backend initialization required"

```bash
terraform init -reconfigure
```

### Error: "Resource already exists"

```bash
# Importar recurso existente
terraform import aws_s3_bucket.raw my-existing-bucket
```

### Error: "Permission denied"

```bash
# Verificar credenciales AWS
aws sts get-caller-identity

# Re-configurar si es necesario
aws configure
```

### Error: "State lock"

```bash
# Forzar unlock (solo si estÃ¡s seguro)
terraform force-unlock LOCK_ID
```

---

## ğŸ¤ Contribuir

1. Fork del repositorio
2. Crear branch (`git checkout -b feature/nueva-funcionalidad`)
3. Commit cambios (`git commit -am 'AÃ±adir nueva funcionalidad'`)
4. Push a branch (`git push origin feature/nueva-funcionalidad`)
5. Crear Pull Request

---

## ğŸ“ Licencia

Este proyecto es parte del **Master en IngenierÃ­a de Datos con IA** y estÃ¡ disponible bajo licencia MIT.

---

## ğŸ“ Soporte

- **DocumentaciÃ³n**: Ver `docs/`
- **Issues**: GitHub Issues
- **Slack**: Canal #terraform-help

---

**Â¡Felicidades!** Has completado el proyecto de Infrastructure as Code. ğŸ‰

Ahora tienes una infraestructura de Data Lake completa, testeada y lista para producciÃ³n.
