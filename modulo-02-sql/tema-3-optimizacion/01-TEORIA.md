# Tema 3: OptimizaciÃ³n de Consultas SQL

## IntroducciÃ³n

Imagina que tienes una biblioteca con 10 millones de libros. Si alguien te pide encontrar un libro especÃ­fico y no tienes ningÃºn sistema de organizaciÃ³n, tendrÃ­as que revisar cada libro uno por uno. PodrÃ­as tardar aÃ±os. Pero si tienes un catÃ¡logo por autor, gÃ©nero y tÃ­tulo, encontrar cualquier libro toma solo minutos.

**Esto es exactamente lo que hace la optimizaciÃ³n SQL**: organiza y estructura tus consultas para que la base de datos encuentre los datos en segundos en lugar de horas.

### Â¿Por quÃ© es importante la optimizaciÃ³n?

En Data Engineering, trabajarÃ¡s con:
- **Millones de registros** en tablas transaccionales
- **Billones de eventos** en sistemas de analytics
- **Petabytes de datos** en data warehouses
- **Consultas que se ejecutan miles de veces por dÃ­a**

Una consulta mal optimizada que tarda 10 segundos en lugar de 0.1 segundos puede:
- **Bloquear tu pipeline ETL** y retrasar todo el procesamiento
- **Costar miles de dÃ³lares** en recursos de nube (AWS RDS cobra por tiempo de CPU)
- **Frustrar a usuarios** esperando reportes
- **Causar caÃ­das de servicio** por saturaciÃ³n de recursos

**Ejemplo real**: En una empresa de e-commerce, optimizar una consulta de "productos relacionados" de 8 segundos a 0.3 segundos aumentÃ³ las ventas en un 12% porque los usuarios no abandonaban la pÃ¡gina mientras cargaba.

### Contexto en Data Engineering

Como Data Engineer, optimizarÃ¡s consultas SQL en:

1. **Pipelines ETL**: Consultas que extraen millones de registros cada hora
2. **Data Warehouses**: Agregaciones sobre billones de eventos para reportes
3. **APIs de Datos**: Endpoints que consultan bases de datos en tiempo real
4. **Dashboards**: Consultas que alimentan visualizaciones ejecutÃ¡ndose cada minuto

La optimizaciÃ³n SQL es una de las habilidades mÃ¡s valiosas y rentables en Data Engineering.

---

## Conceptos Fundamentales

### 1. Â¿CÃ³mo Ejecuta una Consulta la Base de Datos?

Cuando escribes una consulta SQL, la base de datos NO la ejecuta directamente. Primero pasa por 4 etapas:

#### Etapa 1: Parsing (AnÃ¡lisis SintÃ¡ctico)
La BD verifica que tu SQL sea vÃ¡lido:
```sql
SELECT * FORM users;  -- âŒ Error: "FORM" no existe
SELECT * FROM users;  -- âœ… Sintaxis vÃ¡lida
```

#### Etapa 2: Query Planning (PlanificaciÃ³n)
La BD genera **mÃºltiples planes** de cÃ³mo ejecutar tu consulta:
- Plan A: Leer toda la tabla secuencialmente (Seq Scan)
- Plan B: Usar Ã­ndice en columna X (Index Scan)
- Plan C: Usar Ã­ndice en columna Y y filtrar despuÃ©s

**AnalogÃ­a**: Como Google Maps mostrÃ¡ndote 3 rutas diferentes para llegar a tu destino.

#### Etapa 3: Query Optimization (OptimizaciÃ³n)
El **Query Optimizer** elige el plan mÃ¡s eficiente basÃ¡ndose en:
- **EstadÃ­sticas de la tabla** (cuÃ¡ntos registros tiene)
- **Ãndices disponibles** (quÃ© "atajos" existen)
- **DistribuciÃ³n de datos** (quÃ© tan Ãºnicos son los valores)
- **Costo estimado** (cuÃ¡nto tardarÃ¡ cada plan)

**AnalogÃ­a**: Google Maps eligiendo la ruta mÃ¡s rÃ¡pida considerando trÃ¡fico, distancia y tipo de vÃ­as.

#### Etapa 4: Execution (EjecuciÃ³n)
La BD ejecuta el plan elegido y devuelve los resultados.

**Punto clave**: Tu trabajo como Data Engineer es entender quÃ© plan elige la BD y si es el Ã³ptimo.

---

### 2. Ãndices: Los "Atajos" de la Base de Datos

#### Â¿QuÃ© es un Ã­ndice?

Un **Ã­ndice** es una estructura de datos adicional que permite buscar registros sin leer toda la tabla.

**AnalogÃ­a perfecta**: Un Ã­ndice SQL es como el Ã­ndice al final de un libro de texto:
- Sin Ã­ndice: lees las 500 pÃ¡ginas para encontrar "Machine Learning"
- Con Ã­ndice: vas directamente al Ã­ndice, ves "Machine Learning - pÃ¡gina 234", y saltas ahÃ­

#### Â¿CÃ³mo funciona internamente?

Los Ã­ndices mÃ¡s comunes usan **Ã¡rboles B-Tree** (Balanced Tree):

```
Ãndice en columna 'edad':

            [50]
           /    \
        [25]    [75]
       /  \     /  \
    [10][35] [60][90]
```

Buscar `edad = 35`:
- Sin Ã­ndice: Lee 1,000,000 registros â†’ **1,000,000 operaciones**
- Con Ã­ndice: Lee 1 nodo raÃ­z + 1 nodo intermedio + 1 nodo hoja â†’ **3 operaciones**

**Â¡333,333 veces mÃ¡s rÃ¡pido!**

#### Tipos de Ã­ndices

**1. Ãndice Simple (Single-Column Index)**
```sql
CREATE INDEX idx_usuarios_email ON usuarios(email);
```
Acelera consultas que filtran por UNA columna:
```sql
SELECT * FROM usuarios WHERE email = 'juan@example.com';  -- âœ… Usa Ã­ndice
```

**2. Ãndice Compuesto (Multi-Column Index)**
```sql
CREATE INDEX idx_ventas_fecha_tienda ON ventas(fecha, tienda_id);
```
Acelera consultas que filtran por MÃšLTIPLES columnas en ese orden:
```sql
-- âœ… Usa Ã­ndice (fecha es la primera columna del Ã­ndice)
SELECT * FROM ventas WHERE fecha = '2024-01-15' AND tienda_id = 5;

-- âœ… Usa Ã­ndice parcialmente (solo la parte de fecha)
SELECT * FROM ventas WHERE fecha = '2024-01-15';

-- âŒ NO usa Ã­ndice (tienda_id no es la primera columna)
SELECT * FROM ventas WHERE tienda_id = 5;
```

**Regla de oro**: En Ã­ndices compuestos, el orden importa. Usa primero las columnas que filtras mÃ¡s seguido.

**3. Ãndice Ãšnico (Unique Index)**
```sql
CREATE UNIQUE INDEX idx_usuarios_email_unico ON usuarios(email);
```
Garantiza que no haya duplicados Y acelera bÃºsquedas:
```sql
-- âœ… Usa Ã­ndice + garantiza email Ãºnico
SELECT * FROM usuarios WHERE email = 'maria@example.com';
```

**Uso en Data Engineering**: Claves primarias siempre tienen Ã­ndice Ãºnico automÃ¡tico.

**4. Ãndice Parcial (Partial Index)**
```sql
CREATE INDEX idx_pedidos_pendientes
ON pedidos(fecha)
WHERE estado = 'pendiente';
```
Solo indexa registros que cumplen una condiciÃ³n. MÃ¡s pequeÃ±o y rÃ¡pido.

**Ejemplo real**: Si solo el 5% de tus pedidos estÃ¡n pendientes, Â¿por quÃ© indexar el 100%?

#### Â¿CuÃ¡ndo crear un Ã­ndice?

âœ… **SÃ crear Ã­ndice si**:
- La columna aparece frecuentemente en `WHERE`, `JOIN`, `ORDER BY`, `GROUP BY`
- La tabla tiene >10,000 registros
- La columna tiene alta cardinalidad (muchos valores Ãºnicos)
- La consulta es lenta (>1 segundo) y se ejecuta frecuentemente

âŒ **NO crear Ã­ndice si**:
- La tabla tiene <10,000 registros (full scan es rÃ¡pido)
- La columna tiene baja cardinalidad (ejemplo: columna `genero` con solo 'M'/'F')
- La tabla recibe muchas escrituras (`INSERT`/`UPDATE`) porque Ã­ndices ralentizan escrituras
- Ya existe un Ã­ndice compuesto que cubre esa columna

**AnalogÃ­a**: Crear Ã­ndices es como agregar seÃ±ales de trÃ¡fico. Muy pocas = te pierdes. Demasiadas = saturaciÃ³n y confusiÃ³n.

#### Costo de los Ã­ndices

Los Ã­ndices NO son gratis:

1. **Espacio en disco**: Un Ã­ndice puede ocupar 20-50% del tamaÃ±o de la tabla
2. **Escrituras mÃ¡s lentas**: Cada `INSERT`/`UPDATE`/`DELETE` debe actualizar todos los Ã­ndices
3. **Mantenimiento**: Ãndices pueden fragmentarse y necesitar reconstrucciÃ³n

**Regla prÃ¡ctica**: Una tabla puede tener 3-7 Ã­ndices. MÃ¡s de 10 Ã­ndices es sospechoso.

---

### 3. EXPLAIN: La RadiografÃ­a de tus Consultas

#### Â¿QuÃ© es EXPLAIN?

`EXPLAIN` te muestra el **plan de ejecuciÃ³n** que la base de datos eligiÃ³ para tu consulta.

**AnalogÃ­a**: Es como pedirle a Google Maps que te explique POR QUÃ‰ eligiÃ³ esa ruta en lugar de las otras.

#### EXPLAIN vs EXPLAIN ANALYZE

**EXPLAIN** (sin ejecutar):
```sql
EXPLAIN SELECT * FROM usuarios WHERE email = 'test@example.com';
```
- Muestra el plan **estimado** (predicciÃ³n)
- **NO ejecuta** la consulta
- Usa estadÃ­sticas de la tabla
- **RÃ¡pido**: Toma milisegundos

**EXPLAIN ANALYZE** (ejecuta de verdad):
```sql
EXPLAIN ANALYZE SELECT * FROM usuarios WHERE email = 'test@example.com';
```
- Muestra el plan **real** (lo que realmente pasÃ³)
- **SÃ ejecuta** la consulta (Â¡cuidado en producciÃ³n!)
- Incluye tiempos reales de ejecuciÃ³n
- **Lento**: Toma lo que tarde la consulta

**CuÃ¡ndo usar cada uno**:
- Desarrollo/Testing: `EXPLAIN ANALYZE` (quieres datos reales)
- ProducciÃ³n: `EXPLAIN` (no quieres ejecutar consultas peligrosas)

#### Interpretando EXPLAIN (PostgreSQL)

```sql
EXPLAIN SELECT * FROM usuarios WHERE edad > 25;
```

**Salida sin Ã­ndice**:
```
Seq Scan on usuarios  (cost=0.00..1808.00 rows=50000 width=200)
  Filter: (edad > 25)
```

**Lectura**:
- `Seq Scan`: Lectura secuencial (lee TODA la tabla, fila por fila)
- `cost=0.00..1808.00`: Costo estimado de 0 a 1808 unidades
- `rows=50000`: Estima que devolverÃ¡ 50,000 filas
- `width=200`: Cada fila ocupa ~200 bytes
- `Filter: (edad > 25)`: Filtra registros DESPUÃ‰S de leerlos

**Salida con Ã­ndice**:
```
Index Scan using idx_usuarios_edad on usuarios  (cost=0.29..1234.50 rows=50000 width=200)
  Index Cond: (edad > 25)
```

**Lectura**:
- `Index Scan`: Usa el Ã­ndice (Â¡mucho mejor!)
- `cost=0.29..1234.50`: **Costo menor** que Seq Scan
- `Index Cond: (edad > 25)`: Filtra usando el Ã­ndice (mÃ¡s eficiente)

**Tipos de escaneo de mejor a peor**:

1. **Index Only Scan** (â­â­â­â­â­): Lee SOLO el Ã­ndice, ni siquiera toca la tabla
   ```sql
   SELECT edad FROM usuarios WHERE edad > 25;  -- Solo pide 'edad' que estÃ¡ en el Ã­ndice
   ```

2. **Index Scan** (â­â­â­â­): Usa Ã­ndice para encontrar registros, luego lee la tabla
   ```sql
   SELECT * FROM usuarios WHERE edad > 25;  -- Necesita otras columnas de la tabla
   ```

3. **Bitmap Index Scan** (â­â­â­): Crea un "mapa" de dÃ³nde estÃ¡n los registros antes de leerlos
   ```sql
   SELECT * FROM usuarios WHERE edad > 25 OR ciudad = 'Madrid';  -- Combina Ã­ndices
   ```

4. **Seq Scan** (â­): Lee toda la tabla secuencialmente (lento para tablas grandes)
   ```sql
   SELECT * FROM usuarios;  -- Sin filtros, debe leer todo
   ```

#### EXPLAIN ANALYZE con mÃ©tricas reales (PostgreSQL)

```sql
EXPLAIN ANALYZE SELECT * FROM ventas WHERE fecha >= '2024-01-01';
```

**Salida**:
```
Index Scan using idx_ventas_fecha on ventas
  (cost=0.43..8523.67 rows=125000 width=120)
  (actual time=0.052..45.234 rows=128543 loops=1)
  Index Cond: (fecha >= '2024-01-01'::date)
Planning Time: 0.234 ms
Execution Time: 52.123 ms
```

**MÃ©tricas clave**:
- `actual time=0.052..45.234`: Tiempo real en **milisegundos**
  - `0.052 ms`: Tiempo hasta el primer registro
  - `45.234 ms`: Tiempo hasta el Ãºltimo registro
- `rows=128543`: DevolviÃ³ 128,543 filas (vs. estimado 125,000 â†’ buena estimaciÃ³n)
- `Planning Time: 0.234 ms`: Tiempo que tardÃ³ en generar el plan
- `Execution Time: 52.123 ms`: Tiempo total de ejecuciÃ³n real

**QuÃ© buscar**:
- âœ… **Execution Time < 100 ms**: Consulta rÃ¡pida
- âš ï¸ **Execution Time 100-1000 ms**: Consulta lenta, considera optimizar
- âŒ **Execution Time > 1000 ms**: Consulta muy lenta, DEBES optimizar

---

### 4. TÃ©cnicas de OptimizaciÃ³n de Consultas

#### TÃ©cnica 1: Seleccionar solo columnas necesarias

âŒ **MAL** (trae TODO):
```sql
SELECT * FROM usuarios;  -- Trae 50 columnas que no necesitas
```

âœ… **BIEN** (trae solo lo que necesitas):
```sql
SELECT id, nombre, email FROM usuarios;  -- Solo 3 columnas
```

**Por quÃ© importa**:
- Menos datos = menos tiempo de transferencia
- Puede permitir **Index Only Scan** si las columnas estÃ¡n en el Ã­ndice
- Reduce uso de red y memoria

**Impacto real**: En una tabla con 20 columnas, `SELECT *` puede ser 5-10x mÃ¡s lento que seleccionar 2 columnas.

#### TÃ©cnica 2: Filtrar lo antes posible

âŒ **MAL** (filtra en Python despuÃ©s):
```python
# Lee 10 millones de registros
df = pd.read_sql("SELECT * FROM ventas", conn)
# Filtra en memoria (lento)
df_2024 = df[df['fecha'] >= '2024-01-01']
```

âœ… **BIEN** (filtra en SQL):
```python
# Lee solo 500,000 registros relevantes
df = pd.read_sql(
    "SELECT * FROM ventas WHERE fecha >= '2024-01-01'",
    conn
)
```

**Por quÃ© importa**:
- SQL filtra antes de transferir datos
- Reduce uso de red y memoria
- Aprovecha Ã­ndices

#### TÃ©cnica 3: Usar LIMIT para exploraciÃ³n

âŒ **MAL** (cuando solo quieres ver datos):
```sql
SELECT * FROM logs_acceso;  -- Lee 50 millones de registros
```

âœ… **BIEN**:
```sql
SELECT * FROM logs_acceso LIMIT 100;  -- Lee solo 100 registros
```

**Uso en Data Engineering**: Cuando exploras una tabla nueva, SIEMPRE usa `LIMIT` primero.

#### TÃ©cnica 4: Evitar funciones en columnas del WHERE

âŒ **MAL** (no usa Ã­ndice):
```sql
-- Aplica UPPER() a CADA fila antes de comparar
SELECT * FROM usuarios WHERE UPPER(email) = 'TEST@EXAMPLE.COM';
```

âœ… **BIEN** (usa Ã­ndice):
```sql
-- Normaliza el valor que buscas, no la columna
SELECT * FROM usuarios WHERE email = LOWER('TEST@EXAMPLE.COM');
```

**Por quÃ©**: Funciones en columnas indexadas **desactivan el Ã­ndice**.

**Excepciones**: Ãndices funcionales (PostgreSQL):
```sql
CREATE INDEX idx_usuarios_email_upper ON usuarios(UPPER(email));
-- Ahora SÃ usarÃ¡ este Ã­ndice:
SELECT * FROM usuarios WHERE UPPER(email) = 'TEST@EXAMPLE.COM';
```

#### TÃ©cnica 5: JOINs eficientes

âŒ **MAL** (Cartesian Product):
```sql
SELECT *
FROM usuarios, pedidos
WHERE usuarios.ciudad = 'Madrid';  -- âŒ Olvida relacionar las tablas
```
Resultado: Si usuarios tiene 1000 filas y pedidos tiene 10,000 filas â†’ **10,000,000 filas** (explosiÃ³n combinatoria)

âœ… **BIEN**:
```sql
SELECT *
FROM usuarios u
INNER JOIN pedidos p ON u.id = p.usuario_id
WHERE u.ciudad = 'Madrid';
```

**Reglas de oro para JOINs**:

1. **Siempre especifica la condiciÃ³n de JOIN**:
   ```sql
   FROM tabla1 JOIN tabla2 ON tabla1.id = tabla2.tabla1_id
   ```

2. **Indexa las columnas de JOIN**:
   ```sql
   CREATE INDEX idx_pedidos_usuario ON pedidos(usuario_id);
   ```

3. **Filtra ANTES del JOIN cuando sea posible**:
   ```sql
   -- âœ… Filtra usuarios primero, luego JOIN
   SELECT *
   FROM (SELECT * FROM usuarios WHERE ciudad = 'Madrid') u
   INNER JOIN pedidos p ON u.id = p.usuario_id;
   ```

4. **Usa el tipo de JOIN correcto**:
   - `INNER JOIN`: Solo registros que coinciden en ambas tablas (mÃ¡s rÃ¡pido)
   - `LEFT JOIN`: Todos de la izquierda + coincidencias (mÃ¡s lento)
   - `FULL OUTER JOIN`: Todos de ambas tablas (mÃ¡s lento aÃºn)

#### TÃ©cnica 6: Evitar subconsultas correlacionadas

âŒ **MAL** (subconsulta ejecutada por CADA fila):
```sql
SELECT u.nombre,
       (SELECT COUNT(*) FROM pedidos p WHERE p.usuario_id = u.id) as total_pedidos
FROM usuarios u;
```
Si hay 10,000 usuarios â†’ ejecuta la subconsulta **10,000 veces**

âœ… **BIEN** (JOIN + agregaciÃ³n):
```sql
SELECT u.nombre, COUNT(p.id) as total_pedidos
FROM usuarios u
LEFT JOIN pedidos p ON u.id = p.usuario_id
GROUP BY u.id, u.nombre;
```
Ejecuta **una sola vez**, agrupa al final.

**Impacto**: Puede ser 100-1000x mÃ¡s rÃ¡pido.

#### TÃ©cnica 7: EXISTS vs IN para subconsultas

âŒ **LENTO** (con IN y muchos valores):
```sql
SELECT * FROM usuarios
WHERE id IN (SELECT usuario_id FROM pedidos WHERE fecha >= '2024-01-01');
```

âœ… **RÃPIDO** (con EXISTS):
```sql
SELECT * FROM usuarios u
WHERE EXISTS (
    SELECT 1 FROM pedidos p
    WHERE p.usuario_id = u.id AND p.fecha >= '2024-01-01'
);
```

**Por quÃ© EXISTS es mejor**:
- `IN`: Ejecuta la subconsulta completa, crea una lista, busca en ella
- `EXISTS`: Se detiene en cuanto encuentra UNA coincidencia (early exit)

**Regla**: Usa `EXISTS` cuando solo te importa si hay coincidencia (sÃ­/no). Usa `IN` cuando la subconsulta devuelve pocos valores (<1000).

#### TÃ©cnica 8: UNION vs UNION ALL

âŒ **LENTO** (elimina duplicados):
```sql
SELECT nombre FROM usuarios_activos
UNION
SELECT nombre FROM usuarios_inactivos;
```
`UNION`: Ordena y elimina duplicados (costoso)

âœ… **RÃPIDO** (si sabes que no hay duplicados):
```sql
SELECT nombre FROM usuarios_activos
UNION ALL
SELECT nombre FROM usuarios_inactivos;
```
`UNION ALL`: Solo concatena (rÃ¡pido)

**Regla**: Usa `UNION ALL` siempre que NO necesites eliminar duplicados.

---

### 5. Mantenimiento de Ãndices

Los Ã­ndices no son "crea y olvida". Necesitan mantenimiento.

#### Problema: FragmentaciÃ³n de Ã­ndices

Con el tiempo, `INSERT`/`UPDATE`/`DELETE` fragmentan los Ã­ndices:

**AnalogÃ­a**: Como un libro donde arrancas pÃ¡ginas y pegas pÃ¡ginas nuevas. Eventualmente, el Ã­ndice al final del libro ya no refleja correctamente dÃ³nde estÃ¡n los temas.

#### SoluciÃ³n: Reconstruir Ã­ndices

**PostgreSQL**:
```sql
-- Reconstruir un Ã­ndice especÃ­fico
REINDEX INDEX idx_usuarios_email;

-- Reconstruir todos los Ã­ndices de una tabla
REINDEX TABLE usuarios;
```

**CuÃ¡ndo hacerlo**:
- DespuÃ©s de cargas masivas de datos
- Si las consultas se vuelven lentas gradualmente
- Una vez por semana/mes en tablas con muchas escrituras

#### Actualizar estadÃ­sticas

La BD usa estadÃ­sticas para elegir planes de ejecuciÃ³n. Si estÃ¡n desactualizadas, elegirÃ¡ mal.

**PostgreSQL**:
```sql
ANALYZE usuarios;  -- Actualiza estadÃ­sticas de 'usuarios'
VACUUM ANALYZE;    -- Limpia espacio muerto + actualiza estadÃ­sticas
```

**MySQL**:
```sql
ANALYZE TABLE usuarios;
```

**CuÃ¡ndo hacerlo**:
- DespuÃ©s de cargar muchos datos nuevos
- Si `EXPLAIN` muestra estimaciones muy incorrectas (rows estimado â‰  rows real)
- AutomÃ¡tico en PostgreSQL (autovacuum), pero puedes forzarlo

---

## Aplicaciones en Data Engineering

### 1. OptimizaciÃ³n de Pipelines ETL

**Escenario**: Pipeline que extrae 10 millones de registros diarios.

**Problema**:
```python
# âŒ Lee TODO, filtra despuÃ©s
df = pd.read_sql("SELECT * FROM transacciones", conn)
df_hoy = df[df['fecha'] == date.today()]
```
Lee 10 millones de registros â†’ 5 GB de datos â†’ tarda 10 minutos

**SoluciÃ³n optimizada**:
```python
# âœ… Filtra en SQL, usa Ã­ndice
query = """
SELECT id, monto, cliente_id, fecha
FROM transacciones
WHERE fecha = CURRENT_DATE
"""
df_hoy = pd.read_sql(query, conn)
```
Lee 30,000 registros â†’ 15 MB de datos â†’ tarda 2 segundos

**TÃ©cnicas aplicadas**:
- Filtro en SQL (no en Pandas)
- Solo columnas necesarias
- Ãndice en columna `fecha`

**Impacto**: 300x mÃ¡s rÃ¡pido (10 min â†’ 2 seg)

### 2. OptimizaciÃ³n de Data Warehouses

**Escenario**: Dashboard de ventas ejecuta esta consulta cada minuto:

```sql
SELECT p.categoria, SUM(v.monto) as total_ventas
FROM ventas v
INNER JOIN productos p ON v.producto_id = p.id
WHERE v.fecha BETWEEN '2024-01-01' AND '2024-12-31'
GROUP BY p.categoria;
```

**Optimizaciones**:

1. **Ãndice compuesto**:
   ```sql
   CREATE INDEX idx_ventas_fecha_producto ON ventas(fecha, producto_id);
   ```

2. **Tabla materializada** (pre-calculada):
   ```sql
   CREATE MATERIALIZED VIEW ventas_por_categoria AS
   SELECT p.categoria, DATE_TRUNC('day', v.fecha) as fecha, SUM(v.monto) as total
   FROM ventas v
   INNER JOIN productos p ON v.producto_id = p.id
   GROUP BY p.categoria, DATE_TRUNC('day', v.fecha);

   CREATE INDEX idx_ventas_cat_fecha ON ventas_por_categoria(fecha);
   ```

3. **Consulta optimizada**:
   ```sql
   SELECT categoria, SUM(total) as total_ventas
   FROM ventas_por_categoria
   WHERE fecha BETWEEN '2024-01-01' AND '2024-12-31'
   GROUP BY categoria;
   ```

**Resultado**: Consulta que tardaba 8 segundos â†’ 0.05 segundos (160x mÃ¡s rÃ¡pida)

### 3. OptimizaciÃ³n de APIs de Datos

**Escenario**: API que devuelve productos filtrados por usuario.

**Sin optimizaciÃ³n**:
```sql
SELECT * FROM productos WHERE id IN (
    SELECT producto_id FROM favoritos WHERE usuario_id = 12345
);
```
Tarda 2.5 segundos â†’ usuarios abandonan

**Con optimizaciÃ³n**:
```sql
SELECT p.id, p.nombre, p.precio
FROM productos p
WHERE EXISTS (
    SELECT 1 FROM favoritos f
    WHERE f.producto_id = p.id AND f.usuario_id = 12345
);
```
Tarda 0.1 segundos â†’ experiencia fluida

**TÃ©cnicas aplicadas**:
- `EXISTS` en lugar de `IN`
- Solo columnas necesarias
- Ãndices en `favoritos(usuario_id, producto_id)`

---

## Errores Comunes

### Error 1: "MÃ¡s Ã­ndices = MÃ¡s rÃ¡pido"

âŒ **Falso**. Demasiados Ã­ndices ralentizan escrituras y confunden al optimizer.

**Escenario real**: Una tabla con 15 Ã­ndices donde cada `INSERT` tardaba 500 ms. Eliminando 8 Ã­ndices innecesarios â†’ `INSERT` en 50 ms.

**Regla**: 3-7 Ã­ndices por tabla es razonable. MÃ¡s de 10 es sospechoso.

### Error 2: No usar EXPLAIN antes de crear Ã­ndices

âŒ **Mal enfoque**: "Esta consulta es lenta, creo un Ã­ndice en todas las columnas del WHERE"

âœ… **Buen enfoque**:
1. Ejecuta `EXPLAIN ANALYZE`
2. Identifica el cuello de botella (Seq Scan, subconsulta lenta, JOIN pesado)
3. Crea el Ã­ndice especÃ­fico que resuelve ESE problema
4. Verifica con `EXPLAIN ANALYZE` que ahora usa el Ã­ndice

### Error 3: Crear Ã­ndices en columnas de baja cardinalidad

âŒ **InÃºtil**:
```sql
CREATE INDEX idx_usuarios_activo ON usuarios(activo);  -- Solo valores: true/false
```
Un Ã­ndice en una columna con 2 valores Ãºnicos no ayuda. La BD igual debe leer ~50% de la tabla.

**Regla**: Solo indexa columnas con alta cardinalidad (muchos valores Ãºnicos). Columnas con <100 valores Ãºnicos rara vez necesitan Ã­ndice.

### Error 4: Usar SELECT * en producciÃ³n

âŒ **Nunca en producciÃ³n**:
```sql
SELECT * FROM logs;  -- Puede devolver 50 columnas y 10 GB
```

âœ… **EspecÃ­fico**:
```sql
SELECT timestamp, level, message FROM logs WHERE timestamp >= NOW() - INTERVAL '1 hour';
```

### Error 5: No mantener estadÃ­sticas actualizadas

**SÃ­ntoma**: `EXPLAIN` dice "rows=100" pero la consulta devuelve 1,000,000 registros.

**Causa**: EstadÃ­sticas desactualizadas. La BD piensa que la tabla es pequeÃ±a cuando en realidad creciÃ³ 10,000x.

**SoluciÃ³n**:
```sql
ANALYZE tabla;  -- PostgreSQL
ANALYZE TABLE tabla;  -- MySQL
```

### Error 6: Ignorar el Query Plan

âŒ **Mal hÃ¡bito**: Escribir consulta, ejecutarla, si funciona â†’ listo.

âœ… **Buen hÃ¡bito**:
1. Escribe consulta
2. `EXPLAIN ANALYZE` en desarrollo
3. Verifica que usa Ã­ndices correctos
4. Si tarda >100 ms â†’ optimiza

---

## Checklist de Aprendizaje

Al final de este tema, deberÃ­as poder responder SÃ a todas estas preguntas:

### Conceptos BÃ¡sicos
- [ ] Â¿Puedo explicar quÃ© es un Ã­ndice y por quÃ© acelera las consultas?
- [ ] Â¿Entiendo la diferencia entre Seq Scan e Index Scan?
- [ ] Â¿SÃ© cuÃ¡ndo crear un Ã­ndice y cuÃ¡ndo NO crearlo?
- [ ] Â¿Puedo explicar quÃ© hace el Query Optimizer?

### EXPLAIN
- [ ] Â¿SÃ© usar `EXPLAIN` y `EXPLAIN ANALYZE`?
- [ ] Â¿Puedo interpretar el output de EXPLAIN (Seq Scan vs Index Scan)?
- [ ] Â¿Entiendo quÃ© significa "cost" y "rows"?
- [ ] Â¿Puedo identificar si una consulta estÃ¡ usando un Ã­ndice?

### Ãndices
- [ ] Â¿SÃ© crear Ã­ndices simples y compuestos?
- [ ] Â¿Entiendo que el orden de columnas importa en Ã­ndices compuestos?
- [ ] Â¿Puedo identificar cuÃ¡ndo un Ã­ndice NO ayuda (baja cardinalidad)?
- [ ] Â¿SÃ© que los Ã­ndices ralentizan escrituras?

### OptimizaciÃ³n
- [ ] Â¿Puedo optimizar una consulta lenta usando EXPLAIN?
- [ ] Â¿SÃ© cuÃ¡ndo usar `EXISTS` vs `IN`?
- [ ] Â¿Entiendo por quÃ© `SELECT *` es malo en producciÃ³n?
- [ ] Â¿Puedo evitar subconsultas correlacionadas?

### Mantenimiento
- [ ] Â¿SÃ© cuÃ¡ndo reconstruir Ã­ndices (REINDEX)?
- [ ] Â¿SÃ© cuÃ¡ndo actualizar estadÃ­sticas (ANALYZE)?
- [ ] Â¿Entiendo que los Ã­ndices necesitan mantenimiento?

### Data Engineering
- [ ] Â¿Puedo optimizar pipelines ETL filtrando en SQL?
- [ ] Â¿SÃ© cuÃ¡ndo usar tablas materializadas?
- [ ] Â¿Puedo diseÃ±ar Ã­ndices para un data warehouse?

---

## Resumen Ejecutivo

### Conceptos Clave

1. **Ãndices = Atajos**: Permiten buscar sin leer toda la tabla
2. **EXPLAIN = RadiografÃ­a**: Muestra cÃ³mo la BD ejecutarÃ¡ tu consulta
3. **Optimizar = Entender el plan**: Usa EXPLAIN para saber quÃ© optimizar
4. **No siempre mÃ¡s Ã­ndices = mejor**: Balance entre lecturas y escrituras
5. **Filtrar en SQL, no en cÃ³digo**: Reduce transferencia de datos

### Reglas de Oro

1. **Usa EXPLAIN** antes de crear Ã­ndices
2. **Indexa columnas** en WHERE, JOIN, ORDER BY, GROUP BY
3. **Evita SELECT *** en producciÃ³n
4. **Filtra lo antes posible** (en SQL, no en Python)
5. **MantÃ©n Ã­ndices** (REINDEX + ANALYZE periÃ³dicamente)
6. **3-7 Ã­ndices por tabla** es razonable
7. **Usa EXISTS** en lugar de IN para subconsultas grandes
8. **Evita funciones** en columnas indexadas del WHERE

### Prioridades de OptimizaciÃ³n

1. **Primero**: Verifica con EXPLAIN que la consulta usa Ã­ndices
2. **Segundo**: Crea Ã­ndices faltantes en columnas clave
3. **Tercero**: Reescribe consultas ineficientes (subconsultas correlacionadas, SELECT *)
4. **Cuarto**: Considera tablas materializadas para agregaciones pesadas

---

## PrÃ³ximos Pasos

1. **Lee los Ejemplos** (`02-EJEMPLOS.md`): VerÃ¡s casos reales de optimizaciÃ³n
2. **Practica los Ejercicios** (`03-EJERCICIOS.md`): 15 ejercicios progresivos
3. **Construye el Proyecto** (`04-proyecto-practico/`): Sistema de optimizaciÃ³n SQL con TDD

---

**Â¡EstÃ¡s listo para escribir SQL que escale a millones de registros!** ğŸš€

**Tiempo estimado de lectura**: 35-40 minutos
**Palabras**: ~4,200
---

## ğŸ§­ NavegaciÃ³n

â¬…ï¸ **Anterior**: [SQL Intermedio - Proyecto PrÃ¡ctico](../tema-2-sql-intermedio/04-proyecto-practico/README.md) | â¡ï¸ **Siguiente**: [02 Ejemplos](02-EJEMPLOS.md)
