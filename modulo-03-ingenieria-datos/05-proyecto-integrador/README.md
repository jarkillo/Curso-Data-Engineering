# Proyecto Integrador: Pipeline de AnÃ¡lisis de Noticias

Pipeline completo de datos con arquitectura Bronze/Silver/Gold para extracciÃ³n, transformaciÃ³n, validaciÃ³n y carga de noticias.

## ğŸ¯ Objetivos

- Implementar pipeline completo **ETL** con arquitectura **Bronze/Silver/Gold**
- **Extraer** datos desde API simulada
- **Transformar** datos con limpieza, normalizaciÃ³n y agregaciones
- **Validar** calidad de datos con Pandera
- **Cargar** datos en **Parquet** y **bases de datos relacionales**
- Aplicar **TDD** con >80% de cobertura
- Crear **CLI** para ejecuciÃ³n fÃ¡cil

## ğŸ“š Arquitectura Bronze/Silver/Gold

### Bronze (Raw Data)
- Datos crudos tal como llegan de la fuente
- Sin transformaciones
- Guardado en Parquet para trazabilidad
- Columnas: `id`, `title`, `content`, `author`, `published_date`, `source`, `category`, `url`

### Silver (Cleaned Data)
- Datos limpios y normalizados
- Validados contra esquema
- Tipos de datos correctos
- Registros invÃ¡lidos eliminados
- Columnas en espaÃ±ol, fechas como datetime
- MÃ©tricas bÃ¡sicas agregadas (longitud de contenido/tÃ­tulo)

### Gold (Analytics-Ready Data)
- Datos agregados y optimizados para anÃ¡lisis
- Agregaciones por fuente y categorÃ­a
- EstadÃ­sticas descriptivas
- Cargado en BD para consultas rÃ¡pidas

## ğŸ“ Estructura del Proyecto

```
05-proyecto-integrador/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extractor.py              # ExtracciÃ³n de noticias
â”‚   â”œâ”€â”€ transformador_bronze.py   # Bronze â†’ Silver
â”‚   â”œâ”€â”€ transformador_silver.py   # Silver â†’ Gold
â”‚   â”œâ”€â”€ validador.py              # ValidaciÃ³n de calidad
â”‚   â”œâ”€â”€ cargador.py               # Carga en Parquet/BD
â”‚   â”œâ”€â”€ pipeline.py               # Orquestador principal
â”‚   â””â”€â”€ cli.py                    # Interface de lÃ­nea de comandos
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py               # Fixtures compartidos
â”‚   â”œâ”€â”€ test_extractor.py         # 11 tests
â”‚   â”œâ”€â”€ test_transformador_bronze.py  # 17 tests
â”‚   â”œâ”€â”€ test_transformador_silver.py  # 15 tests
â”‚   â”œâ”€â”€ test_validador.py         # 12 tests
â”‚   â”œâ”€â”€ test_cargador.py          # 14 tests
â”‚   â””â”€â”€ test_pipeline.py          # 3 tests
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ bronze/                   # Datos crudos
â”‚   â”œâ”€â”€ silver/                   # Datos limpios
â”‚   â””â”€â”€ gold/                     # Datos agregados
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ .gitignore
```

## ğŸš€ InstalaciÃ³n

```bash
# Activar entorno virtual
cd modulo-03-ingenieria-datos/05-proyecto-integrador

# En Windows:
..\..\..\venv\Scripts\Activate.ps1

# Instalar dependencias
pip install -r requirements.txt
```

## âœ… Ejecutar Tests

```bash
# Ejecutar todos los tests
pytest -v

# Con cobertura
pytest --cov=src --cov-report=html --cov-report=term

# Solo un mÃ³dulo
pytest tests/test_pipeline.py -v
```

**Resultados**:
- âœ… **72 tests pasando** (100% success rate)
- âœ… **83% cobertura** (objetivo: â‰¥80%)

## ğŸ® Uso del Pipeline

### OpciÃ³n 1: CLI (Recomendado)

```bash
# Uso bÃ¡sico
python -m src.cli

# Personalizar parÃ¡metros
python -m src.cli --num-noticias 500 --db-url sqlite:///mi_base.db --output-dir mi_data

# Ver ayuda
python -m src.cli --help
```

**ParÃ¡metros CLI**:
- `--num-noticias`: NÃºmero de noticias a generar (default: 100)
- `--db-url`: URL de conexiÃ³n a BD (default: `sqlite:///noticias.db`)
- `--output-dir`: Directorio de salida (default: `data`)
- `--guardar-intermedios/--no-guardar-intermedios`: Guardar capas intermedias (default: True)

### OpciÃ³n 2: Desde Python

```python
from sqlalchemy import create_engine
from pathlib import Path
from src.pipeline import ejecutar_pipeline_completo

# Configurar
engine = create_engine("sqlite:///noticias.db")
directorio = Path("data")

# Ejecutar pipeline
resultado = ejecutar_pipeline_completo(
    num_noticias=100,
    engine=engine,
    directorio_salida=directorio,
    guardar_intermedios=True
)

# Ver resultados
print(f"Ã‰xito: {resultado['exito']}")
print(f"Registros extraÃ­dos: {resultado['registros_extraidos']}")
print(f"Registros Silver: {resultado['registros_silver']}")
print(f"Registros Gold: {resultado['registros_gold']}")
```

## ğŸ“¦ MÃ³dulos Implementados

### 1. Extractor (`extractor.py`)

Extrae noticias desde API simulada y las guarda en capa Bronze.

```python
from src.extractor import extraer_noticias_api_simulada, guardar_en_bronze
from pathlib import Path

# Generar 50 noticias simuladas
df_bronze = extraer_noticias_api_simulada(num_noticias=50)

# Guardar en Bronze
guardar_en_bronze(df_bronze, Path("data/bronze/noticias.parquet"))
```

### 2. Transformador Bronze (`transformador_bronze.py`)

Transforma datos crudos a datos limpios (Bronze â†’ Silver).

```python
from src.transformador_bronze import transformar_bronze_a_silver

# Transformar
df_silver = transformar_bronze_a_silver(df_bronze)

# Ahora tiene:
# - Columnas en espaÃ±ol
# - Fechas como datetime
# - Textos limpios
# - Registros invÃ¡lidos eliminados
# - MÃ©tricas de longitud
```

### 3. Transformador Silver (`transformador_silver.py`)

Transforma datos limpios a datos analÃ­ticos (Silver â†’ Gold).

```python
from src.transformador_silver import transformar_silver_a_gold

# Transformar
datos_gold = transformar_silver_a_gold(df_silver)

# Retorna dict con:
# - datos_gold["por_fuente"]: DataFrame agregado por fuente
# - datos_gold["por_categoria"]: DataFrame agregado por categorÃ­a
# - datos_gold["estadisticas"]: Dict con estadÃ­sticas descriptivas
```

### 4. Validador (`validador.py`)

Valida calidad de datos con Pandera.

```python
from src.validador import generar_reporte_calidad

# Generar reporte de calidad
reporte = generar_reporte_calidad(df_silver)

print(f"Esquema vÃ¡lido: {reporte['esquema_valido']}")
print(f"Duplicados: {reporte['duplicados']['total']}")
print(f"Longitudes vÃ¡lidas (contenido): {reporte['longitudes_validas']['contenido']}")
```

### 5. Cargador (`cargador.py`)

Carga datos en Parquet y bases de datos.

```python
from src.cargador import cargar_a_parquet, cargar_a_base_datos
from pathlib import Path

# Cargar en Parquet
cargar_a_parquet(df_gold, Path("data/gold/noticias_gold.parquet"))

# Cargar en base de datos
num_cargados = cargar_a_base_datos(
    df_gold,
    engine,
    tabla="noticias_gold",
    if_exists="replace"
)
```

## ğŸ§ª Cobertura de Tests

MÃ³dulo | Tests | Cobertura
-------|-------|----------
`extractor.py` | 11 | 100%
`transformador_bronze.py` | 17 | 100%
`transformador_silver.py` | 15 | 100%
`validador.py` | 12 | 100%
`cargador.py` | 14 | 94%
`pipeline.py` | 3 | 100%
**TOTAL** | **72** | **83%**

## ğŸ“ Conceptos Aplicados

### Arquitectura de Datos
- **Bronze/Silver/Gold** (Medallion Architecture)
- SeparaciÃ³n de capas por nivel de procesamiento
- Trazabilidad completa de datos

### Calidad de Datos
- ValidaciÃ³n de esquemas con **Pandera**
- DetecciÃ³n de duplicados
- ValidaciÃ³n de rangos
- Reporte completo de calidad

### Buenas PrÃ¡cticas
- **TDD** (Test-Driven Development)
- Type hints en todas las funciones
- Docstrings con ejemplos
- Logging estructurado
- Manejo robusto de errores
- Cobertura >80%

### Data Engineering
- ETL completo
- Procesamiento por lotes
- Persistencia dual (Parquet + BD)
- Pipeline idempotente
- MÃ©tricas de ejecuciÃ³n

## ğŸ”§ TecnologÃ­as Utilizadas

- **Python 3.13+**
- **Pandas**: ManipulaciÃ³n de datos
- **Pandera**: ValidaciÃ³n de esquemas
- **SQLAlchemy**: ORM y conexiÃ³n a BD
- **PyArrow**: Formato Parquet
- **Click**: CLI
- **Faker**: GeneraciÃ³n de datos sintÃ©ticos
- **pytest**: Testing

## ğŸ“Š Ejemplo de Salida

```bash
$ python -m src.cli --num-noticias 100

============================================================
Pipeline de AnÃ¡lisis de Noticias
============================================================
Noticias: 100
Base de datos: sqlite:///noticias.db
Directorio salida: data
============================================================

â–¶ Ejecutando pipeline...
2025-11-11 15:30:00 - INFO - === Iniciando pipeline completo ===
2025-11-11 15:30:00 - INFO - Extrayendo 100 noticias...
2025-11-11 15:30:00 - INFO - Bronze guardado en data\bronze\noticias.parquet
2025-11-11 15:30:01 - INFO - Transformando Bronze â†’ Silver...
2025-11-11 15:30:01 - INFO - Silver guardado in data\silver\noticias.parquet
2025-11-11 15:30:01 - INFO - Validando calidad de datos...
2025-11-11 15:30:01 - INFO - Esquema vÃ¡lido: True
2025-11-11 15:30:01 - INFO - Transformando Silver â†’ Gold...
2025-11-11 15:30:01 - INFO - Cargando datos Gold...
2025-11-11 15:30:02 - INFO - === Pipeline completado exitosamente ===

âœ… Pipeline completado exitosamente

ğŸ“Š MÃ©tricas:
  - Registros extraÃ­dos: 100
  - Registros Silver: 98
  - Registros Gold: 5

ğŸ” Calidad de datos:
  - Esquema vÃ¡lido: âœ…
  - Duplicados: 0

ğŸ“ Datos guardados en: data
```

## ğŸ› Troubleshooting

### Error: "ModuleNotFoundError: No module named 'pandera'"
**SoluciÃ³n**: Instalar dependencias
```bash
pip install -r requirements.txt
```

### Error: "FileNotFoundError: [Errno 2] No such file or directory: 'data/...'"
**SoluciÃ³n**: Los directorios se crean automÃ¡ticamente. Verificar permisos de escritura.

### Error: Base de datos bloqueada
**SoluciÃ³n**: Cerrar todas las conexiones antes de ejecutar nuevamente:
```python
engine.dispose()
```

## ğŸ“š Recursos Adicionales

- [Pandas Documentation](https://pandas.pydata.org/docs/)
- [Pandera Validation](https://pandera.readthedocs.io/)
- [SQLAlchemy Tutorial](https://docs.sqlalchemy.org/)
- [Parquet Format](https://parquet.apache.org/)

## ğŸ¯ PrÃ³ximos Pasos

1. Conectar a API real de noticias (NewsAPI, Guardian, etc.)
2. Implementar procesamiento incremental
3. Agregar anÃ¡lisis de sentimiento
4. Crear dashboard con visualizaciones
5. Desplegar en producciÃ³n (Airflow, Prefect)

---

**Proyecto completado** âœ…
**Tests**: 72/72 pasando
**Cobertura**: 83%
**Calidad**: Excelente

**Â¡Ã‰xito con tu aprendizaje de Data Engineering!** ğŸš€ğŸ“Š
