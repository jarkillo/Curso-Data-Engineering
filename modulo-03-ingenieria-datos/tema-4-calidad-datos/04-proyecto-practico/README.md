# Proyecto PrÃ¡ctico: Framework de Calidad de Datos

**MÃ³dulo 3 - Tema 4**: Calidad de Datos
**VersiÃ³n**: 1.0.0
**MetodologÃ­a**: Test-Driven Development (TDD)

---

## ğŸ“‹ DescripciÃ³n

Framework completo para asegurar la calidad de datos en pipelines ETL. Incluye validaciÃ³n de esquemas, detecciÃ³n de duplicados (exactos y fuzzy), identificaciÃ³n de outliers y data profiling completo.

### Contexto de Negocio

Sistema de calidad de datos reutilizable que:
- Valida esquemas de datos con reglas personalizadas
- Detecta y elimina duplicados exactos y similares
- Identifica y trata outliers con mÃºltiples mÃ©todos
- Genera perfiles de calidad automÃ¡ticos
- Produce reportes ejecutivos de calidad

---

## ğŸ—ï¸ Estructura del Proyecto

```
04-proyecto-practico/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ validador_esquema.py         # 7 funciones de validaciÃ³n
â”‚   â”œâ”€â”€ detector_duplicados.py       # 5 funciones de detecciÃ³n
â”‚   â”œâ”€â”€ detector_outliers.py         # 6 funciones de outliers
â”‚   â””â”€â”€ profiler.py                  # 4 funciones de profiling
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                  # Fixtures compartidas
â”‚   â”œâ”€â”€ test_validador_esquema.py    # 15 tests
â”‚   â”œâ”€â”€ test_detector_duplicados.py  # 12 tests
â”‚   â”œâ”€â”€ test_detector_outliers.py    # 18 tests
â”‚   â””â”€â”€ test_profiler.py             # 12 tests
â”œâ”€â”€ datos/
â”‚   â””â”€â”€ transacciones_raw.csv        # Datos de ejemplo
â”œâ”€â”€ ejemplos/
â”‚   â””â”€â”€ ejemplo_pipeline_completo.py # Ejemplo de uso
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pytest.ini
â””â”€â”€ README.md
```

---

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En Linux/Mac:
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Ejecutar Tests

```bash
# Todos los tests
pytest tests/ -v

# Con cobertura
pytest tests/ --cov=src --cov-report=term-missing --cov-report=html

# Tests especÃ­ficos
pytest tests/test_validador_esquema.py -v

# Ver cobertura en HTML
# Abrir: htmlcov/index.html
```

### 3. Uso BÃ¡sico

```python
import pandas as pd
from src.validador_esquema import validar_tipos_columnas, validar_rangos_numericos
from src.detector_duplicados import detectar_duplicados_exactos, detectar_duplicados_fuzzy
from src.detector_outliers import detectar_outliers_iqr, tratar_outliers
from src.profiler import generar_perfil_basico, generar_reporte_calidad

# Cargar datos
df = pd.read_csv('datos/transacciones_raw.csv')

# Validar esquema
esquema = {'monto': 'float', 'fecha': 'str', 'cliente_id': 'int'}
es_valido, errores = validar_tipos_columnas(df, esquema)

# Detectar duplicados
duplicados = detectar_duplicados_exactos(df, ['cliente_id', 'fecha'])

# Detectar outliers
outliers = detectar_outliers_iqr(df, 'monto')

# Generar reporte
reporte = generar_reporte_calidad(df)
print(reporte)
```

---

## ğŸ“š MÃ³dulos

### 1. validador_esquema.py

ValidaciÃ³n de esquemas y reglas de negocio.

**Funciones**:

```python
def validar_tipos_columnas(df: pd.DataFrame, esquema: Dict[str, str]) -> Tuple[bool, List[str]]
```
Valida que columnas tengan los tipos esperados.

```python
def validar_rangos_numericos(df: pd.DataFrame, rangos: Dict[str, Tuple[float, float]]) -> Dict
```
Valida que valores numÃ©ricos estÃ©n en rangos vÃ¡lidos.

```python
def validar_valores_unicos(df: pd.DataFrame, columnas: List[str]) -> Tuple[bool, Dict]
```
Verifica que columnas especificadas no tengan duplicados.

```python
def validar_valores_permitidos(df: pd.DataFrame, reglas: Dict[str, List]) -> Dict
```
Valida que valores estÃ©n en listas permitidas (enums).

```python
def validar_nulls_permitidos(df: pd.DataFrame, columnas_requeridas: List[str]) -> Dict
```
Verifica que columnas requeridas no tengan valores nulos.

```python
def validar_esquema_completo(df: pd.DataFrame, configuracion: Dict) -> Tuple[bool, Dict]
```
Ejecuta todas las validaciones de forma integrada.

```python
def generar_reporte_validacion(resultados_validacion: Dict) -> str
```
Genera reporte legible de resultados de validaciÃ³n.

### 2. detector_duplicados.py

DetecciÃ³n y manejo de duplicados exactos y fuzzy.

**Funciones**:

```python
def detectar_duplicados_exactos(df: pd.DataFrame, columnas: List[str]) -> pd.Series
```
Identifica duplicados exactos en columnas especificadas.

```python
def detectar_duplicados_fuzzy(df: pd.DataFrame, columna: str, umbral: int = 85) -> pd.DataFrame
```
Encuentra valores similares usando fuzzy matching.

```python
def eliminar_duplicados_con_estrategia(df: pd.DataFrame, columnas: List[str], estrategia: str = 'primero') -> pd.DataFrame
```
Elimina duplicados segÃºn estrategia (primero/ultimo/mas_completo).

```python
def marcar_duplicados_probables(df: pd.DataFrame, columnas: List[str]) -> pd.DataFrame
```
AÃ±ade columna booleana marcando duplicados.

```python
def generar_reporte_duplicados(df: pd.DataFrame, columnas: List[str]) -> Dict
```
Genera estadÃ­sticas detalladas de duplicados.

### 3. detector_outliers.py

IdentificaciÃ³n y tratamiento de valores atÃ­picos.

**Funciones**:

```python
def detectar_outliers_iqr(df: pd.DataFrame, columna: str) -> Tuple[pd.Series, Dict]
```
Detecta outliers usando mÃ©todo IQR.

```python
def detectar_outliers_zscore(df: pd.DataFrame, columna: str, umbral: float = 3.0) -> Tuple[pd.Series, Dict]
```
Detecta outliers usando Z-score.

```python
def detectar_outliers_isolation_forest(df: pd.DataFrame, columnas: List[str], contamination: float = 0.1) -> pd.Series
```
Detecta outliers multivariados con Isolation Forest.

```python
def tratar_outliers(df: pd.DataFrame, columna: str, outliers: pd.Series, metodo: str = 'eliminar') -> pd.DataFrame
```
Aplica tratamiento a outliers (eliminar/imputar/capping).

```python
def visualizar_outliers(df: pd.DataFrame, columna: str, archivo_salida: str) -> None
```
Genera grÃ¡ficos de anÃ¡lisis de outliers.

```python
def generar_reporte_outliers(df: pd.DataFrame, columnas_numericas: List[str]) -> Dict
```
EstadÃ­sticas de outliers por columna.

### 4. profiler.py

AnÃ¡lisis y profiling de calidad de datos.

**Funciones**:

```python
def generar_perfil_basico(df: pd.DataFrame) -> Dict
```
EstadÃ­sticas descriptivas bÃ¡sicas por columna.

```python
def generar_perfil_completo(df: pd.DataFrame, archivo_salida: str = None) -> Dict
```
AnÃ¡lisis completo de calidad con ydata-profiling opcional.

```python
def detectar_correlaciones(df: pd.DataFrame, umbral: float = 0.7) -> pd.DataFrame
```
Identifica variables altamente correlacionadas.

```python
def generar_reporte_calidad(df: pd.DataFrame) -> Dict
```
Dashboard completo con todas las mÃ©tricas de calidad.

---

## ğŸ§ª Testing

### Cobertura de Tests

- **validador_esquema.py**: 15 tests (~95% cobertura)
- **detector_duplicados.py**: 12 tests (~92% cobertura)
- **detector_outliers.py**: 18 tests (~90% cobertura)
- **profiler.py**: 12 tests (~88% cobertura)

**Total**: 57 tests, >90% cobertura global

### Convenciones de Tests

- Nombres de funciones: `test_<funcion>_<caso>`
- Fixtures compartidas en `conftest.py`
- Datos de prueba generados programÃ¡ticamente
- Tests parametrizados para casos mÃºltiples
- VerificaciÃ³n de excepciones con `pytest.raises`

### Ejemplos de Tests

```python
def test_validar_tipos_columnas_tipos_validos():
    """Verifica validaciÃ³n correcta con tipos vÃ¡lidos."""
    df = pd.DataFrame({
        'id': [1, 2, 3],
        'nombre': ['A', 'B', 'C'],
        'precio': [10.5, 20.3, 15.7]
    })

    esquema = {'id': 'int', 'nombre': 'str', 'precio': 'float'}
    es_valido, errores = validar_tipos_columnas(df, esquema)

    assert es_valido is True
    assert len(errores) == 0


def test_detectar_outliers_iqr_con_outliers():
    """Verifica detecciÃ³n correcta de outliers con IQR."""
    df = pd.DataFrame({'valores': [1, 2, 3, 4, 5, 100]})

    outliers, stats = detectar_outliers_iqr(df, 'valores')

    assert outliers.sum() == 1
    assert outliers.iloc[-1] is True
```

---

## ğŸ“Š Datos de Ejemplo

### transacciones_raw.csv

Dataset con problemas de calidad conocidos para testing:

- **Registros**: 1000 transacciones
- **Problemas incluidos**:
  - 50 registros duplicados exactos
  - 20 registros con valores similares (fuzzy)
  - 30 outliers en montos
  - 15% de valores nulos
  - 10 registros con fechas futuras (invÃ¡lidas)
  - 5 registros con tipos incorrectos

**Columnas**:
- `transaccion_id`: ID Ãºnico (int)
- `cliente_id`: ID del cliente (int)
- `fecha`: Fecha de transacciÃ³n (str YYYY-MM-DD)
- `monto`: Monto en euros (float)
- `categoria`: CategorÃ­a de transacciÃ³n (str)
- `estado`: Estado del pago (str)

---

## ğŸ”§ ConfiguraciÃ³n

### pytest.ini

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_functions = test_*
addopts =
    -v
    --strict-markers
    --cov=src
    --cov-report=term-missing
    --cov-report=html
    --cov-fail-under=85
```

### requirements.txt

```
pandas>=2.0.0
numpy>=1.24.0
pandera>=0.18.0
rapidfuzz>=3.0.0
ydata-profiling>=4.5.0
scikit-learn>=1.3.0
matplotlib>=3.7.0
pytest>=7.4.0
pytest-cov>=4.1.0
```

---

## ğŸ¯ Casos de Uso

### Caso 1: ValidaciÃ³n RÃ¡pida

```python
from src.validador_esquema import validar_esquema_completo

config = {
    'tipos': {'id': 'int', 'precio': 'float'},
    'rangos': {'precio': (0, 1000)},
    'columnas_requeridas': ['id', 'nombre'],
    'valores_permitidos': {'categoria': ['A', 'B', 'C']}
}

es_valido, reporte = validar_esquema_completo(df, config)
```

### Caso 2: Limpieza de Duplicados

```python
from src.detector_duplicados import eliminar_duplicados_con_estrategia

# Mantener el registro mÃ¡s completo
df_limpio = eliminar_duplicados_con_estrategia(
    df,
    columnas=['email'],
    estrategia='mas_completo'
)
```

### Caso 3: Pipeline Completo

```python
# 1. Validar
es_valido, errores = validar_esquema_completo(df, config)
if not es_valido:
    raise ValueError(f"Datos invÃ¡lidos: {errores}")

# 2. Duplicados
df = eliminar_duplicados_con_estrategia(df, ['id'])

# 3. Outliers
for col in ['monto', 'cantidad']:
    outliers, _ = detectar_outliers_iqr(df, col)
    df = tratar_outliers(df, col, outliers, metodo='capping')

# 4. Reporte
reporte = generar_reporte_calidad(df)
print(reporte)
```

---

## ğŸ“ˆ MÃ©tricas de Calidad

El framework genera las siguientes mÃ©tricas:

### Completitud
- Porcentaje de valores no nulos por columna
- Registros completamente llenos vs incompletos

### Unicidad
- Porcentaje de duplicados
- Grupos de registros duplicados
- Similitud fuzzy entre registros

### Validez
- Cumplimiento de tipos de datos
- Valores dentro de rangos vÃ¡lidos
- Conformidad con reglas de negocio

### Consistencia
- Outliers estadÃ­sticos
- Valores anÃ³malos multivariados
- Correlaciones inesperadas

---

## ğŸš¨ Manejo de Errores

Todas las funciones siguen estas convenciones:

- **ValidaciÃ³n de inputs**: Verificar que DataFrame no estÃ© vacÃ­o
- **Excepciones especÃ­ficas**: `ValueError`, `TypeError`, `KeyError`
- **Mensajes claros**: Indicar exactamente quÃ© fallÃ³ y por quÃ©
- **Sin fallos silenciosos**: Siempre lanzar excepciÃ³n en errores

```python
def ejemplo_funcion(df: pd.DataFrame, columna: str) -> pd.Series:
    """Ejemplo con validaciones."""
    if df.empty:
        raise ValueError("DataFrame estÃ¡ vacÃ­o")

    if columna not in df.columns:
        raise KeyError(f"Columna '{columna}' no existe en DataFrame")

    if not pd.api.types.is_numeric_dtype(df[columna]):
        raise TypeError(f"Columna '{columna}' debe ser numÃ©rica")

    # LÃ³gica de la funciÃ³n...
```

---

## ğŸ” Consideraciones de Seguridad

- **ValidaciÃ³n de inputs**: Nunca confiar en datos externos
- **SanitizaciÃ³n**: Limpiar caracteres especiales en columnas de texto
- **LÃ­mites de tamaÃ±o**: Verificar que DataFrames no excedan memoria disponible
- **Logging**: Registrar todas las operaciones de calidad
- **Trazabilidad**: Mantener histÃ³rico de transformaciones

---

## ğŸ“ Mejores PrÃ¡cticas

1. **Validar temprano**: Fallar rÃ¡pido si datos son invÃ¡lidos
2. **Documentar reglas**: Externalizar reglas de calidad en configuraciÃ³n
3. **Reportar claramente**: Generar reportes comprensibles para negocio
4. **Testear exhaustivamente**: Cobertura > 85%
5. **Versionar esquemas**: Mantener historial de cambios en validaciones

---

## ğŸ“ Licencia

Este proyecto es parte del Master en IngenierÃ­a de Datos.
Uso educativo exclusivamente.

---

## ğŸ‘¥ Contribuciones

Para contribuir:

1. Crear rama feature: `git checkout -b feature/nueva-funcionalidad`
2. Escribir tests primero (TDD)
3. Implementar funcionalidad
4. Asegurar cobertura > 85%
5. Actualizar documentaciÃ³n
6. Crear Pull Request

---

## ğŸ“ Soporte

Para preguntas o problemas:
- Revisar ejemplos en `ejemplos/`
- Consultar tests en `tests/`
- Ver documentaciÃ³n en archivos fuente

---

*Ãšltima actualizaciÃ³n: 2025-10-30*
---

## ğŸ§­ NavegaciÃ³n

â¬…ï¸ **Anterior**: [03 Ejercicios](../03-EJERCICIOS.md) | â¡ï¸ **Siguiente**: [Formatos Modernos - 01 Teoria](../../tema-5-formatos-modernos/01-TEORIA.md)
