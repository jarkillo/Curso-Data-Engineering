# Tema 2: ExtracciÃ³n de Datos

**MÃ³dulo**: 3 - IngenierÃ­a de Datos Core
**DuraciÃ³n estimada**: 1-2 semanas
**Nivel**: Intermedio
**Prerrequisitos**: Tema 1 (Conceptos ETL)

---

## ğŸ¯ Objetivos de Aprendizaje

Al completar este tema, serÃ¡s capaz de:

1. **Extraer datos de archivos** (CSV, JSON, Excel) manejando encodings y estructuras complejas
2. **Consumir APIs REST** con autenticaciÃ³n, paginaciÃ³n y manejo robusto de errores
3. **Realizar web scraping Ã©tico** respetando robots.txt y rate limits
4. **Implementar reintentos automÃ¡ticos** con backoff exponencial
5. **Consolidar datos de mÃºltiples fuentes** en pipelines robustos
6. **Aplicar logging y monitoreo** en procesos de extracciÃ³n

---

## ğŸ“š Contenido del Tema

### ğŸ“– Material TeÃ³rico

#### [01-TEORIA.md](01-TEORIA.md) (~6,500 palabras, 45-60 min)
**Contenido**:
- **Parte 1: Archivos**
  - CSV (encoding, delimitadores, headers)
  - JSON (plano, nested, JSON Lines)
  - Excel (mÃºltiples sheets)
- **Parte 2: APIs REST**
  - Conceptos fundamentales (endpoints, mÃ©todos HTTP, headers)
  - AutenticaciÃ³n (API keys, Bearer tokens, Basic Auth)
  - Rate limiting y paginaciÃ³n
  - Manejo de errores y reintentos
- **Parte 3: Web Scraping**
  - Ã‰tica del scraping (robots.txt, User-Agent)
  - Beautiful Soup basics
  - ExtracciÃ³n de tablas HTML
  - Contenido dinÃ¡mico vs estÃ¡tico
- **Parte 4: Logging y Monitoreo**
- **Parte 5: 5 Errores Comunes y CÃ³mo Evitarlos**

**CaracterÃ­sticas**:
- âœ… Explicaciones desde cero (sin asumir conocimientos previos)
- âœ… AnalogÃ­as del mundo real para conceptos tÃ©cnicos
- âœ… Buenas prÃ¡cticas de Data Engineering
- âœ… Ã‰nfasis en seguridad y Ã©tica

---

#### [02-EJEMPLOS.md](02-EJEMPLOS.md) (5 ejemplos, 60-90 min)
**Ejemplos trabajados paso a paso**:

1. **CSV con Encoding ProblemÃ¡tico** (â­ BÃ¡sico)
   - Detectar encoding automÃ¡ticamente con `chardet`
   - Leer archivos Latin-1, UTF-8-BOM
   - FunciÃ³n reutilizable

2. **JSON Nested con MÃºltiples Niveles** (â­â­ Intermedio)
   - Aplanar estructuras complejas con `json_normalize()`
   - Extraer listas anidadas en tablas separadas
   - Calcular campos derivados

3. **API Paginada con Reintentos AutomÃ¡ticos** (â­â­ Intermedio)
   - Implementar reintentos con backoff exponencial
   - PaginaciÃ³n offset-based completa
   - Rate limiting y logging

4. **Scraping BÃ¡sico con Beautiful Soup** (â­ BÃ¡sico)
   - Parsear HTML y extraer elementos
   - Scraping de tablas
   - Limpiar y estructurar datos

5. **ExtracciÃ³n Multi-Fuente** (â­â­â­ Avanzado)
   - Consolidar CSV + API + Web scraping
   - Merge de mÃºltiples DataFrames
   - Calcular KPIs y generar reportes

**Todas las soluciones son ejecutables y testeadas**.

---

#### [03-EJERCICIOS.md](03-EJERCICIOS.md) (15 ejercicios, 4-8 horas)
**Ejercicios graduados con soluciones completas**:

**BÃ¡sicos (1-5)** - â­
- DetecciÃ³n automÃ¡tica de encoding
- Lectura de JSON Lines
- MÃºltiples hojas de Excel
- Limpieza de CSV con valores nulos
- ValidaciÃ³n de estructura

**Intermedios (6-10)** - â­â­
- API con autenticaciÃ³n Bearer
- PaginaciÃ³n offset-based
- Manejo de rate limit 429
- Scraping de tablas HTML
- Verificar robots.txt

**Avanzados (11-15)** - â­â­â­
- Pipeline multi-fuente completo
- ExtracciÃ³n con logging robusto
- API oculta vs scraping
- Sistema de cachÃ©
- Pipeline orquestado end-to-end

**Incluye**: Tabla de autoevaluaciÃ³n y criterios de Ã©xito

---

### ğŸ’» Proyecto PrÃ¡ctico (4-6 dÃ­as)

#### [04-proyecto-practico/](04-proyecto-practico/) - Sistema de ExtracciÃ³n Multi-Fuente
**Contexto**: Construir un sistema profesional de extracciÃ³n de datos para anÃ¡lisis de mercado.

**Arquitectura** (TDD estricto):
```
src/
â”œâ”€â”€ extractor_archivos.py    (6 funciones - CSV, JSON, Excel)
â”œâ”€â”€ extractor_apis.py         (5 funciones - REST, auth, paginaciÃ³n)
â”œâ”€â”€ extractor_web.py          (4 funciones - Scraping Ã©tico)
â”œâ”€â”€ gestor_extracciones.py    (4 funciones - OrquestaciÃ³n, logging)
â””â”€â”€ validadores.py            (5 funciones - ValidaciÃ³n de datos)

tests/
â”œâ”€â”€ test_extractor_archivos.py    (~15 tests)
â”œâ”€â”€ test_extractor_apis.py        (~15 tests)
â”œâ”€â”€ test_extractor_web.py         (~12 tests)
â”œâ”€â”€ test_gestor_extracciones.py   (~12 tests)
â””â”€â”€ test_validadores.py           (~15 tests)
```

**CaracterÃ­sticas**:
- âœ… 70+ tests unitarios (TDD)
- âœ… >85% cobertura de cÃ³digo
- âœ… Logging completo
- âœ… Manejo robusto de errores
- âœ… Datos de ejemplo incluidos
- âœ… ConfiguraciÃ³n completa (pytest, requirements)

---

## ğŸ—ºï¸ Ruta de Aprendizaje Recomendada

### OpciÃ³n A: Secuencial Completo (Recomendado)
**DuraciÃ³n**: 1-2 semanas

```
DÃ­a 1-2: Leer 01-TEORIA.md + 02-EJEMPLOS.md
         Ejecutar todos los ejemplos

DÃ­a 3:   Hacer ejercicios 1-5 (bÃ¡sicos)
         Revisar soluciones

DÃ­a 4:   Hacer ejercicios 6-10 (intermedios)
         Revisar soluciones

DÃ­a 5:   Hacer ejercicios 11-15 (avanzados)
         Revisar soluciones

DÃ­a 6-10: Proyecto prÃ¡ctico TDD
          Implementar los 5 mÃ³dulos
          Escribir tests (>85% cobertura)
```

### OpciÃ³n B: Solo TeorÃ­a y Ejemplos (RÃ¡pido)
**DuraciÃ³n**: 2-3 dÃ­as

```
DÃ­a 1: Leer 01-TEORIA.md (45-60 min)
       Ejecutar 5 ejemplos de 02-EJEMPLOS.md (2-3 horas)

DÃ­a 2: Hacer ejercicios seleccionados: 1, 3, 6, 9, 11, 15 (4 horas)

DÃ­a 3: Revisar cÃ³digo del proyecto prÃ¡ctico (2 horas)
```

### OpciÃ³n C: Solo Proyecto (Experiencia Previa)
**DuraciÃ³n**: 4-6 dÃ­as

Si ya tienes experiencia con extracciÃ³n de datos:
```
DÃ­a 1: Leer 01-TEORIA.md (enfoque en buenas prÃ¡cticas)
       Revisar 02-EJEMPLOS.md como referencia

DÃ­a 2-6: Implementar proyecto prÃ¡ctico completo con TDD
```

---

## ğŸ› ï¸ Requisitos TÃ©cnicos

### LibrerÃ­as Necesarias
```bash
pip install requests beautifulsoup4 pandas openpyxl chardet pytest pytest-cov
```

### Versiones Recomendadas
- Python: 3.11+
- requests: >=2.32.4
- beautifulsoup4: >=4.12.0
- pandas: >=2.1.0
- openpyxl: >=3.1.0
- chardet: >=5.2.0

### Herramientas Opcionales
- Postman/Insomnia (para probar APIs)
- DB Browser for SQLite (para inspeccionar datos)
- Jupyter Notebook (para experimentar)

---

## ğŸ“Š EvaluaciÃ³n y Calidad

### RevisiÃ³n PedagÃ³gica
- **CalificaciÃ³n**: 9.5/10 â­â­â­â­â­
- **ProgresiÃ³n**: Sin saltos conceptuales
- **Claridad**: AnalogÃ­as efectivas
- **Aplicabilidad**: Casos reales de Data Engineering
- Ver [REVISION_PEDAGOGICA.md](REVISION_PEDAGOGICA.md) para detalles

### Criterios de Ã‰xito

Has completado exitosamente este tema si:
- âœ… Puedes extraer datos de CSV con cualquier encoding
- âœ… Puedes consumir APIs REST con paginaciÃ³n y reintentos
- âœ… Puedes hacer scraping respetando Ã©tica y rate limits
- âœ… Puedes consolidar datos de mÃºltiples fuentes
- âœ… Implementas logging en tus extracciones
- âœ… Manejas errores de forma robusta

**ValidaciÃ³n prÃ¡ctica**: Completa el ejercicio 15 (Pipeline completo) exitosamente.

---

## ğŸ”— Recursos Adicionales

### DocumentaciÃ³n Oficial
- [requests](https://requests.readthedocs.io/) - HTTP library
- [Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - Web scraping
- [pandas](https://pandas.pydata.org/docs/) - Data manipulation
- [chardet](https://chardet.readthedocs.io/) - Encoding detection

### APIs PÃºblicas para Practicar
- [JSONPlaceholder](https://jsonplaceholder.typicode.com/) - API de prueba gratuita
- [OpenWeatherMap](https://openweathermap.org/api) - API de clima
- [REST Countries](https://restcountries.com/) - Datos de paÃ­ses

### Ã‰tica de Web Scraping
- [robots.txt checker](https://en.ryte.com/free-tools/robots-txt/)
- [Web Scraping Best Practices](https://www.scrapehero.com/web-scraping-best-practices/)

### Lecturas Complementarias
- "Web Scraping with Python" - Ryan Mitchell
- "RESTful Web APIs" - Leonard Richardson

---

## ğŸ’¡ Tips para el Ã‰xito

### Durante el Estudio
1. **Ejecuta todo el cÃ³digo**: No solo leas, prueba cada ejemplo
2. **Modifica los ejemplos**: Cambia parÃ¡metros, aÃ±ade funcionalidad
3. **Usa debugging**: Pon breakpoints, inspecciona variables
4. **Toma notas**: Documenta patrones que encuentres Ãºtiles

### Durante los Ejercicios
1. **Lee el contexto**: Entender el problema es clave
2. **Intenta primero**: Dedica 15-30 min antes de ver la soluciÃ³n
3. **Compara soluciones**: Aprende de las diferencias con tu cÃ³digo
4. **Refactoriza**: Mejora tu cÃ³digo despuÃ©s de ver la soluciÃ³n

### Durante el Proyecto
1. **TDD estricto**: Test primero, cÃ³digo despuÃ©s
2. **Commits pequeÃ±os**: Commitea cada funciÃ³n que completes
3. **Refactoriza**: Limpia cÃ³digo despuÃ©s de que los tests pasen
4. **Documenta**: Escribe docstrings para todas las funciones

---

## ğŸš¨ Troubleshooting

### Problema: UnicodeDecodeError al leer CSV
**SoluciÃ³n**: Usa `chardet` para detectar el encoding automÃ¡ticamente
```python
import chardet
with open('file.csv', 'rb') as f:
    encoding = chardet.detect(f.read())['encoding']
df = pd.read_csv('file.csv', encoding=encoding)
```

### Problema: Error 429 (Too Many Requests) en API
**SoluciÃ³n**: Implementa rate limiting con `time.sleep()`
```python
import time
response = requests.get(url)
time.sleep(1)  # 1 segundo entre peticiones
```

### Problema: Beautiful Soup no encuentra elementos
**SoluciÃ³n**: Verifica el HTML real (puede ser diferente al esperado)
```python
print(soup.prettify())  # Ver estructura HTML
```

### Problema: Tests fallan en proyecto
**SoluciÃ³n**: Verifica que estÃ¡s en el directorio correcto
```bash
cd 04-proyecto-practico
pytest -v
```

---

## ğŸ“ Soporte

### Â¿Dudas sobre conceptos?
- Revisa la secciÃ³n correspondiente en 01-TEORIA.md
- Busca en "Errores Comunes" (Parte 5)
- Consulta las soluciones de ejercicios similares

### Â¿Problemas tÃ©cnicos?
- Verifica versiones de librerÃ­as
- Consulta la secciÃ³n Troubleshooting arriba
- Revisa logs de error completos

### Â¿Necesitas mÃ¡s prÃ¡ctica?
- Repite ejercicios modificando el contexto
- Busca APIs pÃºblicas adicionales para practicar
- Implementa variaciones del proyecto prÃ¡ctico

---

## âœ… Checklist de Completitud

- [ ] LeÃ­ 01-TEORIA.md completamente
- [ ] EjecutÃ© los 5 ejemplos de 02-EJEMPLOS.md
- [ ] CompletÃ© ejercicios bÃ¡sicos (1-5)
- [ ] CompletÃ© ejercicios intermedios (6-10)
- [ ] CompletÃ© ejercicios avanzados (11-15)
- [ ] ImplementÃ© proyecto prÃ¡ctico con TDD
- [ ] Tests del proyecto >85% cobertura
- [ ] Todos los tests pasan
- [ ] CÃ³digo sin errores de linting
- [ ] DocumentÃ© funciones principales

**Si completaste 9+ items**: Â¡Felicidades! Dominas extracciÃ³n de datos ğŸ‰

---

## ğŸ”œ PrÃ³ximos Pasos

DespuÃ©s de completar este tema:

1. **Tema 3: TransformaciÃ³n con Pandas** (modulo-03-ingenieria-datos/tema-3-transformacion/)
   - DataFrames avanzados
   - Operaciones: filter, map, apply, groupby
   - Merge, join, concat
   - Limpieza y preparaciÃ³n de datos

2. **Tema 4: Calidad de Datos** (modulo-03-ingenieria-datos/tema-4-calidad/)
   - ValidaciÃ³n de esquemas
   - DetecciÃ³n de duplicados y outliers
   - Data profiling
   - Frameworks de calidad

3. **Proyecto Integrador del MÃ³dulo 3**
   - Pipeline ETL completo end-to-end
   - Integra extracciÃ³n, transformaciÃ³n y calidad
   - Arquitectura Bronze/Silver/Gold

---

**Â¡Ã‰xito en tu aprendizaje de extracciÃ³n de datos!** ğŸš€ğŸ“Š

---

**Ãšltima actualizaciÃ³n**: 2025-10-30
**VersiÃ³n**: 1.0.0
**Issue Linear**: [JAR-265](https://linear.app/jarko/issue/JAR-265)
**CalificaciÃ³n PedagÃ³gica**: 9.5/10 â­â­â­â­â­
