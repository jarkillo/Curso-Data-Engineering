# Proyecto PrÃ¡ctico: Pipeline de TransformaciÃ³n con Pandas

**MÃ³dulo 3 - Tema 3**: TransformaciÃ³n de Datos
**VersiÃ³n**: 1.0.0
**MetodologÃ­a**: Test-Driven Development (TDD)

---

## ğŸ“‹ DescripciÃ³n

Proyecto prÃ¡ctico completo que implementa un pipeline de transformaciÃ³n de datos de ventas utilizando Pandas. Incluye mÃ³dulos para limpieza, transformaciÃ³n, agregaciÃ³n y validaciÃ³n de datos.

### Contexto de Negocio

Sistema de procesamiento de datos de ventas que:
- Limpia datos crudos con problemas de calidad
- Aplica transformaciones y enriquecimientos
- Genera mÃ©tricas y agregaciones de negocio
- Valida esquemas y calidad de datos

---

## ğŸ—ï¸ Estructura del Proyecto

```
04-proyecto-practico/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ limpiador.py              # 6 funciones de limpieza
â”‚   â”œâ”€â”€ transformador_pandas.py   # 8 funciones de transformaciÃ³n
â”‚   â”œâ”€â”€ agregador.py              # 5 funciones de agregaciÃ³n
â”‚   â””â”€â”€ validador_schema.py       # 4 funciones de validaciÃ³n
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_limpiador.py         # 40 tests
â”‚   â”œâ”€â”€ test_transformador_pandas.py  # 50 tests
â”‚   â”œâ”€â”€ test_agregador.py         # 30 tests
â”‚   â””â”€â”€ test_validador_schema.py  # 40 tests
â”œâ”€â”€ datos/
â”‚   â””â”€â”€ ventas_raw.csv           # Datos de ejemplo
â”œâ”€â”€ ejemplos/
â”‚   â””â”€â”€ (scripts de ejemplo)
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸš€ Inicio RÃ¡pido

### 1. InstalaciÃ³n

```bash
# Crear entorno virtual
python -m venv venv

# Activar entorno virtual
# En Windows:
venv\Scripts\activate
# En Linux/Mac:
source venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt
```

### 2. Ejecutar Tests

```bash
# Todos los tests
pytest tests/ -v

# Con cobertura
pytest tests/ --cov=src --cov-report=term-missing --cov-report=html

# Tests especÃ­ficos
pytest tests/test_limpiador.py -v
```

### 3. Uso BÃ¡sico

```python
import pandas as pd
from src.limpiador import eliminar_duplicados_completos, normalizar_texto
from src.transformador_pandas import calcular_columnas_derivadas
from src.agregador import agrupar_con_multiples_metricas
from src.validador_schema import generar_reporte_calidad

# Cargar datos
df = pd.read_csv('datos/ventas_raw.csv')

# Limpiar
df = eliminar_duplicados_completos(df)
df = normalizar_texto(df, ['producto', 'region'], 'title')

# Transformar
formulas = {'total': 'cantidad * precio'}
df = calcular_columnas_derivadas(df, formulas)

# Agregar
resultado = agrupar_con_multiples_metricas(
    df,
    ['region'],
    {'total': ['sum', 'mean', 'count']}
)

# Validar
reporte = generar_reporte_calidad(df)
print(f"Datos vÃ¡lidos: {reporte['es_valido']}")
```

---

## ğŸ“¦ MÃ³dulos

### 1. `limpiador.py` - Limpieza de Datos

**Funciones**:

| FunciÃ³n | DescripciÃ³n |
|---------|-------------|
| `eliminar_duplicados_completos()` | Elimina filas completamente duplicadas |
| `eliminar_filas_sin_id()` | Elimina filas sin ID vÃ¡lido |
| `rellenar_valores_nulos()` | Rellena nulos con estrategias personalizadas |
| `normalizar_texto()` | Normaliza texto (mayÃºsculas, trim, etc.) |
| `validar_rangos_numericos()` | Valida valores dentro de rangos |
| `eliminar_filas_con_errores_criticos()` | Elimina filas con errores en columnas crÃ­ticas |

**Ejemplo**:

```python
from src.limpiador import rellenar_valores_nulos, normalizar_texto

# Rellenar nulos
estrategias = {
    'edad': 'mean',
    'nombre': 'Desconocido',
    'ciudad': 'No Especificada'
}
df_limpio = rellenar_valores_nulos(df, estrategias)

# Normalizar texto
df_limpio = normalizar_texto(df_limpio, ['nombre', 'ciudad'], 'title')
```

---

### 2. `transformador_pandas.py` - Transformaciones

**Funciones**:

| FunciÃ³n | DescripciÃ³n |
|---------|-------------|
| `calcular_columnas_derivadas()` | Calcula columnas usando expresiones eval |
| `aplicar_transformacion_por_fila()` | Aplica funciÃ³n a cada fila |
| `categorizar_valores()` | Categoriza basado en condiciones |
| `agregar_metricas_por_grupo()` | Agrega mÃ©tricas por grupo (transform) |
| `aplicar_ventana_movil()` | Calcula rolling windows |
| `crear_columna_condicional()` | Crea columna con mÃºltiples condiciones |
| `extraer_informacion_temporal()` | Extrae componentes de fechas |
| `aplicar_transformacion_condicional_compleja()` | Aplica funciÃ³n que usa fila completa |

**Ejemplo**:

```python
from src.transformador_pandas import categorizar_valores, aplicar_ventana_movil

# Categorizar
categorias = {
    'Bajo': lambda x: x < 100,
    'Medio': lambda x: 100 <= x < 500,
    'Alto': lambda x: x >= 500
}
df = categorizar_valores(df, 'precio', 'rango_precio', categorias)

# Media mÃ³vil
df = aplicar_ventana_movil(df, 'ventas', ventana=7, operacion='mean')
```

---

### 3. `agregador.py` - Agregaciones

**Funciones**:

| FunciÃ³n | DescripciÃ³n |
|---------|-------------|
| `agrupar_con_multiples_metricas()` | GroupBy con mÃºltiples agregaciones |
| `calcular_top_n_por_grupo()` | Top N registros por grupo |
| `crear_tabla_pivot()` | Crea tabla dinÃ¡mica |
| `calcular_porcentajes_por_grupo()` | Calcula % respecto al total del grupo |
| `generar_resumen_estadistico()` | Genera estadÃ­sticas completas por grupo |

**Ejemplo**:

```python
from src.agregador import agrupar_con_multiples_metricas, calcular_top_n_por_grupo

# AgregaciÃ³n mÃºltiple
resumen = agrupar_con_multiples_metricas(
    df,
    ['region', 'categoria'],
    {
        'ventas': ['sum', 'mean', 'count'],
        'cantidad': ['sum']
    }
)

# Top 5 por regiÃ³n
top_ventas = calcular_top_n_por_grupo(df, 'region', 'ventas', n=5)
```

---

### 4. `validador_schema.py` - ValidaciÃ³n

**Funciones**:

| FunciÃ³n | DescripciÃ³n |
|---------|-------------|
| `validar_columnas_requeridas()` | Valida presencia de columnas |
| `validar_tipos_de_datos()` | Valida tipos de datos esperados |
| `validar_completitud_datos()` | Valida porcentaje de completitud |
| `generar_reporte_calidad()` | Genera reporte completo de calidad |

**Ejemplo**:

```python
from src.validador_schema import generar_reporte_calidad

# Generar reporte completo
reporte = generar_reporte_calidad(
    df,
    columnas_requeridas=['id', 'fecha', 'producto', 'cantidad', 'precio'],
    tipos_esperados={
        'id': 'int',
        'fecha': 'datetime',
        'cantidad': 'int',
        'precio': 'float'
    },
    umbral_completitud=0.95
)

print(f"âœ… Datos vÃ¡lidos: {reporte['es_valido']}")
print(f"ğŸ“Š Filas: {reporte['total_filas']}")
print(f"ğŸ“Š Columnas: {reporte['total_columnas']}")
print(f"âš ï¸  Nulos: {reporte['porcentaje_nulos_total']}%")
print(f"ğŸ”„ Duplicados: {reporte['duplicados_completos']}")
```

---

## ğŸ§ª Testing

### EstadÃ­sticas de Tests

- **Total de tests**: 130+
- **Cobertura**: 98%
- **MÃ³dulos testeados**: 4
- **LÃ­neas de cÃ³digo**: 306
- **LÃ­neas sin cubrir**: 7

### Ejecutar Tests

```bash
# Todos los tests con output verbose
pytest tests/ -v

# Con cobertura HTML
pytest tests/ --cov=src --cov-report=html
# Abrir: htmlcov/index.html

# Tests especÃ­ficos por mÃ³dulo
pytest tests/test_limpiador.py -v
pytest tests/test_transformador_pandas.py -v
pytest tests/test_agregador.py -v
pytest tests/test_validador_schema.py -v

# Filtrar por nombre de test
pytest tests/ -k "test_valida" -v

# Mostrar prints durante tests
pytest tests/ -v -s

# Parar en el primer fallo
pytest tests/ -x
```

---

## ğŸ“Š MÃ©tricas de Calidad

### Cobertura por MÃ³dulo

| MÃ³dulo | LÃ­neas | Cobertura |
|--------|--------|-----------|
| `limpiador.py` | 69 | 100% âœ… |
| `transformador_pandas.py` | 108 | 98% âœ… |
| `agregador.py` | 59 | 93% âœ… |
| `validador_schema.py` | 69 | 99% âœ… |
| **TOTAL** | **306** | **98%** âœ… |

### Validaciones

âœ… Todos los tests pasan
âœ… Cobertura > 85% (objetivo: 85%)
âœ… Sin errores de linting
âœ… CÃ³digo documentado con docstrings
âœ… Tipado explÃ­cito en todas las funciones
âœ… Siguiendo convenciones PEP 8

---

## ğŸ’¡ Ejemplos de Uso

### Pipeline Completo

```python
import pandas as pd
from src.limpiador import (
    eliminar_duplicados_completos,
    eliminar_filas_sin_id,
    rellenar_valores_nulos,
    normalizar_texto,
    validar_rangos_numericos
)
from src.transformador_pandas import (
    calcular_columnas_derivadas,
    extraer_informacion_temporal
)
from src.agregador import generar_resumen_estadistico
from src.validador_schema import generar_reporte_calidad

# 1. CARGAR DATOS
df = pd.read_csv('datos/ventas_raw.csv')
print(f"Datos cargados: {len(df)} filas")

# 2. LIMPIAR
df = eliminar_duplicados_completos(df)
df = eliminar_filas_sin_id(df, 'id')

estrategias_nulos = {
    'cliente': 'Desconocido',
    'precio': 'median',
    'descuento': 0
}
df = rellenar_valores_nulos(df, estrategias_nulos)
df = normalizar_texto(df, ['producto', 'region', 'vendedor'], 'title')

rangos = {
    'cantidad': (0, 1000),
    'precio': (0, 10000),
    'descuento': (0, 100)
}
df = validar_rangos_numericos(df, rangos)

print(f"Datos limpios: {len(df)} filas")

# 3. TRANSFORMAR
df['fecha'] = pd.to_datetime(df['fecha'])
df = extraer_informacion_temporal(df, 'fecha', ['year', 'month', 'quarter'])

formulas = {
    'subtotal': 'cantidad * precio',
    'descuento_monto': 'subtotal * (descuento / 100)',
    'total': 'subtotal - descuento_monto'
}
df = calcular_columnas_derivadas(df, formulas)

# 4. AGREGAR
resumen = generar_resumen_estadistico(df, 'region', 'total')
print("\nResumen por regiÃ³n:")
print(resumen)

# 5. VALIDAR
reporte = generar_reporte_calidad(
    df,
    columnas_requeridas=['id', 'fecha', 'producto', 'total'],
    tipos_esperados={'id': 'int', 'total': 'float'},
    umbral_completitud=0.95
)

print(f"\nâœ… Pipeline completado")
print(f"   - Datos vÃ¡lidos: {reporte['es_valido']}")
print(f"   - Filas procesadas: {reporte['total_filas']}")
print(f"   - Completitud: {100 - reporte['porcentaje_nulos_total']}%")
```

---

## ğŸ”§ Troubleshooting

### Problema: Tests fallan con "Module not found"

**SoluciÃ³n**:
```bash
# AsegÃºrate de estar en el directorio correcto
cd modulo-03-ingenieria-datos/tema-3-transformacion/04-proyecto-practico

# Instala el paquete en modo desarrollo
pip install -e .
```

### Problema: Error con pandas version

**SoluciÃ³n**:
```bash
# Actualizar pandas
pip install --upgrade pandas>=2.1.0
```

### Problema: Cobertura no se genera

**SoluciÃ³n**:
```bash
# Reinstalar pytest-cov
pip install --force-reinstall pytest-cov
```

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n

- [Pandas Official Docs](https://pandas.pydata.org/docs/)
- [Pytest Documentation](https://docs.pytest.org/)
- [Python Type Hints](https://docs.python.org/3/library/typing.html)

### Conceptos Relacionados

- **TeorÃ­a**: Ver `01-TEORIA.md` para conceptos de transformaciÃ³n con Pandas
- **Ejemplos**: Ver `02-EJEMPLOS.md` para mÃ¡s ejemplos prÃ¡cticos
- **Ejercicios**: Ver `03-EJERCICIOS.md` para practicar

---

## ğŸ¤ ContribuciÃ³n

Este es un proyecto educativo. Para mejoras:

1. AsegÃºrate de que todos los tests pasen
2. MantÃ©n la cobertura >85%
3. Documenta las funciones con docstrings
4. Sigue las convenciones de cÃ³digo del proyecto
5. AÃ±ade tests para nuevas funciones

---

## ğŸ“ Notas de Desarrollo

### Decisiones de DiseÃ±o

1. **Funciones puras**: Las funciones no modifican el DataFrame original, siempre devuelven uno nuevo
2. **Tipado explÃ­cito**: Todas las funciones tienen type hints
3. **Validaciones robustas**: Todas las funciones validan inputs y lanzan errores claros
4. **DocumentaciÃ³n completa**: Cada funciÃ³n tiene docstring con ejemplos
5. **Testing exhaustivo**: Cada funciÃ³n tiene mÃºltiples tests (casos normales y edge cases)

### Convenciones

- **Nombres de funciones**: snake_case
- **Nombres de variables**: snake_case
- **Nombres de constantes**: UPPER_CASE
- **Imports**: Ordenados (estÃ¡ndar, externos, internos)
- **LÃ­nea mÃ¡xima**: 100 caracteres
- **Docstrings**: Google style

---

## ğŸ“œ Licencia

Material educativo de cÃ³digo abierto para aprendizaje personal.

---

## âœï¸ Autor

**Proyecto PrÃ¡ctico del MÃ³dulo 3 - Tema 3**
Master en IngenierÃ­a de Datos
Fecha: 2025-10-30

---

**Â¡Happy coding! ğŸš€**
