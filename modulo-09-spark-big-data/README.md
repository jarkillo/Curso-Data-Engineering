# MÃ³dulo 9: Apache Spark y Big Data

**Objetivo**: Dominar Apache Spark para procesamiento distribuido de grandes volÃºmenes de datos, incluyendo batch processing, SQL analytics y streaming en tiempo real.

---

## ğŸ“‹ Contenido del MÃ³dulo

| Tema | Estado | DescripciÃ³n |
|------|--------|-------------|
| **Tema 1**: IntroducciÃ³n a Spark | ğŸš§ En desarrollo | RDDs, DataFrames, transformaciones, acciones |
| **Tema 2**: Spark SQL y OptimizaciÃ³n | ğŸ“‹ Planificado | Catalyst, particionamiento, caching |
| **Tema 3**: Spark Streaming | ğŸ“‹ Planificado | Structured Streaming, Kafka, windowing |

---

## ğŸ¯ Objetivos de Aprendizaje

Al completar este mÃ³dulo serÃ¡s capaz de:

### Tema 1: IntroducciÃ³n a Spark
- âœ… Entender la arquitectura distribuida de Spark
- âœ… Trabajar con RDDs, DataFrames y Datasets
- âœ… Aplicar transformaciones y acciones
- âœ… Comprender lazy evaluation y DAG
- âœ… Ejecutar jobs en modo local y cluster

### Tema 2: Spark SQL y OptimizaciÃ³n
- â¬œ Escribir queries SQL sobre DataFrames
- â¬œ Entender el Catalyst Optimizer
- â¬œ Aplicar particionamiento efectivo
- â¬œ Usar caching y persistencia
- â¬œ Optimizar joins y shuffles

### Tema 3: Spark Streaming
- â¬œ Implementar Structured Streaming
- â¬œ Trabajar con ventanas de tiempo (windowing)
- â¬œ Integrar Kafka con Spark
- â¬œ Manejar late data y watermarks

---

## ğŸ—ï¸ Requisitos Previos

- **MÃ³dulos completados**:
  - MÃ³dulo 1: Fundamentos de Python
  - MÃ³dulo 3: IngenierÃ­a de Datos Core (ETL/Pandas)
  - MÃ³dulo 8: Data Warehousing (recomendado)

- **Conocimientos**:
  - Python intermedio
  - SQL bÃ¡sico
  - Conceptos de ETL

- **Software**:
  - Docker Desktop
  - Python 3.11+
  - Java 11+ (para Spark)

---

## ğŸš€ InstalaciÃ³n

### OpciÃ³n 1: Docker (Recomendado)

```bash
# Usar imagen oficial de Spark
docker run -it --rm \
  -p 4040:4040 \
  -v $(pwd):/app \
  apache/spark:3.5.0-python3 \
  /opt/spark/bin/pyspark

# O usar Jupyter con PySpark
docker run -it --rm \
  -p 8888:8888 \
  -p 4040:4040 \
  -v $(pwd):/home/jovyan/work \
  jupyter/pyspark-notebook
```

### OpciÃ³n 2: InstalaciÃ³n Local

```bash
# Instalar Java 11
# Windows: descargar de adoptium.net
# Mac: brew install openjdk@11
# Linux: sudo apt install openjdk-11-jdk

# Instalar PySpark
pip install pyspark==3.5.0

# Verificar instalaciÃ³n
pyspark --version
```

---

## ğŸ“Š Arquitectura de Spark

```
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           Driver Program            â”‚
                    â”‚  (SparkContext / SparkSession)      â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚         Cluster Manager             â”‚
                    â”‚   (Standalone / YARN / Kubernetes)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                           â”‚                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Worker Node    â”‚     â”‚     Worker Node       â”‚   â”‚     Worker Node       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚     â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚   â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚   â”‚ Executor  â”‚   â”‚     â”‚   â”‚ Executor  â”‚       â”‚   â”‚   â”‚ Executor  â”‚       â”‚
â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”‚   â”‚     â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”‚       â”‚   â”‚   â”‚  â”Œâ”€â”€â”€â”€â”€â”  â”‚       â”‚
â”‚   â”‚  â”‚Task â”‚  â”‚   â”‚     â”‚   â”‚  â”‚Task â”‚  â”‚       â”‚   â”‚   â”‚  â”‚Task â”‚  â”‚       â”‚
â”‚   â”‚  â””â”€â”€â”€â”€â”€â”˜  â”‚   â”‚     â”‚   â”‚  â””â”€â”€â”€â”€â”€â”˜  â”‚       â”‚   â”‚   â”‚  â””â”€â”€â”€â”€â”€â”˜  â”‚       â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚     â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“š Recursos Adicionales

- [Apache Spark Documentation](https://spark.apache.org/docs/latest/)
- [PySpark API Reference](https://spark.apache.org/docs/latest/api/python/)
- [Learning Spark, 2nd Edition](https://www.oreilly.com/library/view/learning-spark-2nd/9781492050049/)
- [Spark: The Definitive Guide](https://www.oreilly.com/library/view/spark-the-definitive/9781491912201/)

---

## ğŸ“ Changelog

### v0.1.0 (En desarrollo)
- ğŸš§ Tema 1: IntroducciÃ³n a Spark
- ğŸ“‹ Tema 2: Planificado
- ğŸ“‹ Tema 3: Planificado

---

**Siguiente paso**: [Tema 1: IntroducciÃ³n a Spark](tema-1-introduccion/)
