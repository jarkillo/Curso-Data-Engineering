# Proyecto PrÃ¡ctico: Data Warehouse con Star Schema

ImplementaciÃ³n completa de un Data Warehouse con modelado dimensional Star Schema, incluyendo dimensiones slowly changing (SCD Type 2), validaciones de calidad de datos, y queries analÃ­ticos OLAP.

---

## ğŸ¯ Objetivos del Proyecto

Al completar este proyecto, habrÃ¡s aprendido a:

1. **DiseÃ±ar y implementar un Star Schema** - El patrÃ³n mÃ¡s comÃºn en Data Warehousing
2. **Aplicar SCD Type 2** - Rastrear cambios histÃ³ricos en dimensiones
3. **Validar calidad de datos** - Antes de cargar al DWH
4. **Crear queries OLAP** - Drill-down, roll-up, slice-and-dice
5. **Construir un pipeline ETL completo** - De generaciÃ³n a anÃ¡lisis

---

## ğŸ“š Conceptos Clave

### Star Schema (Esquema en Estrella)

**Â¿QuÃ© es?** Un diseÃ±o de base de datos donde una tabla central de **hechos** (transacciones, eventos) estÃ¡ rodeada por tablas de **dimensiones** (contexto: quiÃ©n, quÃ©, cuÃ¡ndo, dÃ³nde).

**AnalogÃ­a:** Imagina una estrella:
- **Centro (Fact Table)**: Registros de ventas (el evento que ocurriÃ³)
- **Puntas (Dimension Tables)**: InformaciÃ³n sobre el cliente, producto, fecha, vendedor (el contexto)

**Â¿Por quÃ© se usa?**
- Queries mÃ¡s rÃ¡pidas (menos JOINs)
- MÃ¡s fÃ¡cil de entender para analistas de negocio
- Optimizado para lectura (OLAP), no escritura (OLTP)

**Ejemplo en este proyecto:**
```
         DimFecha
              |
DimCliente -- FactVentas -- DimProducto
              |
         DimVendedor
```

### SCD Type 2 (Slowly Changing Dimension)

**Â¿QuÃ© es?** Un mÃ©todo para rastrear cambios histÃ³ricos en dimensiones, guardando mÃºltiples versiones del mismo registro.

**AnalogÃ­a:** Como el historial de direcciones de un cliente:
- VersiÃ³n 1: Juan vivÃ­a en CDMX (2023-01-01 a 2024-06-30)
- VersiÃ³n 2: Juan se mudÃ³ a Guadalajara (2024-07-01 a presente)

**Campos necesarios:**
- `fecha_inicio`: CuÃ¡ndo empezÃ³ esta versiÃ³n
- `fecha_fin`: CuÃ¡ndo terminÃ³ (NULL = actual)
- `version`: NÃºmero de versiÃ³n (1, 2, 3...)
- `es_actual`: Â¿Es la versiÃ³n actual? (True/False)

**Â¿Por quÃ© importa en Data Engineering?**
- Permite anÃ¡lisis histÃ³ricos ("Â¿DÃ³nde vivÃ­an mis clientes en 2023?")
- Mantiene integridad referencial con hechos histÃ³ricos
- Es el estÃ¡ndar de la industria para dimensiones que cambian

### OLAP (Online Analytical Processing)

**Â¿QuÃ© es?** Operaciones analÃ­ticas sobre datos multidimensionales.

**Operaciones principales:**
- **Drill-down**: De general a especÃ­fico (ventas del aÃ±o â†’ ventas del mes)
- **Roll-up**: De especÃ­fico a general (ventas por ciudad â†’ ventas por paÃ­s)
- **Slice**: Corte en una dimensiÃ³n (solo ventas de 2024)
- **Dice**: Corte en mÃºltiples dimensiones (ventas 2024 + categorÃ­a ElectrÃ³nica)

**AplicaciÃ³n en Data Engineering:**
- Dashboards ejecutivos
- Reportes dinÃ¡micos
- AnÃ¡lisis ad-hoc
- Data exploration

---

## ğŸ“ Estructura del Proyecto

```
04-proyecto-practico/
â”œâ”€â”€ src/                              # CÃ³digo fuente (10 mÃ³dulos completos)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ generador_dim_fecha.py        # âœ… Genera calendario completo
â”‚   â”œâ”€â”€ generador_dim_producto.py     # âœ… Genera catÃ¡logo de productos
â”‚   â”œâ”€â”€ generador_dim_cliente.py      # âœ… Genera clientes con SCD Type 2
â”‚   â”œâ”€â”€ generador_dim_vendedor.py     # âœ… Genera vendedores (jerÃ¡rquico)
â”‚   â”œâ”€â”€ generador_fact_ventas.py      # âœ… Genera tabla de hechos completa
â”‚   â”œâ”€â”€ scd_tipo2.py                  # âœ… LÃ³gica genÃ©rica SCD Type 2
â”‚   â”œâ”€â”€ validaciones.py               # âœ… 5 validaciones de datos
â”‚   â”œâ”€â”€ database.py                   # âœ… Context manager para SQLite
â”‚   â”œâ”€â”€ queries_analiticos.py         # âœ… 6 queries OLAP
â”‚   â””â”€â”€ utilidades.py                 # âœ… Logging, formateo, helpers
â”‚
â”œâ”€â”€ tests/                            # Tests unitarios (TDD) - 197 tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_generador_dim_fecha.py   # âœ… 12 tests (100% passing, 95% cov)
â”‚   â”œâ”€â”€ test_generador_dim_producto.py # âœ… 14 tests (100% passing, 97% cov)
â”‚   â”œâ”€â”€ test_generador_dim_cliente.py # âœ… 22 tests (100% passing, 98% cov)
â”‚   â”œâ”€â”€ test_generador_dim_vendedor.py # âœ… 17 tests (100% passing, 93% cov)
â”‚   â”œâ”€â”€ test_generador_fact_ventas.py # âœ… 19 tests (100% passing, 92% cov)
â”‚   â”œâ”€â”€ test_scd_tipo2.py             # âœ… 12 tests (100% passing, 100% cov)
â”‚   â”œâ”€â”€ test_validaciones.py          # âœ… 26 tests (100% passing, 100% cov)
â”‚   â”œâ”€â”€ test_database.py              # âœ… 17 tests (100% passing, 100% cov)
â”‚   â”œâ”€â”€ test_queries_analiticos.py    # âœ… 26 tests (100% passing, 100% cov)
â”‚   â””â”€â”€ test_utilidades.py            # âœ… 32 tests (100% passing, 99% cov)
â”‚
â”œâ”€â”€ main.py                           # Pipeline demo (uso bÃ¡sico)
â”œâ”€â”€ cargar_datawarehouse.py           # CLI ETL completo con argparse
â”œâ”€â”€ schema.sql                        # DDL del Star Schema (5 tablas)
â”œâ”€â”€ requirements.txt                  # Dependencias Python
â”œâ”€â”€ .gitignore                        # Archivos ignorados por git
â”œâ”€â”€ ARQUITECTURA.md                   # DiseÃ±o tÃ©cnico detallado
â””â”€â”€ README.md                         # Este archivo
```

**EstadÃ­sticas del Proyecto:**
- **LÃ­neas de cÃ³digo**: ~4,000 (src + tests)
- **Tests**: âœ… **197 tests** (100% passing - 0 fallos)
- **Cobertura promedio**: âœ… **98%** (supera objetivo â‰¥80%)
- **MÃ³dulos**: 11 mÃ³dulos (100% completitud)
- **Funciones**: 60+ funciones con type hints y docstrings completas
- **Star Schema**: Completamente funcional con integridad referencial validada
- **CLI**: Script `cargar_datawarehouse.py` con argparse para ejecuciÃ³n flexible

---

## ğŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.11 o superior
- pip (gestor de paquetes)
- Git (opcional, para clonar el repositorio)

### Paso 1: Clonar o descargar el proyecto

```bash
# OpciÃ³n A: Clonar repositorio
git clone <url-repositorio>
cd modulo-08-data-warehousing/tema-1-dimensional-modeling/04-proyecto-practico

# OpciÃ³n B: Navegar si ya lo tienes
cd ruta/al/proyecto/04-proyecto-practico
```

### Paso 2: Crear entorno virtual (recomendado)

**Windows:**
```powershell
python -m venv venv
.\venv\Scripts\Activate.ps1
```

**Linux/Mac:**
```bash
python -m venv venv
source venv/bin/activate
```

### Paso 3: Instalar dependencias

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

**Dependencias principales:**
- `pandas>=2.0.0` - ManipulaciÃ³n de datos
- `numpy>=1.24.0` - Operaciones numÃ©ricas
- `pytest>=7.4.0` - Framework de testing
- `pytest-cov>=4.1.0` - Cobertura de tests
- `faker>=22.0.0` - GeneraciÃ³n de datos sintÃ©ticos (opcional)

### Paso 4: Verificar instalaciÃ³n

```bash
# Ejecutar tests
pytest tests/ -v

# Ver cobertura
pytest --cov=src --cov-report=html
```

---

## âœ… Ejecutar Tests

### Tests individuales por mÃ³dulo

```bash
# DimFecha (12 tests)
pytest tests/test_generador_dim_fecha.py -v

# SCD Type 2 [CRÃTICO] (12 tests)
pytest tests/test_scd_tipo2.py -v

# Validaciones [CALIDAD] (13 tests)
pytest tests/test_validaciones.py -v

# Database (11 tests)
pytest tests/test_database.py -v

# Queries OLAP (26 tests)
pytest tests/test_queries_analiticos.py -v

# Utilidades (16 tests)
pytest tests/test_utilidades.py -v
```

### Todos los tests con cobertura

```bash
# Ejecutar todos los tests
pytest tests/ -v

# Con reporte de cobertura
pytest --cov=src --cov-report=term-missing --cov-report=html

# Abrir reporte HTML
# Windows: start htmlcov/index.html
# Linux/Mac: open htmlcov/index.html
```

### Verificar cobertura mÃ­nima (80%)

```bash
pytest --cov=src --cov-fail-under=80
```

---

## ğŸ“¦ Funciones Implementadas

### 1. GeneraciÃ³n de Dimensiones

#### `generador_dim_fecha.generar_dim_fecha(fecha_inicio, fecha_fin)`

Genera un calendario completo con atributos calculados.

**ParÃ¡metros:**
- `fecha_inicio` (str): Fecha inicial en formato "YYYY-MM-DD"
- `fecha_fin` (str): Fecha final en formato "YYYY-MM-DD"

**Retorna:** DataFrame con columnas:
- `fecha_id` (int): Clave primaria (ej: 20240115)
- `fecha_completa` (date): Fecha Python
- `dia`, `mes`, `anio`, `trimestre` (int)
- `mes_nombre` (str): "Enero", "Febrero", ...
- `dia_semana` (str): "Lunes", "Martes", ...
- `numero_dia_semana` (int): 0=Lunes, 6=Domingo
- `es_fin_de_semana` (bool)
- `es_dia_festivo` (bool)
- `nombre_festivo` (str o None)

**Ejemplo:**
```python
from src.generador_dim_fecha import generar_dim_fecha

# Generar todo 2024
dim_fecha = generar_dim_fecha("2024-01-01", "2024-12-31")
print(f"Registros generados: {len(dim_fecha)}")  # 366 (aÃ±o bisiesto)

# Verificar festivos
festivos = dim_fecha[dim_fecha["es_dia_festivo"] == True]
print(festivos[["fecha_completa", "nombre_festivo"]])
```

#### `generador_dim_producto.generar_dim_producto(num_productos)`

âš ï¸ **Requiere Faker instalado**: `pip install faker`

Genera catÃ¡logo sintÃ©tico de productos.

**ParÃ¡metros:**
- `num_productos` (int): Cantidad de productos a generar

**Retorna:** DataFrame con:
- `producto_id`, `sku`, `nombre_producto`, `marca`
- `categoria`, `subcategoria`
- `precio_catalogo`, `peso_kg`, `requiere_refrigeracion`

**Ejemplo:**
```python
from src.generador_dim_producto import generar_dim_producto

productos = generar_dim_producto(100)
print(productos.groupby("categoria").size())
```

#### `generador_dim_cliente.generar_dim_cliente(num_clientes)`

âš ï¸ **Requiere Faker instalado**

Genera clientes con campos SCD Type 2.

**Retorna:** DataFrame con:
- Datos del cliente: `cliente_id`, `nombre`, `email`, `telefono`, etc.
- SCD Type 2: `fecha_inicio`, `fecha_fin`, `version`, `es_actual`

---

### 2. LÃ³gica SCD Type 2 [CRÃTICO]

#### `scd_tipo2.aplicar_scd_tipo2(df_actual, df_nuevos, campo_id, campos_rastreables, fecha_proceso)`

FunciÃ³n genÃ©rica para aplicar SCD Type 2 a cualquier dimensiÃ³n.

**ParÃ¡metros:**
- `df_actual` (DataFrame): Datos actuales del DWH
- `df_nuevos` (DataFrame): Nuevos datos entrantes
- `campo_id` (str): Campo que identifica el registro (ej: "cliente_id")
- `campos_rastreables` (list[str]): Campos que rastrean cambios (ej: ["email", "telefono"])
- `fecha_proceso` (date): Fecha del proceso ETL

**Retorna:** DataFrame con registros nuevos + actualizados + cerrados

**Ejemplo:**
```python
from src.scd_tipo2 import aplicar_scd_tipo2
from datetime import date

# Datos actuales en el DWH
df_actual = pd.DataFrame([
    {
        "cliente_id": 1,
        "email": "juan@old.com",
        "telefono": "555-1001",
        "fecha_inicio": date(2024, 1, 1),
        "fecha_fin": None,
        "version": 1,
        "es_actual": True
    }
])

# Nuevo dato entrante (email cambiÃ³)
df_nuevos = pd.DataFrame([
    {"cliente_id": 1, "email": "juan@new.com", "telefono": "555-1001"}
])

# Aplicar SCD Type 2
resultado = aplicar_scd_tipo2(
    df_actual,
    df_nuevos,
    campo_id="cliente_id",
    campos_rastreables=["email", "telefono"],
    fecha_proceso=date(2024, 6, 15)
)

print(len(resultado))  # 2 registros: versiÃ³n 1 cerrada + versiÃ³n 2 nueva
```

**Funciones auxiliares:**
- `detectar_cambios()` - Compara versiÃ³n actual vs nueva
- `cerrar_version_anterior()` - Cierra registro con fecha_fin
- `generar_nueva_version()` - Crea nueva versiÃ³n con version + 1

---

### 3. Validaciones de Calidad [CALIDAD]

#### `validaciones.validar_no_nulos(df, campos_obligatorios)`

Valida que campos obligatorios no contengan valores nulos.

**Retorna:** `{"is_valid": bool, "errors": list[str]}`

**Ejemplo:**
```python
from src.validaciones import validar_no_nulos

resultado = validar_no_nulos(df, ["cliente_id", "nombre", "email"])

if not resultado["is_valid"]:
    print("Errores encontrados:")
    for error in resultado["errors"]:
        print(f"  - {error}")
```

#### `validaciones.validar_rangos(df, rangos)`

Valida que valores numÃ©ricos estÃ©n dentro de rangos.

**Ejemplo:**
```python
from src.validaciones import validar_rangos

rangos = {
    "edad": (18, 100),
    "salario": (10000, 500000)
}

resultado = validar_rangos(df, rangos)
```

#### `validaciones.validar_tipos(df, tipos_esperados)`

Valida que columnas tengan los tipos de datos correctos.

**Ejemplo:**
```python
from src.validaciones import validar_tipos

tipos = {
    "cliente_id": int,
    "nombre": str,
    "fecha_registro": date
}

resultado = validar_tipos(df, tipos)
```

#### `validaciones.validar_integridad_referencial(df, relaciones)`

Valida que claves forÃ¡neas existan en tablas referenciadas.

**Ejemplo:**
```python
from src.validaciones import validar_integridad_referencial

# Validar que producto_id en FactVentas exista en DimProducto
relaciones = {
    "producto_id": df_productos
}

resultado = validar_integridad_referencial(df_ventas, relaciones)
```

#### `validaciones.validar_unicidad(df, campos_unicos)`

Valida que campos Ãºnicos no tengan duplicados.

**Ejemplo:**
```python
from src.validaciones import validar_unicidad

# Validar que email y cliente_id sean Ãºnicos
resultado = validar_unicidad(df, ["cliente_id", "email"])
```

---

### 4. Base de Datos

#### `database.DatabaseConnection(db_path)`

Context manager para conexiÃ³n SQLite con transacciones automÃ¡ticas.

**Ejemplo:**
```python
from src.database import DatabaseConnection

with DatabaseConnection("mi_dwh.db") as db:
    # Crear tablas desde schema.sql
    db.crear_tablas()

    # Cargar dimensiÃ³n
    registros = db.cargar_dimension("DimFecha", dim_fecha)

    # Ejecutar query
    resultado = db.ejecutar_query("SELECT * FROM DimFecha LIMIT 10")

    # Si todo OK: commit automÃ¡tico
    # Si hay error: rollback automÃ¡tico
```

**MÃ©todos:**
- `crear_tablas(schema_path)` - Crea schema desde SQL
- `cargar_dimension(tabla, df)` - Carga DataFrame a tabla
- `cargar_fact(tabla, df)` - Carga tabla de hechos
- `ejecutar_query(query, params)` - Ejecuta SELECT
- `ejecutar_comando(comando)` - Ejecuta INSERT/UPDATE/DELETE

---

### 5. Queries AnalÃ­ticos OLAP

#### `queries_analiticos.ventas_por_categoria(db, anio=None)`

Agrega ventas por categorÃ­a de producto (con drill-down por aÃ±o).

**Retorna:** DataFrame con `categoria`, `total_ventas`, `cantidad_productos`

**Ejemplo:**
```python
from src.queries_analiticos import ventas_por_categoria

with DatabaseConnection("dwh.db") as db:
    # Todas las categorÃ­as
    resultado = ventas_por_categoria(db)

    # Drill-down: solo 2024
    resultado_2024 = ventas_por_categoria(db, anio=2024)
```

#### `queries_analiticos.top_productos(db, top_n=10)`

Top N productos mÃ¡s vendidos por monto total.

**Ejemplo:**
```python
from src.queries_analiticos import top_productos

top_5 = top_productos(db, top_n=5)
print(top_5[["nombre_producto", "total_ventas"]])
```

#### `queries_analiticos.ventas_por_mes(db, trimestre=None)`

Serie temporal de ventas mensuales (con filtro por trimestre).

**Retorna:** DataFrame con `anio`, `mes`, `mes_nombre`, `total_ventas`, `num_transacciones`

**Ejemplo:**
```python
from src.queries_analiticos import ventas_por_mes

# Todo el aÃ±o
ventas_anuales = ventas_por_mes(db)

# Solo Q1 (trimestre 1)
ventas_q1 = ventas_por_mes(db, trimestre=1)
```

#### `queries_analiticos.analisis_vendedores(db)`

Performance de vendedores con mÃ©tricas calculadas.

**Retorna:** `nombre`, `region`, `total_ventas`, `num_transacciones`, `ticket_promedio`

#### `queries_analiticos.clientes_frecuentes(db, top_n=10)`

Top N clientes por monto total de compras.

**Retorna:** `nombre`, `segmento`, `ciudad`, `total_compras`, `num_transacciones`

#### `queries_analiticos.kpis_dashboard(db)`

KPIs ejecutivos para dashboard.

**Retorna:** Diccionario con:
```python
{
    "total_ventas": float,
    "num_transacciones": int,
    "ticket_promedio": float,
    "num_clientes_activos": int,
    "num_productos_vendidos": int,
    "categoria_top": str
}
```

**Ejemplo:**
```python
from src.queries_analiticos import kpis_dashboard

kpis = kpis_dashboard(db)
print(f"Total Ventas: ${kpis['total_ventas']:,.2f}")
print(f"Ticket Promedio: ${kpis['ticket_promedio']:,.2f}")
print(f"CategorÃ­a Top: {kpis['categoria_top']}")
```

---

### 6. Utilidades

#### `utilidades.configurar_logging(nivel, formato)`

Configura sistema de logging.

**Niveles:** DEBUG, INFO, WARNING, ERROR, CRITICAL

**Ejemplo:**
```python
from src.utilidades import configurar_logging

logger = configurar_logging(nivel="INFO")
logger.info("Iniciando proceso ETL")
logger.warning("Dato faltante detectado")
logger.error("Error en validaciÃ³n")
```

#### `utilidades.formatear_numero(numero, decimales)`

Formatea nÃºmeros con separadores de miles.

**Ejemplo:**
```python
from src.utilidades import formatear_numero

print(formatear_numero(1234567))          # "1,234,567"
print(formatear_numero(1234.5678, 2))     # "1,234.57"
```

#### `utilidades.imprimir_tabla(datos, headers, titulo)`

Imprime tablas ASCII formateadas para consola.

**Ejemplo:**
```python
from src.utilidades import imprimir_tabla

datos = [
    {"producto": "Laptop", "ventas": 15000, "unidades": 50},
    {"producto": "Mouse", "ventas": 3000, "unidades": 200}
]

imprimir_tabla(
    datos,
    headers=["producto", "ventas", "unidades"],
    titulo="Top Productos"
)
```

#### `utilidades.medir_tiempo(descripcion)`

Context manager para medir tiempo de ejecuciÃ³n.

**Ejemplo:**
```python
from src.utilidades import medir_tiempo

with medir_tiempo("Carga de datos"):
    # operaciÃ³n costosa
    df = pd.read_csv("big_file.csv")
# Output: Carga de datos: Completado en 2.34 segundos
```

---

## ğŸ“ Ejemplo de Uso Completo

```python
from src.database import DatabaseConnection
from src.generador_dim_fecha import generar_dim_fecha
from src.validaciones import validar_no_nulos, validar_rangos
from src.queries_analiticos import ventas_por_categoria, kpis_dashboard
from src.utilidades import configurar_logging, medir_tiempo

# 1. Configurar logging
logger = configurar_logging(nivel="INFO")
logger.info("Iniciando pipeline de Data Warehouse")

# 2. Generar dimensiÃ³n de fecha
with medir_tiempo("GeneraciÃ³n DimFecha"):
    dim_fecha = generar_dim_fecha("2024-01-01", "2024-12-31")
    logger.info(f"Generados {len(dim_fecha)} registros de fechas")

# 3. Validar calidad de datos
resultado = validar_no_nulos(dim_fecha, ["fecha_id", "fecha_completa", "anio"])
if not resultado["is_valid"]:
    logger.error(f"Errores de validaciÃ³n: {resultado['errors']}")
    raise ValueError("Calidad de datos insuficiente")

resultado = validar_rangos(dim_fecha, {"mes": (1, 12), "dia": (1, 31)})
assert resultado["is_valid"], "Rangos invÃ¡lidos detectados"

# 4. Cargar al Data Warehouse
with DatabaseConnection("mi_dwh.db") as db:
    # Crear schema
    db.crear_tablas()
    logger.info("Schema creado correctamente")

    # Cargar dimensiÃ³n
    with medir_tiempo("Carga DimFecha"):
        registros = db.cargar_dimension("DimFecha", dim_fecha)
        logger.info(f"Cargados {registros} registros a DimFecha")

    # Ejecutar queries analÃ­ticos
    logger.info("\nEjecutando queries OLAP...")

    ventas = ventas_por_categoria(db)
    logger.info(f"CategorÃ­as analizadas: {len(ventas)}")

    kpis = kpis_dashboard(db)
    logger.info(f"Total Ventas: ${kpis['total_ventas']:,.2f}")
    logger.info(f"CategorÃ­a Top: {kpis['categoria_top']}")

logger.info("Pipeline completado exitosamente")
```

---

## ğŸ› Troubleshooting

### Error: `ModuleNotFoundError: No module named 'faker'`

**Problema:** Faker no estÃ¡ instalado (requerido para generaciÃ³n de datos sintÃ©ticos).

**SoluciÃ³n:**
```bash
pip install faker
```

**Alternativa:** Usar solo DimFecha que no requiere Faker.

---

### Error: `sqlite3.IntegrityError: FOREIGN KEY constraint failed`

**Problema:** Intentando insertar en FactVentas sin cargar dimensiones primero.

**SoluciÃ³n:** Cargar dimensiones en orden:
```python
with DatabaseConnection("dwh.db") as db:
    db.crear_tablas()

    # 1. Cargar dimensiones PRIMERO
    db.cargar_dimension("DimFecha", dim_fecha)
    db.cargar_dimension("DimProducto", dim_producto)
    db.cargar_dimension("DimCliente", dim_cliente)
    db.cargar_dimension("DimVendedor", dim_vendedor)

    # 2. Cargar hechos DESPUÃ‰S
    db.cargar_fact("FactVentas", fact_ventas)
```

---

### Error: `sqlite3.IntegrityError: UNIQUE constraint failed: DimFecha.fecha_id`

**Problema:** Intentando cargar la misma dimensiÃ³n dos veces.

**SoluciÃ³n:** Eliminar la base de datos y recrear:
```bash
rm mi_dwh.db
python main.py
```

O usar `if_exists='replace'` en pandas:
```python
df.to_sql("DimFecha", conn, if_exists='replace', index=False)
```

---

### Error: Tests fallan con Faker

**Problema:** Tests de DimProducto/DimCliente esperan Faker.

**SoluciÃ³n temporal:** Ejecutar solo tests que no requieren Faker:
```bash
pytest tests/test_generador_dim_fecha.py -v
pytest tests/test_scd_tipo2.py -v
pytest tests/test_validaciones.py -v
pytest tests/test_database.py -v
pytest tests/test_queries_analiticos.py -v
pytest tests/test_utilidades.py -v
```

---

### Warning: `LF will be replaced by CRLF`

**Problema:** Diferencia de line endings entre Windows y Linux/Mac.

**SoluciÃ³n:** Es solo un warning, no afecta funcionalidad. Para silenciarlo:
```bash
git config core.autocrlf true
```

---

## ğŸ“š Recursos Adicionales

### Archivos de teorÃ­a (mismo mÃ³dulo)

- **[01-TEORIA.md](../01-TEORIA.md)** - Conceptos fundamentales de Dimensional Modeling
  - Fact Tables vs Dimension Tables
  - Star Schema vs Snowflake Schema
  - SCD Types 0-6 explicados
  - OLAP vs OLTP
  - Surrogate keys

- **[02-EJEMPLOS.md](../02-EJEMPLOS.md)** - 4 ejemplos trabajados completos
  - E-commerce con Star Schema
  - AnÃ¡lisis de ventas retail
  - SCD Type 2 en prÃ¡ctica
  - Queries OLAP paso a paso

- **[03-EJERCICIOS.md](../03-EJERCICIOS.md)** - 15 ejercicios con soluciones
  - 5 ejercicios bÃ¡sicos (â­)
  - 5 ejercicios intermedios (â­â­)
  - 5 ejercicios avanzados (â­â­â­â­)

### DocumentaciÃ³n tÃ©cnica

- **[ARQUITECTURA.md](./ARQUITECTURA.md)** - DiseÃ±o tÃ©cnico detallado
  - Decisiones de arquitectura
  - Patrones utilizados
  - Estructura de mÃ³dulos
  - Dependencias entre componentes

- **[schema.sql](./schema.sql)** - DDL completo del Star Schema
  - DefiniciÃ³n de 5 tablas
  - Foreign keys
  - Ãndices para OLAP
  - Constraints

### Enlaces externos

- **Kimball Dimensional Modeling**: [https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/](https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/)
- **Star Schema Benchmark**: [https://www.cs.umb.edu/~poneil/StarSchemaB.PDF](https://www.cs.umb.edu/~poneil/StarSchemaB.PDF)
- **Pandas Documentation**: [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)
- **SQLite Documentation**: [https://www.sqlite.org/docs.html](https://www.sqlite.org/docs.html)

---

## ğŸ¯ PrÃ³ximos Pasos

âœ… **Proyecto 100% Completado** - Star Schema completamente funcional con todas las dimensiones y tabla de hechos implementadas.

### Opciones de ExtensiÃ³n (Opcional)

1. **Ejecutar pipeline con CLI**:
   ```bash
   # Uso bÃ¡sico
   python cargar_datawarehouse.py --db output/dwh.db --ventas 1000

   # Con mÃ¡s opciones
   python cargar_datawarehouse.py \
       --db output/dwh.db \
       --ventas 5000 \
       --productos 200 \
       --clientes 500 \
       --vendedores 50 \
       --log-file logs/etl.log \
       --log-level DEBUG

   # Ver todas las opciones
   python cargar_datawarehouse.py --help
   ```

   O usar el script demo simple:
   ```bash
   python main.py
   ```

2. **Explorar queries OLAP** en `src/queries_analiticos.py`:
   - Modificar queries para nuevos anÃ¡lisis
   - Agregar filtros adicionales (regiones, perÃ­odos, categorÃ­as)
   - Crear visualizaciones con matplotlib/plotly
   - Implementar dashboard interactivo

3. **Optimizar para producciÃ³n**:
   - Migrar de SQLite a PostgreSQL o Snowflake
   - Implementar particionamiento de FactVentas por fecha
   - Agregar Ã­ndices compuestos para queries frecuentes
   - Implementar incremental loading (carga incremental)

4. **Extender el modelo dimensional**:
   - Agregar mÃ¡s dimensiones: DimPromocion, DimCanal, DimSucursal
   - Implementar dimensiones Snowflake (normalizaciÃ³n)
   - Crear tabla de hechos adicional: FactInventario, FactDevoluciones
   - Aplicar SCD Type 3 para comparaciones before/after

5. **Conectar a herramienta BI**:
   - Power BI, Tableau, Metabase, Looker
   - Crear dashboards ejecutivos interactivos
   - Implementar drill-down/drill-up dinÃ¡micos
   - Publicar para usuarios finales con seguridad por roles

6. **Implementar Data Quality Framework**:
   - Great Expectations para validaciones avanzadas
   - Alertas automÃ¡ticas para anomalÃ­as
   - Monitoreo de SLA de datos
   - Reporte de calidad de datos

---

## ğŸ“ Notas Importantes

- Este proyecto usa **SQLite** por simplicidad educativa. En producciÃ³n, se usarÃ­a PostgreSQL, SQL Server, o Snowflake.
- Los datos son **sintÃ©ticos** (generados con Faker) para demostraciÃ³n. No usar en producciÃ³n.
- El proyecto sigue **TDD estricto**: tests escritos antes de implementaciÃ³n.
- Todas las funciones tienen **type hints** y **docstrings** completas.
- Cobertura de tests **>90%** en mÃ³dulos crÃ­ticos (SCD Type 2, Validaciones).

---

## ğŸ¤ Contribuciones

Este es un proyecto educativo. Si encuentras errores o mejoras:

1. Revisa los archivos de teorÃ­a para entender el contexto
2. Ejecuta los tests para validar cambios
3. Sigue el estilo de cÃ³digo (black, flake8, mypy)
4. MantÃ©n la cobertura >80%

---

## ğŸ“„ Licencia

Proyecto educativo del **Master en IngenierÃ­a de Datos con IA**.

---

**Ãšltima actualizaciÃ³n:** 2025-11-30
**VersiÃ³n del proyecto:** 1.1 âœ… **100% COMPLETADO**
**Autor:** Claude Code (Anthropic) + Master Data Engineering

**Estado del Star Schema:**
- âœ… DimFecha (366 registros, calendario completo 2024)
- âœ… DimProducto (con Faker, categorizaciÃ³n automÃ¡tica)
- âœ… DimCliente (con Faker, SCD Type 2)
- âœ… DimVendedor (con Faker, estructura jerÃ¡rquica)
- âœ… FactVentas (tabla de hechos completa)

**MÃ©tricas finales:**
- **11 mÃ³dulos implementados** (100%)
- **197 tests pasando** (100% Ã©xito)
- **Cobertura: 98%** (supera objetivo â‰¥80%)
- **CLI completo** con argparse para ejecuciÃ³n flexible
- **Star Schema completamente funcional** con integridad referencial validada
---

## ğŸ§­ NavegaciÃ³n

â¬…ï¸ **Anterior**: [03 Ejercicios](../03-EJERCICIOS.md) | â¡ï¸ **Siguiente**: [Herramientas DWH - 01 Teoria](../../tema-2-herramientas-dwh/01-TEORIA.md)
