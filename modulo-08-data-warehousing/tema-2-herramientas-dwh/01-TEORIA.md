# Tema 2: dbt (data build tool) - Transformaciones Modernas en Data Warehouses

## Introducci√≥n

### ¬øPor qu√© existe dbt?

Imagina que eres un ingeniero de datos en una empresa de e-commerce. Tienes un Data Warehouse con datos crudos de ventas, productos y clientes. Necesitas transformar esos datos para crear tablas limpias que los analistas puedan consultar. Tradicionalmente, tendr√≠as dos opciones:

**Opci√≥n 1**: Escribir scripts Python con Pandas (lo que viste en el M√≥dulo 3)
- ‚ùå Los analistas no saben Python
- ‚ùå Dif√≠cil de mantener
- ‚ùå Sin tests autom√°ticos
- ‚ùå Sin documentaci√≥n autom√°tica

**Opci√≥n 2**: Escribir SQL a mano en el Data Warehouse
- ‚ùå C√≥digo duplicado everywhere
- ‚ùå Sin control de versiones claro
- ‚ùå Dif√≠cil de testear
- ‚ùå Sin documentaci√≥n
- ‚ùå ¬øQu√© tabla se cre√≥ primero? Nadie lo sabe

**dbt es la soluci√≥n moderna**: Te permite escribir SQL (que todos conocen), pero con:
- ‚úÖ **Tests autom√°ticos** sobre tus datos
- ‚úÖ **Documentaci√≥n autom√°tica** con lineage visual
- ‚úÖ **Versionado con Git** (como c√≥digo normal)
- ‚úÖ **Reutilizaci√≥n de c√≥digo** con macros
- ‚úÖ **Dependencias claras** entre tablas
- ‚úÖ **CI/CD** para validar cambios antes de producci√≥n

### Contexto Real en Data Engineering

**Caso de uso t√≠pico:**

En **DataMart Inc.**, una empresa de analytics, tienen un proceso as√≠:

1. **Extract**: Datos crudos llegan a PostgreSQL cada hora desde m√∫ltiples fuentes (Salesforce, Google Analytics, bases de datos transaccionales)

2. **Load**: Los datos crudos se cargan en un esquema `raw` del Data Warehouse sin transformaciones

3. **Transform** (AQU√ç ENTRA dbt): dbt transforma los datos crudos en tablas anal√≠ticas:
   - `raw.salesforce_leads` ‚Üí `analytics.leads_cleaned` ‚Üí `analytics.leads_scored`
   - `raw.ga_sessions` ‚Üí `analytics.web_traffic` ‚Üí `analytics.marketing_attribution`
   - Combina m√∫ltiples fuentes en tablas consolidadas

4. **BI Tools**: Metabase/Tableau/Looker consultan las tablas finales

**¬øPor qu√© usar dbt y no Python?**
- Los analistas de negocio saben SQL, no Python
- SQL es m√°s eficiente para transformaciones grandes (se ejecuta en el DWH, no en memoria)
- dbt genera documentaci√≥n y lineage autom√°ticamente
- Tests sobre datos, no sobre c√≥digo

### Analog√≠a del Mundo Real

Piensa en dbt como **Git para tu Data Warehouse**:

- **Git** versiona tu c√≥digo ‚Üí **dbt** versiona tus transformaciones SQL
- **Git** tiene branches ‚Üí **dbt** permite desarrollar transformaciones sin romper producci√≥n
- **Git** tiene pull requests con tests ‚Üí **dbt** ejecuta tests antes de deployar cambios
- **Git** documenta cambios ‚Üí **dbt** documenta autom√°ticamente qu√© tabla depende de cu√°l

O piensa en dbt como **"React/Vue para SQL"**:
- React tiene componentes reutilizables ‚Üí dbt tiene modelos reutilizables
- React tiene props ‚Üí dbt tiene refs (referencias)
- React renderiza autom√°ticamente cuando hay cambios ‚Üí dbt reconstruye tablas cuando sus dependencias cambian

---

## Conceptos Fundamentales

### ¬øQu√© es dbt?

**dbt (data build tool)** es una herramienta de **transformaci√≥n de datos** que:

1. **Toma como input**: Datos crudos en tu Data Warehouse (PostgreSQL, Snowflake, BigQuery, etc.)
2. **Transforma**: Usando SQL + Jinja templating
3. **Produce como output**: Tablas/vistas limpias y documentadas en tu DWH

**Filosof√≠a central de dbt:**
> "Bring software engineering best practices to analytics"

Esto significa:
- **Modularidad**: Una transformaci√≥n = Un archivo `.sql`
- **Testing**: Tests autom√°ticos sobre datos
- **Documentaci√≥n**: Generada autom√°ticamente
- **DRY (Don't Repeat Yourself)**: Macros reutilizables
- **Dependency management**: dbt determina el orden de ejecuci√≥n

### ELT vs ETL

**ETL tradicional (Extract-Transform-Load)**:
```
1. Extract: Leer datos de fuentes
2. Transform: Transformar EN UN SERVIDOR INTERMEDIO (Airflow worker, script Python)
3. Load: Cargar datos transformados al DWH
```

**ELT moderno (Extract-Load-Transform)**:
```
1. Extract: Leer datos de fuentes
2. Load: Cargar datos CRUDOS directamente al DWH
3. Transform: Transformar DENTRO DEL DWH usando dbt
```

**¬øPor qu√© ELT es mejor para Data Warehouses?**
- ‚úÖ Aprovecha la potencia del DWH (est√° optimizado para queries SQL complejos)
- ‚úÖ No necesitas un servidor intermedio potente
- ‚úÖ Los datos crudos est√°n siempre disponibles (si la transformaci√≥n falla, los crudos siguen ah√≠)
- ‚úÖ M√°s f√°cil auditar y rehacer transformaciones

**dbt es la herramienta T en ELT.**

### dbt Core vs dbt Cloud

**dbt Core** (Open Source, Gratis):
- CLI (Command Line Interface)
- Ejecutas `dbt run` desde terminal
- T√∫ manejas la infraestructura (d√≥nde correrlo, scheduling, logs)
- Ideal para: Desarrollo local, empresas con DevOps fuerte

**dbt Cloud** (SaaS, Pago):
- Interface web visual
- Scheduling incorporado (corre tus dbt jobs autom√°ticamente)
- IDE en el browser
- Logs y monitoreo centralizados
- Ideal para: Empresas que quieren un producto listo, equipos no-t√©cnicos

**En este curso usaremos dbt Core** porque:
- Es gratis
- Te ense√±a los fundamentos
- Todo lo que aprendas aplica a dbt Cloud

### Estructura de un Proyecto dbt

Un proyecto dbt t√≠pico se ve as√≠:

```
mi_proyecto_dbt/
‚îú‚îÄ‚îÄ dbt_project.yml         # Configuraci√≥n del proyecto
‚îú‚îÄ‚îÄ profiles.yml            # Conexiones a bases de datos (NO commitear)
‚îú‚îÄ‚îÄ models/                 # ‚≠ê Aqu√≠ viven tus transformaciones SQL
‚îÇ   ‚îú‚îÄ‚îÄ staging/            #    Capa 1: Datos limpios b√°sicos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ stg_customers.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ stg_orders.sql
‚îÇ   ‚îú‚îÄ‚îÄ intermediate/       #    Capa 2: Transformaciones intermedias
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ int_order_items_joined.sql
‚îÇ   ‚îú‚îÄ‚îÄ marts/              #    Capa 3: Tablas finales para analistas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dim_customers.sql
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ fct_orders.sql
‚îÇ   ‚îî‚îÄ‚îÄ schema.yml          #    Documentaci√≥n y tests
‚îú‚îÄ‚îÄ macros/                 # Funciones SQL reutilizables
‚îÇ   ‚îî‚îÄ‚îÄ cents_to_dollars.sql
‚îú‚îÄ‚îÄ seeds/                  # Archivos CSV peque√±os (datos est√°ticos)
‚îÇ   ‚îî‚îÄ‚îÄ country_codes.csv
‚îú‚îÄ‚îÄ snapshots/              # SCD Type 2 autom√°tico
‚îÇ   ‚îî‚îÄ‚îÄ customers_snapshot.sql
‚îú‚îÄ‚îÄ tests/                  # Tests personalizados
‚îÇ   ‚îî‚îÄ‚îÄ assert_positive_revenue.sql
‚îî‚îÄ‚îÄ analyses/               # Queries ad-hoc (no se ejecutan en dbt run)
    ‚îî‚îÄ‚îÄ monthly_revenue.sql
```

**Conceptos clave:**

**models/**: Cada archivo `.sql` es un "modelo" (una transformaci√≥n). dbt ejecutar√° ese SQL y crear√° una tabla/vista.

**dbt_project.yml**: Define nombre del proyecto, versi√≥n, materializations por defecto, etc.

**profiles.yml**: Define D√ìNDE conectarse (PostgreSQL local, Snowflake prod, etc.). Este archivo NO se commitea a Git porque tiene credenciales.

---

## Models (Modelos)

### ¬øQu√© es un Modelo?

Un **modelo** en dbt es simplemente:
- Un archivo `.sql` con un `SELECT` statement
- dbt ejecuta ese SELECT y crea una tabla/vista con el resultado

**Ejemplo b√°sico** (`models/stg_customers.sql`):

```sql
-- Limpiar datos de clientes
SELECT
    customer_id,
    LOWER(TRIM(email)) AS email,
    INITCAP(first_name) AS first_name,
    INITCAP(last_name) AS last_name,
    created_at
FROM raw.customers
WHERE email IS NOT NULL
```

Cuando ejecutas `dbt run`, dbt:
1. Lee ese archivo
2. Ejecuta el SQL en tu Data Warehouse
3. Crea la tabla/vista `analytics.stg_customers` (el schema depende de tu configuraci√≥n)

### Tipos de Materializaci√≥n

**Materializaci√≥n** = C√≥mo dbt guarda el resultado de tu modelo.

Hay 4 tipos:

#### 1. **view** (Vista)

```sql
-- models/vw_active_customers.sql
{{ config(materialized='view') }}

SELECT * FROM {{ ref('stg_customers') }}
WHERE status = 'active'
```

- **Qu√© hace**: Crea una VIEW en la base de datos
- **Cu√°ndo usarlo**: Datos que cambian frecuentemente, queries r√°pidos
- **Ventaja**: No ocupa espacio, siempre actualizado
- **Desventaja**: Cada query ejecuta el SELECT completo (puede ser lento)

#### 2. **table** (Tabla)

```sql
-- models/dim_customers.sql
{{ config(materialized='table') }}

SELECT
    customer_id,
    email,
    full_name,
    segment,
    lifetime_value
FROM {{ ref('stg_customers') }}
```

- **Qu√© hace**: Crea una TABLE f√≠sica (hace DROP + CREATE)
- **Cu√°ndo usarlo**: Queries complejos, muchos usuarios consultando
- **Ventaja**: Queries r√°pidos (los datos ya est√°n materializados)
- **Desventaja**: Ocupa espacio, reconstruye TODO cada vez

#### 3. **incremental** (Incremental)

```sql
-- models/fct_page_views.sql
{{ config(
    materialized='incremental',
    unique_key='event_id'
) }}

SELECT
    event_id,
    user_id,
    page_url,
    event_timestamp
FROM {{ ref('stg_events') }}

{% if is_incremental() %}
-- Solo procesar eventos nuevos
WHERE event_timestamp > (SELECT MAX(event_timestamp) FROM {{ this }})
{% endif %}
```

- **Qu√© hace**: Primera vez ‚Üí CREATE TABLE, siguientes veces ‚Üí INSERT/UPDATE solo registros nuevos
- **Cu√°ndo usarlo**: Tablas grandes que crecen con el tiempo (logs, eventos)
- **Ventaja**: Mucho m√°s r√°pido que reconstruir la tabla completa
- **Desventaja**: M√°s complejo, necesitas `unique_key`

**Estrategias incrementales:**
- `append`: Solo hace INSERT (no actualiza registros existentes)
- `merge`: Hace UPSERT (inserta nuevos, actualiza existentes bas√°ndose en `unique_key`)
- `delete+insert`: Borra registros que matchean, luego inserta

#### 4. **ephemeral** (Ef√≠mero)

```sql
-- models/intermediate/int_order_items.sql
{{ config(materialized='ephemeral') }}

SELECT
    order_id,
    product_id,
    quantity * price AS line_total
FROM {{ ref('stg_order_items') }}
```

- **Qu√© hace**: NO crea tabla ni vista. El SQL se inserta como CTE en los modelos que lo referencian
- **Cu√°ndo usarlo**: Transformaciones intermedias que solo otro modelo usa
- **Ventaja**: No ocupa espacio, menos objetos en DWH
- **Desventaja**: No puedes queryarlo directamente, puede hacer queries complejos

### Refs y Sources

#### `{{ ref('modelo') }}` - Referencias entre modelos

En vez de escribir:
```sql
SELECT * FROM analytics.stg_customers
```

Escribes:
```sql
SELECT * FROM {{ ref('stg_customers') }}
```

**¬øPor qu√©?**
- dbt sabe que este modelo depende de `stg_customers`
- dbt ejecutar√° `stg_customers` ANTES que este modelo
- Si cambias el schema de `stg_customers`, dbt actualiza autom√°ticamente la referencia
- El lineage graph muestra la dependencia visualmente

#### `{{ source('schema', 'table') }}` - Datos crudos

Para referenciar tablas crudas (que NO son modelos dbt):

**Definici√≥n en schema.yml:**
```yaml
sources:
  - name: raw
    schema: raw_data
    tables:
      - name: customers
      - name: orders
```

**Uso en modelo:**
```sql
SELECT * FROM {{ source('raw', 'customers') }}
```

**Ventaja**: dbt puede testear que la fuente existe antes de ejecutar modelos.

---

## Tests

### ¬øPor qu√© testear datos?

**Datos incorrectos son peores que no tener datos.**

Ejemplos de problemas reales:
- Duplicados en `customer_id` ‚Üí El dashboard muestra ingresos inflados
- `NULL` en `order_date` ‚Üí Los reportes mensuales fallan
- `revenue` negativo ‚Üí El CFO toma decisiones equivocadas

**dbt tests validan autom√°ticamente que tus datos cumplen reglas.**

### Tests Gen√©ricos (Built-in)

dbt incluye 4 tests b√°sicos que puedes aplicar a cualquier columna:

**Definici√≥n en `models/schema.yml`:**

```yaml
models:
  - name: dim_customers
    description: "Tabla dimensional de clientes"
    columns:
      - name: customer_id
        description: "Primary key √∫nica"
        tests:
          - unique            # ‚úÖ No duplicados
          - not_null          # ‚úÖ No NULLs

      - name: email
        tests:
          - unique

      - name: segment
        tests:
          - accepted_values:  # ‚úÖ Solo valores de esta lista
              values: ['Bronze', 'Silver', 'Gold', 'Platinum']

  - name: fct_orders
    columns:
      - name: customer_id
        tests:
          - relationships:    # ‚úÖ Foreign key v√°lida
              to: ref('dim_customers')
              field: customer_id
```

**Ejecutar tests:**
```bash
dbt test  # Ejecuta todos los tests
dbt test --select dim_customers  # Solo tests de un modelo
```

Si un test falla, dbt devuelve error y muestra qu√© registros fallaron.

### Tests Personalizados

Para l√≥gica de negocio espec√≠fica, creas tests custom:

**`tests/assert_positive_revenue.sql`:**
```sql
-- Este test falla si encuentra revenue <= 0
SELECT *
FROM {{ ref('fct_orders') }}
WHERE revenue <= 0
```

**L√≥gica**: Si el SELECT devuelve filas, el test falla.

**Otro ejemplo:**
```sql
-- Test: Todas las √≥rdenes tienen al menos 1 item
SELECT order_id
FROM {{ ref('fct_orders') }}
WHERE order_id NOT IN (
    SELECT DISTINCT order_id
    FROM {{ ref('fct_order_items') }}
)
```

### Severity de Tests

Por defecto, los tests que fallan causan que `dbt test` retorne error. Puedes cambiar esto:

```yaml
models:
  - name: dim_products
    columns:
      - name: price
        tests:
          - not_null:
              severity: warn  # Solo advertencia, no falla el build
```

**Severities:**
- `error` (default): Falla el build
- `warn`: Muestra advertencia, contin√∫a

---

## Documentaci√≥n

### Schema.yml - Documentaci√≥n de Modelos

El archivo `schema.yml` sirve para:
1. Documentar modelos y columnas
2. Definir tests
3. Configurar sources

**Ejemplo completo:**

```yaml
version: 2

models:
  - name: dim_customers
    description: |
      Tabla dimensional de clientes consolidada.

      Esta tabla combina datos de Salesforce y la base transaccional,
      aplicando limpieza y deduplicaci√≥n.

      **Actualizaci√≥n**: Diaria a las 2 AM UTC
      **Owner**: Equipo Analytics

    columns:
      - name: customer_id
        description: "Surrogate key √∫nica del cliente"
        tests:
          - unique
          - not_null

      - name: email
        description: "Email normalizado (lowercase, trimmed)"
        tests:
          - unique
          - not_null

      - name: first_name
        description: "Nombre en formato t√≠tulo (John, no JOHN)"

      - name: segment
        description: |
          Segmento del cliente basado en lifetime value:
          - Bronze: < $1,000
          - Silver: $1,000 - $5,000
          - Gold: $5,000 - $20,000
          - Platinum: > $20,000
        tests:
          - accepted_values:
              values: ['Bronze', 'Silver', 'Gold', 'Platinum']
```

### Generaci√≥n Autom√°tica de Documentaci√≥n

```bash
dbt docs generate  # Genera la documentaci√≥n
dbt docs serve     # Abre un servidor web local con la documentaci√≥n
```

Esto genera un **sitio web interactivo** con:
- üìä **Lineage Graph**: Diagrama visual de dependencias entre modelos
- üìÑ **Cat√°logo de tablas**: Todas las tablas con sus descripciones
- üìù **Definiciones de columnas**: Qu√© significa cada campo
- üîç **B√∫squeda**: Encuentra r√°pidamente modelos o columnas
- üìà **Estad√≠sticas**: Cu√°ntas filas, √∫ltima ejecuci√≥n, etc.

**El lineage graph es INCRE√çBLE**:
- Ves visualmente c√≥mo fluyen los datos: `raw.customers` ‚Üí `stg_customers` ‚Üí `dim_customers` ‚Üí `fct_orders`
- Click en un modelo para ver su SQL
- Identificas r√°pidamente qu√© tablas se romper√°n si cambias un modelo

---

## Jinja y Macros

### Templating SQL con Jinja

dbt usa **Jinja** (un lenguaje de templating) para hacer tu SQL m√°s din√°mico.

**Ejemplo b√°sico - Variables:**

```sql
{% set payment_methods = ['credit_card', 'debit_card', 'bank_transfer'] %}

SELECT
    order_id,
    {% for method in payment_methods %}
    SUM(CASE WHEN payment_method = '{{ method }}' THEN amount ELSE 0 END) AS {{ method }}_amount
    {{ "," if not loop.last }}
    {% endfor %}
FROM {{ ref('stg_payments') }}
GROUP BY 1
```

**Se renderiza como:**
```sql
SELECT
    order_id,
    SUM(CASE WHEN payment_method = 'credit_card' THEN amount ELSE 0 END) AS credit_card_amount,
    SUM(CASE WHEN payment_method = 'debit_card' THEN amount ELSE 0 END) AS debit_card_amount,
    SUM(CASE WHEN payment_method = 'bank_transfer' THEN amount ELSE 0 END) AS bank_transfer_amount
FROM analytics.stg_payments
GROUP BY 1
```

### Macros - Funciones Reutilizables

Un **macro** es una funci√≥n SQL que puedes reutilizar en m√∫ltiples modelos.

**Definici√≥n** (`macros/cents_to_dollars.sql`):
```sql
{% macro cents_to_dollars(column_name) %}
    ({{ column_name }} / 100.0)::numeric(10,2)
{% endmacro %}
```

**Uso en modelo:**
```sql
SELECT
    order_id,
    {{ cents_to_dollars('amount_cents') }} AS amount_dollars,
    {{ cents_to_dollars('tax_cents') }} AS tax_dollars
FROM {{ ref('stg_orders') }}
```

**Otro ejemplo √∫til - Generar surrogate key:**

```sql
{% macro generate_surrogate_key(columns) %}
    MD5(CONCAT(
        {% for col in columns %}
        COALESCE(CAST({{ col }} AS VARCHAR), '')
        {{ "," if not loop.last }}
        {% endfor %}
    ))
{% endmacro %}
```

**Uso:**
```sql
SELECT
    {{ generate_surrogate_key(['customer_id', 'order_date']) }} AS order_key,
    customer_id,
    order_date
FROM {{ ref('stg_orders') }}
```

### Macros de dbt-utils

El paquete `dbt-utils` (oficial) tiene macros s√∫per √∫tiles:

```yaml
# packages.yml
packages:
  - package: dbt-labs/dbt_utils
    version: 1.1.0
```

```bash
dbt deps  # Instala los paquetes
```

**Ejemplos:**

```sql
-- Generar surrogate key
SELECT {{ dbt_utils.generate_surrogate_key(['customer_id', 'email']) }} AS customer_key

-- Pivotar columnas
{{ dbt_utils.pivot(
    column='payment_method',
    values=dbt_utils.get_column_values(ref('stg_payments'), 'payment_method'),
    agg='sum',
    then_value='amount'
) }}

-- Union de m√∫ltiples modelos
{{ dbt_utils.union_relations(
    relations=[ref('orders_2022'), ref('orders_2023'), ref('orders_2024')]
) }}
```

---

## Incremental Models (Avanzado)

### ¬øCu√°ndo usar modelos incrementales?

**Caso de uso perfecto**: Tienes una tabla de **eventos** que crece constantemente (ej: page views, clicks, logs).

**Problema sin incremental:**
- Cada `dbt run` hace `DROP TABLE` y `CREATE TABLE` con TODOS los datos hist√≥ricos
- Si tienes 1 bill√≥n de filas, esto tarda horas

**Soluci√≥n con incremental:**
- Primera ejecuci√≥n: Crea la tabla con todos los datos hist√≥ricos
- Siguientes ejecuciones: Solo procesa registros nuevos (ej: del √∫ltimo d√≠a)

### Implementaci√≥n

```sql
-- models/fct_page_views.sql
{{ config(
    materialized='incremental',
    unique_key='event_id',
    on_schema_change='fail'
) }}

SELECT
    event_id,
    user_id,
    page_url,
    event_timestamp,
    session_id
FROM {{ ref('stg_events') }}

{% if is_incremental() %}
    -- En runs posteriores, solo procesar datos nuevos
    WHERE event_timestamp > (SELECT MAX(event_timestamp) FROM {{ this }})
{% endif %}
```

**Explicaci√≥n:**
- `materialized='incremental'`: Activa el modo incremental
- `unique_key='event_id'`: Columna que identifica registros √∫nicos (para UPSERT)
- `is_incremental()`: Funci√≥n que retorna `True` si la tabla ya existe
- `{{ this }}`: Referencia a la tabla actual (equivale a `analytics.fct_page_views`)

### Estrategias Incrementales

**1. append** (Solo insertar):
```sql
{{ config(
    materialized='incremental',
    incremental_strategy='append'
) }}
```
- Hace `INSERT` de filas nuevas
- NO actualiza registros existentes
- R√°pido pero puede causar duplicados si la l√≥gica falla

**2. merge** (UPSERT):
```sql
{{ config(
    materialized='incremental',
    incremental_strategy='merge',
    unique_key='order_id'
) }}
```
- Si `order_id` ya existe ‚Üí UPDATE
- Si es nuevo ‚Üí INSERT
- M√°s lento pero evita duplicados

**3. delete+insert**:
```sql
{{ config(
    materialized='incremental',
    incremental_strategy='delete+insert',
    unique_key=['date', 'customer_id']
) }}
```
- Borra registros que matchean el `unique_key`
- Inserta todos los registros nuevos

---

## Seeds y Snapshots

### Seeds - Datos Est√°ticos

**Seeds** son archivos CSV que dbt carga como tablas en tu DWH.

**Caso de uso**: Datos que cambian raramente (ej: c√≥digos de pa√≠ses, categor√≠as de productos, tipos de moneda).

**Archivo** (`seeds/country_codes.csv`):
```csv
country_code,country_name,continent
US,United States,North America
MX,Mexico,North America
BR,Brazil,South America
```

**Carga:**
```bash
dbt seed  # Carga todos los CSVs en seeds/
```

**Uso en modelo:**
```sql
SELECT
    o.order_id,
    o.amount,
    c.country_name,
    c.continent
FROM {{ ref('orders') }} o
LEFT JOIN {{ ref('country_codes') }} c
    ON o.country_code = c.country_code
```

### Snapshots - SCD Type 2 Autom√°tico

**Problema**: Tienes una tabla de clientes. El email de un cliente cambi√≥. ¬øC√≥mo guardas el hist√≥rico?

**Soluci√≥n manual**: Implementar SCD Type 2 (lo viste en Tema 1).

**Soluci√≥n con dbt**: Usar **snapshots**, que implementa SCD Type 2 autom√°ticamente.

**Definici√≥n** (`snapshots/customers_snapshot.sql`):
```sql
{% snapshot customers_snapshot %}

{{
    config(
      target_schema='snapshots',
      unique_key='customer_id',
      strategy='timestamp',
      updated_at='updated_at'
    )
}}

SELECT *
FROM {{ source('raw', 'customers') }}

{% endsnapshot %}
```

**Ejecuci√≥n:**
```bash
dbt snapshot
```

**Resultado**: dbt crea una tabla `snapshots.customers_snapshot` con columnas adicionales:
- `dbt_valid_from`: Cu√°ndo este registro se volvi√≥ v√°lido
- `dbt_valid_to`: Cu√°ndo dej√≥ de ser v√°lido (NULL si es actual)
- `dbt_scd_id`: ID √∫nico del snapshot
- `dbt_updated_at`: Timestamp del √∫ltimo cambio

**Ejemplo de tabla generada:**

| customer_id | email | updated_at | dbt_valid_from | dbt_valid_to |
|---|---|---|---|---|
| 1 | john@old.com | 2024-01-01 | 2024-01-01 | 2024-06-15 |
| 1 | john@new.com | 2024-06-15 | 2024-06-15 | NULL |

---

## Aplicaciones Pr√°cticas en Data Engineering

### Use Case 1: Pipeline de E-commerce

**Problema**: Tienes ventas crudas en PostgreSQL. Necesitas crear reportes de ingresos por producto, regi√≥n y mes.

**Soluci√≥n con dbt:**

```
raw.orders
raw.order_items
raw.products
raw.customers
    ‚Üì
[dbt transforma]
    ‚Üì
analytics.dim_products
analytics.dim_customers
analytics.fct_order_items
    ‚Üì
[BI Tool consume]
```

**Ventajas:**
- Los analistas pueden modificar las transformaciones (saben SQL)
- Tests autom√°ticos validan que no hay productos sin categor√≠a
- Documentaci√≥n muestra qu√© significa cada m√©trica
- Si cambias la l√≥gica de `dim_products`, sabes qu√© reportes se afectan (lineage)

### Use Case 2: Agregaciones Diarias

**Problema**: Tienes millones de eventos de clickstream. Necesitas reportes diarios de tr√°fico.

**Soluci√≥n con modelo incremental:**

```sql
-- models/daily_page_views.sql
{{ config(materialized='incremental', unique_key=['date', 'page_url']) }}

SELECT
    DATE(event_timestamp) AS date,
    page_url,
    COUNT(*) AS page_views,
    COUNT(DISTINCT user_id) AS unique_visitors
FROM {{ ref('stg_events') }}

{% if is_incremental() %}
WHERE DATE(event_timestamp) = CURRENT_DATE - INTERVAL '1 day'
{% endif %}

GROUP BY 1, 2
```

**Ventaja**: Solo procesas el d√≠a de ayer, no todos los hist√≥ricos.

### Use Case 3: Consolidaci√≥n de Fuentes

**Problema**: Tienes clientes en Salesforce y en tu base transaccional. Necesitas una √∫nica fuente de verdad.

**Soluci√≥n:**

```sql
-- models/dim_customers.sql
WITH salesforce_customers AS (
    SELECT
        sf_id AS customer_id,
        email,
        'salesforce' AS source
    FROM {{ source('raw', 'sf_accounts') }}
),

transactional_customers AS (
    SELECT
        customer_id,
        email,
        'transactional' AS source
    FROM {{ source('raw', 'app_users') }}
),

unioned AS (
    SELECT * FROM salesforce_customers
    UNION ALL
    SELECT * FROM transactional_customers
),

deduplicated AS (
    SELECT *,
        ROW_NUMBER() OVER (PARTITION BY email ORDER BY source) AS rn
    FROM unioned
)

SELECT
    customer_id,
    email,
    source AS primary_source
FROM deduplicated
WHERE rn = 1
```

---

## Cloud Data Warehouses: Snowflake vs Redshift vs BigQuery

### ¬øPor qu√© elegir un Cloud DWH?

dbt funciona con cualquier Data Warehouse que soporte SQL. Sin embargo, los tres grandes dominan el mercado empresarial:

**Analog√≠a**: Piensa en los cloud DWH como diferentes marcas de coches deportivos:
- **Snowflake** = Tesla ‚Üí Innovador, moderno, separaci√≥n de c√≥mputo y almacenamiento
- **Redshift** = BMW ‚Üí Integrado con ecosistema AWS, s√≥lido y probado
- **BigQuery** = Mercedes ‚Üí Serverless total, escalabilidad autom√°tica, integrado con Google

### Comparativa T√©cnica

| Caracter√≠stica | Snowflake | Redshift | BigQuery |
|---|---|---|---|
| **Modelo de precio** | Por segundos de uso | Por hora de cluster | Por TB procesado |
| **Escalado** | Autom√°tico (compute separado) | Manual (resize cluster) | Autom√°tico (serverless) |
| **Almacenamiento** | Separado de c√≥mputo | Junto con c√≥mputo | Separado (serverless) |
| **Multi-cloud** | ‚úÖ AWS, Azure, GCP | ‚ùå Solo AWS | ‚ùå Solo GCP |
| **Data Sharing** | ‚úÖ Nativo (Zero Copy) | ‚ùå Requiere ETL | ‚ö†Ô∏è Analytics Hub |
| **Formato nativo** | Propio (columnar) | Columnar (Redshift) | Columnar (Capacitor) |
| **dbt Support** | ‚úÖ Excelente | ‚úÖ Excelente | ‚úÖ Excelente |

### ¬øCu√°ndo usar cada uno?

**Snowflake - Ideal para:**
- Empresas multi-cloud o que quieren evitar vendor lock-in
- Cargas de trabajo variables (picos de demanda)
- Data sharing entre organizaciones
- Equipos que necesitan c√≥mputo separado del storage

```sql
-- En dbt, conectarse a Snowflake
-- profiles.yml
snowflake:
  target: dev
  outputs:
    dev:
      type: snowflake
      account: xy12345.us-east-1
      user: dbt_user
      warehouse: TRANSFORM_WH
      database: ANALYTICS
      schema: dbt_dev
```

**Redshift - Ideal para:**
- Empresas 100% en AWS
- Cargas de trabajo predecibles (precio fijo)
- Integraci√≥n con otros servicios AWS (S3, Glue, SageMaker)
- Equipos que ya conocen PostgreSQL (sintaxis similar)

```sql
-- En dbt, conectarse a Redshift
-- profiles.yml
redshift:
  target: dev
  outputs:
    dev:
      type: redshift
      host: my-cluster.abc123.us-east-1.redshift.amazonaws.com
      user: dbt_user
      port: 5439
      dbname: analytics
      schema: dbt_dev
```

**BigQuery - Ideal para:**
- Empresas en GCP o con muchos datos de Google (Analytics, Ads)
- Cargas de trabajo impredecibles (paga por query)
- Equipos peque√±os sin tiempo para gestionar infraestructura
- An√°lisis de datos semi-estructurados (JSON, arrays)

```sql
-- En dbt, conectarse a BigQuery
-- profiles.yml
bigquery:
  target: dev
  outputs:
    dev:
      type: bigquery
      method: oauth
      project: my-gcp-project
      dataset: dbt_dev
      location: US
```

### Consideraciones de Costo

| Escenario | Snowflake | Redshift | BigQuery |
|---|---|---|---|
| Pocos queries, mucho storage | üí∞ Econ√≥mico | üí∏ Caro (cluster fijo) | üí∞ Econ√≥mico |
| Muchos queries peque√±os | ‚ö†Ô∏è Depende | üí∞ Econ√≥mico (cluster fijo) | üí∏ Puede ser caro |
| Queries espor√°dicos grandes | üí∞ Econ√≥mico (escala bajo demanda) | üí∏ Cluster subutilizado | üí∞ Econ√≥mico (serverless) |
| 24/7 producci√≥n constante | ‚ö†Ô∏è Depende del warehouse size | üí∞ Reserved instances | ‚ö†Ô∏è Depende del volumen |

**Consejo pr√°ctico**: Comienza con el DWH de tu proveedor cloud principal. Si est√°s en AWS, prueba Redshift. Si est√°s en GCP, BigQuery. Si necesitas flexibilidad o multi-cloud, Snowflake.

---

## Errores Comunes

### Error 1: Referencias Circulares

**Problema:**
- `modelo_a` hace `{{ ref('modelo_b') }}`
- `modelo_b` hace `{{ ref('modelo_a') }}`

**S√≠ntoma**: `dbt run` falla con "Circular dependency detected"

**Soluci√≥n**: Redise√±a tus modelos para que el flujo sea unidireccional (A ‚Üí B ‚Üí C, nunca C ‚Üí A).

### Error 2: Olvidar `is_incremental()`

**Problema:**
```sql
{{ config(materialized='incremental') }}

SELECT * FROM {{ ref('stg_events') }}
WHERE event_date > (SELECT MAX(event_date) FROM {{ this }})
```

**Error**: En la primera ejecuci√≥n, la tabla no existe, entonces `{{ this }}` falla.

**Soluci√≥n**: Siempre usa `is_incremental()`:
```sql
{% if is_incremental() %}
WHERE event_date > (SELECT MAX(event_date) FROM {{ this }})
{% endif %}
```

### Error 3: No testear sources

**Problema**: Tu modelo asume que `raw.customers` tiene columna `email`, pero un d√≠a un dev la renombra.

**Soluci√≥n**: Testea tus sources:
```yaml
sources:
  - name: raw
    tables:
      - name: customers
        columns:
          - name: email
            tests:
              - not_null
```

### Error 4: Macros sin documentaci√≥n

**Problema**: Creas un macro complejo, nadie sabe c√≥mo usarlo.

**Soluci√≥n**: Documenta tus macros:
```sql
{% macro generate_surrogate_key(columns) %}
{#
    Genera una surrogate key usando MD5 de m√∫ltiples columnas.

    Args:
        columns (list): Lista de nombres de columnas para incluir en el hash.

    Returns:
        String MD5 hash de las columnas concatenadas.

    Example:
        {{ generate_surrogate_key(['customer_id', 'order_date']) }}
#}
    MD5(CONCAT(
        {% for col in columns %}
        COALESCE(CAST({{ col }} AS VARCHAR), '')
        {{ "," if not loop.last }}
        {% endfor %}
    ))
{% endmacro %}
```

---

## Checklist de Aprendizaje

Antes de continuar al siguiente tema, aseg√∫rate de que puedes:

### Conceptos B√°sicos
- [ ] Explicar qu√© es dbt y por qu√© existe
- [ ] Diferenciar entre ETL y ELT
- [ ] Conocer la diferencia entre dbt Core y dbt Cloud
- [ ] Describir la estructura de un proyecto dbt

### Models
- [ ] Crear un modelo b√°sico (archivo `.sql` con SELECT)
- [ ] Entender los 4 tipos de materializaci√≥n (view, table, incremental, ephemeral)
- [ ] Usar `{{ ref('modelo') }}` para referenciar otros modelos
- [ ] Definir y usar `{{ source('schema', 'table') }}`

### Tests
- [ ] Aplicar los 4 tests gen√©ricos (unique, not_null, accepted_values, relationships)
- [ ] Crear un test personalizado
- [ ] Ejecutar `dbt test` y entender los resultados

### Documentaci√≥n
- [ ] Escribir documentaci√≥n en `schema.yml`
- [ ] Generar y explorar `dbt docs`
- [ ] Interpretar el lineage graph

### Jinja y Macros
- [ ] Usar variables y loops de Jinja en SQL
- [ ] Crear un macro simple
- [ ] Reutilizar un macro en m√∫ltiples modelos

### Avanzado
- [ ] Implementar un modelo incremental b√°sico
- [ ] Usar `is_incremental()` correctamente
- [ ] Cargar un seed CSV
- [ ] Crear un snapshot para SCD Type 2

### Buenas Pr√°cticas
- [ ] Organizar modelos en carpetas (staging, intermediate, marts)
- [ ] Nombrar modelos consistentemente (`stg_`, `int_`, `dim_`, `fct_`)
- [ ] Testear todas las primary keys y foreign keys
- [ ] Documentar modelos y columnas importantes

---

**¬°Felicidades!** Ahora entiendes los fundamentos de dbt. En la siguiente secci√≥n veremos ejemplos pr√°cticos ejecutables.

**Pr√≥ximo paso**: [`02-EJEMPLOS.md`](./02-EJEMPLOS.md) - Ejemplos progresivos de dbt desde b√°sico hasta avanzado.
