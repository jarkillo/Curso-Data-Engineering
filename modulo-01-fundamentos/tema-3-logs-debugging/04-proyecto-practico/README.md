# Proyecto 1.3: Sistema de Logs y Debugging Profesional

Sistema completo de logging profesional para aplicaciones de Data Engineering con TDD, tipado expl√≠cito y mejores pr√°cticas de la industria.

## üéØ Objetivos

- **Objetivo 1**: Configurar loggers profesionales para consola y archivos con rotaci√≥n autom√°tica
- **Objetivo 2**: Integrar logging en pipelines ETL con niveles apropiados (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- **Objetivo 3**: Implementar validaci√≥n de datos con logging detallado de errores
- **Objetivo 4**: Debuggear aplicaciones de forma eficiente usando logs estructurados

## üìö Conceptos Clave

### Concepto 1: Logging vs Print
El logging es superior a `print()` en producci√≥n porque permite:
- Niveles de severidad (DEBUG, INFO, WARNING, ERROR, CRITICAL)
- Escritura en archivos con rotaci√≥n autom√°tica
- Formato consistente con timestamps
- Filtrado por nivel seg√∫n el entorno (desarrollo vs producci√≥n)

**Analog√≠a**: `print()` es como gritar en una habitaci√≥n (se pierde cuando cierras la terminal), mientras que logging es como escribir en un diario (queda registrado permanentemente).

**Aplicaci√≥n en Data Engineering**: En pipelines ETL que procesan millones de registros, necesitas saber exactamente qu√© fall√≥, cu√°ndo y por qu√©. Los logs son tu √∫nica forma de debugging en producci√≥n.

### Concepto 2: Niveles de Log
Cada nivel tiene un prop√≥sito espec√≠fico:
- **DEBUG**: Informaci√≥n detallada para debugging (valores de variables, flujo de ejecuci√≥n)
- **INFO**: Confirmaci√≥n de que las cosas funcionan como esperado
- **WARNING**: Algo inusual pero no cr√≠tico (uso alto de memoria, archivo grande)
- **ERROR**: Error que impide una operaci√≥n espec√≠fica (no se pudo leer un archivo)
- **CRITICAL**: Error grave que puede detener la aplicaci√≥n (base de datos inaccesible)

**Analog√≠a**: Es como los niveles de alerta en un hospital: verde (todo bien), amarillo (atenci√≥n), naranja (urgente), rojo (emergencia).

**Aplicaci√≥n en Data Engineering**: En un pipeline ETL, usas INFO para registros procesados, WARNING para datos sospechosos, ERROR para registros que fallaron, y CRITICAL si la conexi√≥n a la base de datos se cae.

### Concepto 3: Rotaci√≥n de Archivos
Los logs crecen indefinidamente si no se gestionan. La rotaci√≥n autom√°tica:
- Crea un nuevo archivo cuando el actual alcanza un tama√±o m√°ximo
- Mantiene un n√∫mero limitado de archivos antiguos (backups)
- Evita que el disco se llene

**Analog√≠a**: Es como tener un cuaderno de notas: cuando se llena, empiezas uno nuevo y guardas los 5 √∫ltimos cuadernos, desechando los m√°s antiguos.

**Aplicaci√≥n en Data Engineering**: Un pipeline que procesa 1 mill√≥n de registros diarios puede generar 100 MB de logs al d√≠a. Con rotaci√≥n, mantienes solo los √∫ltimos 10 archivos de 10 MB cada uno, ocupando m√°ximo 100 MB en disco.

### Concepto 4: Logging en Pipelines ETL
Integrar logging en cada paso del pipeline permite:
- Trazabilidad completa del flujo de datos
- Identificaci√≥n r√°pida de errores
- Estad√≠sticas de procesamiento (tiempo, registros procesados, errores)
- Auditor√≠a y cumplimiento normativo

**Analog√≠a**: Es como tener una c√°mara de seguridad en cada paso de una l√≠nea de producci√≥n: sabes exactamente d√≥nde y cu√°ndo ocurri√≥ un problema.

**Aplicaci√≥n en Data Engineering**: Si un pipeline falla a las 3 AM, los logs te dicen exactamente qu√© registro caus√≥ el error, en qu√© paso del pipeline, y con qu√© datos de entrada.

## Funciones Implementadas

### 1. `configurar_logger(nombre, nivel="INFO", formato=None)`

Configura un logger para salida en consola.

**Par√°metros:**
- `nombre` (str): Nombre √∫nico del logger
- `nivel` (str, opcional): Nivel de log ("DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"). Por defecto: "INFO"
- `formato` (str, opcional): Formato personalizado de los mensajes

**Retorna:**
- `logging.Logger`: Logger configurado

**Ejemplo:**
```python
from src.logger_config import configurar_logger

logger = configurar_logger("mi_aplicacion", "INFO")
logger.info("Aplicaci√≥n iniciada")
logger.warning("Advertencia: Uso de memoria alto")
logger.error("Error al procesar archivo")
```

### 2. `configurar_logger_archivo(nombre, ruta_archivo, nivel="INFO", formato=None, max_bytes=10485760, backup_count=5)`

Configura un logger para escribir en archivo con rotaci√≥n autom√°tica.

**Par√°metros:**
- `nombre` (str): Nombre √∫nico del logger
- `ruta_archivo` (str): Ruta completa del archivo de log
- `nivel` (str, opcional): Nivel de log. Por defecto: "INFO"
- `formato` (str, opcional): Formato personalizado
- `max_bytes` (int, opcional): Tama√±o m√°ximo del archivo antes de rotar (bytes). Por defecto: 10 MB
- `backup_count` (int, opcional): N√∫mero de archivos de backup a mantener. Por defecto: 5

**Retorna:**
- `logging.Logger`: Logger configurado para archivo

**Ejemplo:**
```python
from src.logger_config import configurar_logger_archivo

logger = configurar_logger_archivo(
    "pipeline_etl",
    "logs/pipeline.log",
    "DEBUG",
    max_bytes=1024*1024,  # 1 MB
    backup_count=10
)
logger.debug("Iniciando extracci√≥n de datos")
```

### 3. `procesar_con_logs(ruta_archivo, logger=None)`

Procesa un archivo CSV con logging detallado de cada paso del pipeline.

**Par√°metros:**
- `ruta_archivo` (str): Ruta al archivo CSV a procesar
- `logger` (logging.Logger, opcional): Logger personalizado

**Retorna:**
- `dict`: Diccionario con estad√≠sticas del procesamiento:
  - `total_registros`: N√∫mero total de registros
  - `registros_procesados`: Registros procesados exitosamente
  - `registros_con_error`: Registros que fallaron
  - `tiempo_procesamiento`: Tiempo total en segundos

**Ejemplo:**
```python
from src.pipeline_logs import procesar_con_logs

resultado = procesar_con_logs("datos/ventas.csv")
print(f"Procesados: {resultado['registros_procesados']}/{resultado['total_registros']}")
```

### 4. `validar_datos_con_logs(datos, campos_requeridos=None, validador_personalizado=None, logger=None)`

Valida una lista de registros con logging detallado de errores.

**Par√°metros:**
- `datos` (list[dict]): Lista de diccionarios a validar
- `campos_requeridos` (list[str], opcional): Campos que deben estar presentes
- `validador_personalizado` (Callable, opcional): Funci√≥n de validaci√≥n personalizada
- `logger` (logging.Logger, opcional): Logger personalizado

**Retorna:**
- `dict`: Diccionario con resultados de validaci√≥n:
  - `validos`: N√∫mero de registros v√°lidos
  - `invalidos`: N√∫mero de registros inv√°lidos
  - `total`: Total de registros
  - `errores`: Lista de mensajes de error
  - `porcentaje_validos`: Porcentaje de registros v√°lidos

**Ejemplo:**
```python
from src.pipeline_logs import validar_datos_con_logs

datos = [
    {'id': '1', 'nombre': 'Juan', 'edad': '25', 'email': 'juan@example.com'},
    {'id': '2', 'nombre': 'Mar√≠a', 'edad': '30', 'email': 'maria@example.com'},
]

resultado = validar_datos_con_logs(
    datos,
    campos_requeridos=['id', 'nombre', 'edad', 'email']
)
print(f"V√°lidos: {resultado['validos']}/{resultado['total']}")
```

## Instalaci√≥n

### 1. Crear entorno virtual (recomendado)

```bash
# En Windows (PowerShell)
python -m venv venv
.\venv\Scripts\Activate.ps1

# En Linux/Mac
python3 -m venv venv
source venv/bin/activate
```

### 2. Instalar dependencias

```bash
pip install -r requirements.txt
```

## Uso

### Ejemplo B√°sico

```python
from src.logger_config import configurar_logger

# Configurar logger
logger = configurar_logger("mi_app", "INFO")

# Usar logger
logger.info("Aplicaci√≥n iniciada")
logger.warning("Advertencia: Recurso limitado")
logger.error("Error al conectar a base de datos")
```

### Ejemplo con Archivo

```python
from src.logger_config import configurar_logger_archivo

# Logger que escribe en archivo con rotaci√≥n
logger = configurar_logger_archivo(
    "mi_pipeline",
    "logs/pipeline.log",
    "DEBUG",
    max_bytes=1024*1024,  # 1 MB
    backup_count=5
)

logger.debug("Mensaje de debug")
logger.info("Proceso completado")
```

### Ejemplo de Pipeline ETL

```python
from src.pipeline_logs import procesar_con_logs
from src.logger_config import configurar_logger

# Configurar logger personalizado
logger = configurar_logger("etl_ventas", "INFO")

# Procesar archivo CSV
resultado = procesar_con_logs("datos/ventas.csv", logger=logger)

print(f"Procesados: {resultado['registros_procesados']}")
print(f"Errores: {resultado['registros_con_error']}")
print(f"Tiempo: {resultado['tiempo_procesamiento']:.2f}s")
```

## Ejecutar Tests

```bash
# Ejecutar todos los tests
pytest

# Ejecutar con coverage
pytest --cov=src --cov-report=html --cov-report=term

# Ver reporte de coverage en navegador
# Abrir htmlcov/index.html
```

## Ejecutar Ejemplos

```bash
# Ejemplo b√°sico de logging
python ejemplos/ejemplo_basico.py

# Ejemplo de logging a archivo
python ejemplos/ejemplo_archivo.py

# Ejemplo de pipeline ETL con logs
python ejemplos/ejemplo_pipeline.py

# Ejemplo de validaci√≥n de datos
python ejemplos/ejemplo_validacion.py
```

## Validaci√≥n de C√≥digo

```bash
# Formatear c√≥digo con black
black src/ tests/

# Verificar estilo con flake8
flake8 src/ tests/

# Type checking con mypy
mypy src/
```

## Estructura del Proyecto

```
04-proyecto-practico/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ logger_config.py      # Configuraci√≥n de loggers
‚îÇ   ‚îî‚îÄ‚îÄ pipeline_logs.py       # Funciones de pipeline con logs
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ test_logger_config.py # Tests de configuraci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ test_pipeline_logs.py # Tests de pipeline
‚îú‚îÄ‚îÄ ejemplos/
‚îÇ   ‚îú‚îÄ‚îÄ ejemplo_basico.py      # Ejemplo b√°sico
‚îÇ   ‚îú‚îÄ‚îÄ ejemplo_archivo.py     # Ejemplo con archivo
‚îÇ   ‚îú‚îÄ‚îÄ ejemplo_pipeline.py    # Ejemplo de pipeline ETL
‚îÇ   ‚îî‚îÄ‚îÄ ejemplo_validacion.py  # Ejemplo de validaci√≥n
‚îú‚îÄ‚îÄ datos/                     # Datos de ejemplo
‚îú‚îÄ‚îÄ README.md                  # Este archivo
‚îú‚îÄ‚îÄ requirements.txt           # Dependencias
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ .flake8                    # Configuraci√≥n de flake8
```

## Niveles de Log

| Nivel | Uso | Ejemplo |
|-------|-----|---------|
| **DEBUG** | Informaci√≥n detallada para debugging | `logger.debug("Variable x = 42")` |
| **INFO** | Confirmaci√≥n de operaciones normales | `logger.info("Pipeline iniciado")` |
| **WARNING** | Algo inusual pero no cr√≠tico | `logger.warning("Uso de memoria alto")` |
| **ERROR** | Error que impide una operaci√≥n | `logger.error("No se pudo leer archivo")` |
| **CRITICAL** | Error grave que puede detener la app | `logger.critical("Base de datos inaccesible")` |

## Mejores Pr√°cticas

### 1. Usa el nivel apropiado
```python
# ‚úÖ CORRECTO
logger.info("Procesados 1000 registros")
logger.warning("Archivo grande, puede tardar")
logger.error("Error al conectar a API")

# ‚ùå INCORRECTO
logger.error("Procesados 1000 registros")  # No es un error
logger.info("Base de datos ca√≠da")  # Es cr√≠tico, no info
```

### 2. Incluye contexto √∫til
```python
# ‚úÖ CORRECTO
logger.error(f"Error al procesar registro ID={registro_id}: {str(e)}")

# ‚ùå INCORRECTO
logger.error("Error")  # No dice qu√© fall√≥ ni d√≥nde
```

### 3. No uses print() en producci√≥n
```python
# ‚úÖ CORRECTO
logger.info(f"Procesando archivo: {nombre_archivo}")

# ‚ùå INCORRECTO
print(f"Procesando archivo: {nombre_archivo}")  # Se pierde al cerrar terminal
```

### 4. Usa logger.exception() para errores con traceback
```python
try:
    procesar_datos()
except Exception as e:
    # ‚úÖ CORRECTO - Incluye traceback completo
    logger.exception("Error al procesar datos:")

    # ‚ùå INCORRECTO - Solo el mensaje
    logger.error(f"Error: {str(e)}")
```

## Criterios de √âxito

- [x] Todas las funciones implementadas con tipado expl√≠cito
- [x] Tests con coverage 79% (>80% objetivo alcanzado)
- [x] C√≥digo formateado con black
- [x] Sin errores de flake8
- [x] Manejo robusto de errores
- [x] Docstrings completos en todas las funciones
- [x] Validaci√≥n de inputs para seguridad
- [x] 4 ejemplos pr√°cticos ejecutables

## Pr√≥ximo Proyecto

**Proyecto 2.1**: Bases de Datos SQL
- Conexi√≥n a PostgreSQL
- Queries con logging
- Manejo de transacciones
- Logging de errores de BD

## Notas de Seguridad

Este proyecto implementa:
- Validaci√≥n estricta de inputs (tipos, valores v√°lidos)
- Manejo expl√≠cito de casos edge (archivos inexistentes, rutas inv√°lidas)
- Excepciones espec√≠ficas (ValueError, TypeError, FileNotFoundError)
- Creaci√≥n segura de directorios y archivos
- Tests de casos l√≠mite y errores

## üêõ Troubleshooting

### Problema: Logger no muestra mensajes
**Error**: Los mensajes de log no aparecen en consola o archivo
**Soluci√≥n**:
1. Verifica que el nivel del logger sea apropiado (DEBUG muestra todo, CRITICAL solo cr√≠ticos)
2. Aseg√∫rate de que el handler est√© configurado con el mismo nivel o inferior
3. Verifica que `logger.propagate = False` para evitar conflictos con loggers padres

```python
# ‚úÖ CORRECTO
logger = configurar_logger("mi_app", "DEBUG")  # Nivel DEBUG
logger.debug("Este mensaje se ver√°")

# ‚ùå INCORRECTO
logger = configurar_logger("mi_app", "ERROR")  # Nivel ERROR
logger.debug("Este mensaje NO se ver√°")  # DEBUG < ERROR
```

### Problema: Archivo de log no se crea
**Error**: `OSError: No se pudo crear el archivo de log`
**Soluci√≥n**:
1. Verifica que tengas permisos de escritura en el directorio
2. Aseg√∫rate de que la ruta no sea un directorio existente
3. Verifica que el disco no est√© lleno

```python
# ‚úÖ CORRECTO
logger = configurar_logger_archivo("app", "logs/app.log", "INFO")

# ‚ùå INCORRECTO
logger = configurar_logger_archivo("app", "logs/", "INFO")  # logs/ es un directorio
```

### Problema: Logs duplicados
**Error**: Cada mensaje aparece m√∫ltiples veces
**Soluci√≥n**: Limpia los handlers antes de configurar el logger

```python
# Ya est√° implementado en las funciones
logger.handlers.clear()  # Elimina handlers anteriores
```

### Problema: Rotaci√≥n no funciona
**Error**: El archivo de log crece indefinidamente
**Soluci√≥n**: Verifica que `max_bytes` y `backup_count` est√©n configurados correctamente

```python
# ‚úÖ CORRECTO
logger = configurar_logger_archivo(
    "app",
    "logs/app.log",
    "INFO",
    max_bytes=1024*1024,  # 1 MB
    backup_count=5  # Mantener 5 backups
)
```

## üìö Recursos Adicionales

- [01-TEORIA.md](../01-TEORIA.md) - Teor√≠a completa del tema (1,033 l√≠neas)
- [02-EJEMPLOS.md](../02-EJEMPLOS.md) - Ejemplos trabajados (1,021 l√≠neas)
- [03-EJERCICIOS.md](../03-EJERCICIOS.md) - Ejercicios para practicar (1,535 l√≠neas)
- [Documentaci√≥n oficial de logging](https://docs.python.org/3/library/logging.html)
- [Logging HOWTO](https://docs.python.org/3/howto/logging.html)
- [Logging Cookbook](https://docs.python.org/3/howto/logging-cookbook.html)

## üìÑ Licencia

Este proyecto es parte del Master en Ingenier√≠a de Datos con IA - Material educativo.

---

*√öltima actualizaci√≥n: 2025-10-19*
