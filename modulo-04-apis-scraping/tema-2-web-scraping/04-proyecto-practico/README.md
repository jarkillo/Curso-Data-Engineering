# üï∑Ô∏è Proyecto Pr√°ctico: Scraper de E-Commerce con TDD

**Tema 2: Web Scraping**
**M√≥dulo 4: APIs y Web Scraping**
**Master en Ingenier√≠a de Datos**

---

## üìã Descripci√≥n del Proyecto

**Scraper robusto y √©tico** para extraer datos de productos de e-commerce ficticios, desarrollado con **Test-Driven Development (TDD)**.

### üéØ Objetivo

Crear un sistema completo de scraping que:
- ‚úÖ Extrae datos de p√°ginas HTML est√°ticas (BeautifulSoup)
- ‚úÖ Maneja contenido din√°mico JavaScript (Selenium)
- ‚úÖ Valida y limpia datos extra√≠dos
- ‚úÖ Respeta robots.txt y √©tica del scraping
- ‚úÖ Almacena datos en SQLite con historial
- ‚úÖ Implementa rate limiting y logging

---

## üèóÔ∏è Arquitectura del Proyecto

```
04-proyecto-practico/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ scraper_html.py         # Parseo con BeautifulSoup (5 funciones)
‚îÇ   ‚îú‚îÄ‚îÄ scraper_selenium.py     # Scraping din√°mico (3 funciones)
‚îÇ   ‚îú‚îÄ‚îÄ validador_scraping.py   # Validaci√≥n de datos (4 funciones)
‚îÇ   ‚îú‚îÄ‚îÄ almacenamiento.py       # Guardar en SQLite (3 funciones)
‚îÇ   ‚îî‚îÄ‚îÄ utilidades_scraping.py  # Rate limiting, robots.txt (4 funciones)
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ test_scraper_html.py    # 15 tests
‚îÇ   ‚îú‚îÄ‚îÄ test_scraper_selenium.py # 12 tests
‚îÇ   ‚îú‚îÄ‚îÄ test_validador.py       # 16 tests
‚îÇ   ‚îú‚îÄ‚îÄ test_almacenamiento.py  # 12 tests
‚îÇ   ‚îî‚îÄ‚îÄ test_utilidades.py      # 16 tests
‚îÇ
‚îú‚îÄ‚îÄ ejemplos/
‚îÇ   ‚îú‚îÄ‚îÄ 01_scraping_basico.py
‚îÇ   ‚îú‚îÄ‚îÄ 02_scraping_selenium.py
‚îÇ   ‚îú‚îÄ‚îÄ 03_pipeline_completo.py
‚îÇ   ‚îî‚îÄ‚îÄ html_ejemplo.html
‚îÇ
‚îú‚îÄ‚îÄ data/                       # (generado al ejecutar)
‚îÇ   ‚îî‚îÄ‚îÄ productos.db
‚îÇ
‚îú‚îÄ‚îÄ logs/                       # (generado al ejecutar)
‚îÇ   ‚îî‚îÄ‚îÄ scraper.log
‚îÇ
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ pytest.ini
‚îî‚îÄ‚îÄ README.md (este archivo)
```

---

## üì¶ M√≥dulos del Proyecto

### 1Ô∏è‚É£ `scraper_html.py` - Scraping con BeautifulSoup

**Funciones implementadas:**

| Funci√≥n                                 | Descripci√≥n                            | Tests |
| --------------------------------------- | -------------------------------------- | ----- |
| `extraer_productos(html, selector)`     | Extrae lista de productos con selector | 3     |
| `extraer_titulo(producto_elem)`         | Extrae nombre del producto             | 3     |
| `extraer_precio(producto_elem)`         | Extrae precio y lo limpia              | 3     |
| `extraer_rating(producto_elem)`         | Extrae rating (estrellas)              | 3     |
| `extraer_disponibilidad(producto_elem)` | Verifica stock                         | 3     |

**Total tests:** 15

---

### 2Ô∏è‚É£ `scraper_selenium.py` - Scraping Din√°mico

**Funciones implementadas:**

| Funci√≥n                                       | Descripci√≥n                  | Tests |
| --------------------------------------------- | ---------------------------- | ----- |
| `inicializar_driver(headless=True)`           | Configura Selenium WebDriver | 3     |
| `esperar_elemento(driver, selector, timeout)` | Espera carga de JS           | 4     |
| `extraer_datos_dinamicos(driver, url)`        | Scrapea p√°gina con JS        | 5     |

**Total tests:** 12

---

### 3Ô∏è‚É£ `validador_scraping.py` - Validaci√≥n de Datos

**Funciones implementadas:**

| Funci√≥n                               | Descripci√≥n                 | Tests |
| ------------------------------------- | --------------------------- | ----- |
| `validar_precio(precio_str)`          | Convierte "$1,299" ‚Üí 1299.0 | 4     |
| `validar_nombre(nombre)`              | Verifica nombre no vac√≠o    | 4     |
| `validar_rating(rating)`              | Valida rating 0-5           | 4     |
| `validar_producto_completo(producto)` | Valida todos los campos     | 4     |

**Total tests:** 16

---

### 4Ô∏è‚É£ `almacenamiento.py` - Persistencia en SQLite

**Funciones implementadas:**

| Funci√≥n                               | Descripci√≥n             | Tests |
| ------------------------------------- | ----------------------- | ----- |
| `crear_base_datos(db_path)`           | Crea tabla de productos | 3     |
| `guardar_producto(db_path, producto)` | Inserta producto        | 5     |
| `obtener_productos(db_path, filtros)` | Query productos         | 4     |

**Total tests:** 12

---

### 5Ô∏è‚É£ `utilidades_scraping.py` - Herramientas de Soporte

**Funciones implementadas:**

| Funci√≥n                                 | Descripci√≥n                | Tests |
| --------------------------------------- | -------------------------- | ----- |
| `verificar_robots_txt(url, user_agent)` | Valida robots.txt          | 4     |
| `obtener_user_agent()`                  | Genera User-Agent realista | 3     |
| `rate_limiter(delay_segundos)`          | Decorador de rate limiting | 4     |
| `configurar_logging(log_file)`          | Setup logging              | 5     |

**Total tests:** 16

---

## üìä Resumen de Tests

| M√≥dulo                   | Funciones | Tests  | Cobertura Objetivo |
| ------------------------ | --------- | ------ | ------------------ |
| `scraper_html.py`        | 5         | 15     | >90%               |
| `scraper_selenium.py`    | 3         | 12     | >85%               |
| `validador_scraping.py`  | 4         | 16     | >95%               |
| `almacenamiento.py`      | 3         | 12     | >90%               |
| `utilidades_scraping.py` | 4         | 16     | >90%               |
| **TOTAL**                | **19**    | **71** | **>90%**           |

---

## üöÄ Instalaci√≥n

### Requisitos

- Python 3.8+
- pip

### Paso 1: Crear entorno virtual

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux/Mac
source venv/bin/activate
```

### Paso 2: Instalar dependencias

```bash
pip install -r requirements.txt
```

### Paso 3: Verificar instalaci√≥n

```bash
pytest --version
```

---

## üß™ Ejecutar Tests

### Todos los tests

```bash
pytest
```

### Tests con cobertura

```bash
pytest --cov=src --cov-report=html
```

### Tests de un m√≥dulo espec√≠fico

```bash
pytest tests/test_scraper_html.py
```

### Tests con verbose

```bash
pytest -v
```

---

## üíª Uso del Proyecto

### Ejemplo 1: Scraping B√°sico

```python
from src.scraper_html import extraer_productos, extraer_titulo, extraer_precio

# HTML de ejemplo
html = """
<div class="producto">
    <h2 class="nombre">Laptop Dell XPS</h2>
    <span class="precio">$1,299.99</span>
</div>
"""

# Extraer productos
productos = extraer_productos(html, 'div.producto')

for prod in productos:
    nombre = extraer_titulo(prod)
    precio = extraer_precio(prod)
    print(f"{nombre}: ${precio}")
```

### Ejemplo 2: Scraping con Selenium

```python
from src.scraper_selenium import inicializar_driver, extraer_datos_dinamicos

# Inicializar driver
driver = inicializar_driver(headless=True)

try:
    # Scrapear p√°gina con JavaScript
    url = "https://ejemplo.com/productos"
    productos = extraer_datos_dinamicos(driver, url)

    for prod in productos:
        print(prod)
finally:
    driver.quit()
```

### Ejemplo 3: Pipeline Completo

```python
from src.scraper_html import extraer_productos
from src.validador_scraping import validar_producto_completo
from src.almacenamiento import guardar_producto
from src.utilidades_scraping import rate_limiter, configurar_logging

# Setup
configurar_logging('logs/scraper.log')

@rate_limiter(delay_segundos=2)
def scrapear_url(url):
    # Scraping + Validaci√≥n + Almacenamiento
    productos = extraer_productos(html, 'div.producto')

    for prod in productos:
        if validar_producto_completo(prod):
            guardar_producto('data/productos.db', prod)

# Ejecutar
scrapear_url('https://ejemplo.com/productos')
```

---

## üìä Estructura de Datos

### Producto (Dict)

```python
producto = {
    'nombre': str,          # "Dell XPS 13"
    'precio': float,        # 1299.99
    'rating': float,        # 4.8 (0-5)
    'disponibilidad': str,  # "En stock" | "Agotado"
    'descripcion': str,     # "Ultrabook potente..."
    'url': str,             # URL del producto
    'fecha_scraping': str,  # ISO format: "2025-10-23T14:30:00"
}
```

### Tabla SQLite: `productos`

```sql
CREATE TABLE productos (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    nombre TEXT NOT NULL,
    precio REAL NOT NULL,
    rating REAL,
    disponibilidad TEXT,
    descripcion TEXT,
    url TEXT,
    fecha_scraping TEXT NOT NULL,
    UNIQUE(nombre, fecha_scraping)  -- Evitar duplicados del mismo d√≠a
);
```

---

## üéì Conceptos Aprendidos

### 1. Test-Driven Development (TDD)

‚úÖ **Red-Green-Refactor:**
1. üî¥ Escribir test que falla
2. üü¢ Implementar c√≥digo m√≠nimo para pasar
3. üîµ Refactorizar manteniendo tests verdes

### 2. Web Scraping con BeautifulSoup

‚úÖ Selectores CSS (`div.producto span.precio`)
‚úÖ Navegaci√≥n del DOM (parent, children)
‚úÖ Extracci√≥n de texto y atributos

### 3. Selenium para Contenido Din√°mico

‚úÖ WebDriver setup (Chrome, Firefox)
‚úÖ Esperas expl√≠citas vs impl√≠citas
‚úÖ Interacci√≥n con JavaScript

### 4. Validaci√≥n de Datos

‚úÖ Limpieza de strings ("$1,299" ‚Üí 1299.0)
‚úÖ Validaci√≥n de rangos (rating 0-5)
‚úÖ Manejo de valores nulos

### 5. Scraping √âtico

‚úÖ Verificaci√≥n de robots.txt
‚úÖ Rate limiting (delay entre requests)
‚úÖ User-Agent identificable
‚úÖ Logging de acciones

### 6. Persistencia en SQLite

‚úÖ Creaci√≥n de tablas
‚úÖ Inserts con validaci√≥n (UNIQUE)
‚úÖ Queries con filtros

---

## üîß Configuraci√≥n Avanzada

### `pytest.ini`

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
addopts =
    -v
    --strict-markers
    --tb=short
    --cov=src
    --cov-report=term-missing
markers =
    scraper: Tests de scraping
    validacion: Tests de validaci√≥n
    db: Tests de base de datos
```

### `requirements.txt`

```txt
# Core
beautifulsoup4==4.12.2
selenium==4.15.2
requests==2.31.0

# Database
# (sqlite3 viene incluido en Python)

# Testing
pytest==7.4.3
pytest-cov==4.1.0
pytest-timeout==2.2.0

# Utilities
python-dotenv==1.0.0
```

---

## üêõ Troubleshooting

### Problema: Selenium no encuentra ChromeDriver

**Soluci√≥n:**
```bash
# Instalar webdriver-manager
pip install webdriver-manager

# Usar en c√≥digo
from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager

driver = webdriver.Chrome(ChromeDriverManager().install())
```

### Problema: Tests fallan por timeout

**Soluci√≥n:**
```python
# En pytest.ini, aumentar timeout
addopts = --timeout=30

# O en test espec√≠fico
@pytest.mark.timeout(30)
def test_scraping_lento():
    pass
```

### Problema: Error de encoding en Windows

**Soluci√≥n:**
```python
# Forzar UTF-8 en archivos
with open('file.txt', 'r', encoding='utf-8') as f:
    content = f.read()
```

---

## üìà M√©tricas de Calidad

### Cobertura de Tests

```bash
$ pytest --cov=src --cov-report=term-missing

----------- coverage: platform win32, python 3.11 -----------
Name                           Stmts   Miss  Cover   Missing
------------------------------------------------------------
src/scraper_html.py               45      2    96%   23, 45
src/scraper_selenium.py           32      3    91%   15-17
src/validador_scraping.py         38      1    97%   50
src/almacenamiento.py             28      2    93%   25, 40
src/utilidades_scraping.py        35      2    94%   18, 42
------------------------------------------------------------
TOTAL                            178      10   94%
```

### Flake8 (Linting)

```bash
$ flake8 src/ tests/ --max-line-length=88
# 0 errores
```

### Black (Formatting)

```bash
$ black src/ tests/ --check
All done! ‚ú® üç∞ ‚ú®
35 files would be left unchanged.
```

---

## üéØ Pr√≥ximos Pasos

Una vez completado este proyecto, estar√°s listo para:

1. ‚úÖ **Tema 3:** Rate Limiting y Caching (optimizaci√≥n de scrapers)
2. ‚úÖ Implementar scrapers en producci√≥n
3. ‚úÖ Integrar scraping en pipelines ETL
4. ‚úÖ Scrapear sitios reales (con permiso)

---

## üìö Recursos Adicionales

**Documentaci√≥n:**
- [BeautifulSoup Docs](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Selenium Python Docs](https://selenium-python.readthedocs.io/)
- [Pytest Docs](https://docs.pytest.org/)

**Tutoriales:**
- [Real Python - Web Scraping](https://realpython.com/beautiful-soup-web-scraper-python/)
- [Selenium with Python Tutorial](https://selenium-python.readthedocs.io/getting-started.html)

---

## ü§ù Contribuciones

Este es un proyecto educativo del **Master en Ingenier√≠a de Datos - DataHub Inc.**

---

**Autor:** Equipo DataHub Inc.
**√öltima actualizaci√≥n:** 2025-10-23
**Versi√≥n:** 1.0.0

---

*"El scraping es como la pesca: necesitas paciencia, la herramienta correcta, y respetar las reglas del lago." üé£*
