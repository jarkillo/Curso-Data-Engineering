# üåê M√≥dulo 4: APIs y Web Scraping

**Master en Ingenier√≠a de Datos**
**Nivel:** Intermedio
**Duraci√≥n estimada:** 3-4 semanas
**Estado:** ‚úÖ **COMPLETADO (100%)**

---

## üéØ Objetivos Generales del M√≥dulo

Al completar este m√≥dulo, ser√°s capaz de:

1. ‚úÖ **Consumir APIs REST** profesionalmente (GET, POST, PUT, DELETE, autenticaci√≥n)
2. ‚úÖ **Extraer datos de sitios web** con web scraping √©tico (BeautifulSoup, Selenium)
3. ‚úÖ **Optimizar pipelines de extracci√≥n** con rate limiting, caching y async programming
4. ‚úÖ **Manejar errores y reintentos** de forma robusta (exponential backoff, timeouts)
5. ‚úÖ **Implementar paginaci√≥n** autom√°tica (Offset/Limit, Cursor-based)
6. ‚úÖ **Respetar √©tica y legalidad** (robots.txt, rate limits, t√©rminos de servicio)
7. ‚úÖ **Medir y monitorear performance** (throughput, latencia, cache hit rate, ROI)
8. ‚úÖ **Aplicar TDD** en extracci√≥n de datos (210 tests totales)

---

## üìä Progreso del M√≥dulo

```
M√≥dulo 4: APIs y Web Scraping
‚îú‚îÄ‚îÄ ‚úÖ Tema 1: APIs REST (100%)
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Teor√≠a: ~4,500 palabras
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Ejemplos: 5 ejemplos trabajados
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Ejercicios: 15 con soluciones
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Proyecto pr√°ctico: 98 tests, 100% cobertura
‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ Calificaci√≥n pedag√≥gica: 9.2/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
‚îÇ
‚îú‚îÄ‚îÄ ‚úÖ Tema 2: Web Scraping (100%)
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Teor√≠a: ~4,200 palabras
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Ejemplos: 5 ejemplos trabajados
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Ejercicios: 15 con soluciones
‚îÇ   ‚îú‚îÄ‚îÄ ‚úÖ Proyecto pr√°ctico: 71 tests, 90% cobertura
‚îÇ   ‚îî‚îÄ‚îÄ ‚úÖ Calificaci√≥n pedag√≥gica: 9.3/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
‚îÇ
‚îî‚îÄ‚îÄ ‚úÖ Tema 3: Rate Limiting y Caching (100%)
    ‚îú‚îÄ‚îÄ ‚úÖ Teor√≠a: ~3,500 palabras
    ‚îú‚îÄ‚îÄ ‚úÖ Ejemplos: 4 ejemplos trabajados
    ‚îú‚îÄ‚îÄ ‚úÖ Ejercicios: 12 con soluciones
    ‚îú‚îÄ‚îÄ ‚úÖ Proyecto pr√°ctico: 41 tests, 88% cobertura
    ‚îî‚îÄ‚îÄ ‚úÖ Calificaci√≥n pedag√≥gica: 9.4/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
```

**Progreso total:** 3/3 temas completados ‚úÖ

---

## üìö Estructura de los 3 Temas

### Tema 1: APIs REST

**Objetivo:** Dominar el consumo de APIs REST de forma profesional.

**Contenido:**
- üìñ **Teor√≠a:** HTTP, status codes, autenticaci√≥n, rate limiting, paginaci√≥n
- üíª **Ejemplos:** GET, POST, API Key, paginaci√≥n autom√°tica, reintentos
- ‚úçÔ∏è **Ejercicios:** 15 ejercicios progresivos (b√°sico ‚Üí avanzado)
- üèóÔ∏è **Proyecto:** Cliente HTTP robusto con 5 m√≥dulos y 98 tests

**Tecnolog√≠as:** `requests`, `dotenv`, type hints, TDD

**Duraci√≥n:** 1-1.5 semanas

[üìÇ Ver Tema 1](tema-1-apis-rest/)

---

### Tema 2: Web Scraping

**Objetivo:** Extraer datos de sitios web de forma √©tica y eficiente.

**Contenido:**
- üìñ **Teor√≠a:** HTML/DOM, BeautifulSoup, Selenium, robots.txt, XPath
- üíª **Ejemplos:** Scraping est√°tico, tablas, navegaci√≥n, scraping din√°mico
- ‚úçÔ∏è **Ejercicios:** 15 ejercicios con casos reales (noticias, e-commerce)
- üèóÔ∏è **Proyecto:** Scraper completo con 5 m√≥dulos y 71 tests

**Tecnolog√≠as:** `beautifulsoup4`, `selenium`, `sqlite3`, `pandas`

**Duraci√≥n:** 1-1.5 semanas

[üìÇ Ver Tema 2](tema-2-web-scraping/)

---

### Tema 3: Rate Limiting y Caching

**Objetivo:** Optimizar scrapers para ser 10x-20x m√°s r√°pidos.

**Contenido:**
- üìñ **Teor√≠a:** Rate limiting algorithms, caching strategies, async programming
- üíª **Ejemplos:** Token Bucket, cache con TTL, async requests, m√©tricas
- ‚úçÔ∏è **Ejercicios:** 12 ejercicios de optimizaci√≥n con ROI
- üèóÔ∏è **Proyecto:** Scraper optimizado con 4 m√≥dulos y 55 tests

**Tecnolog√≠as:** `aiohttp`, `asyncio`, `shelve`, m√©tricas

**Duraci√≥n:** 1-1.5 semanas

[üìÇ Ver Tema 3](tema-3-rate-limiting-caching/)

---

## üöÄ C√≥mo Estudiar Este M√≥dulo

### Orden Recomendado

#### Semana 1: Tema 1 - APIs REST

1. **D√≠a 1-2:** Teor√≠a + Ejemplos (APIs REST, autenticaci√≥n)
2. **D√≠a 3-4:** Ejercicios b√°sicos e intermedios
3. **D√≠a 5-7:** Proyecto pr√°ctico (TDD: cliente HTTP robusto)

**Hito:** Consumir APIs REST con autenticaci√≥n y manejo de errores ‚úÖ

---

#### Semana 2: Tema 2 - Web Scraping

1. **D√≠a 1-2:** Teor√≠a + Ejemplos (BeautifulSoup, Selenium)
2. **D√≠a 3-4:** Ejercicios b√°sicos e intermedios
3. **D√≠a 5-7:** Proyecto pr√°ctico (TDD: scraper completo)

**Hito:** Extraer datos de sitios web est√°ticos y din√°micos ‚úÖ

---

#### Semana 3: Tema 3 - Optimizaci√≥n

1. **D√≠a 1-2:** Teor√≠a + Ejemplos (rate limiting, caching, async)
2. **D√≠a 3-4:** Ejercicios de optimizaci√≥n
3. **D√≠a 5-7:** Proyecto pr√°ctico (TDD: scraper optimizado)

**Hito:** Optimizar scrapers 10x-20x m√°s r√°pido ‚úÖ

---

#### Semana 4 (Opcional): Integraci√≥n y Pr√°ctica

1. **D√≠a 1-3:** Proyecto integrador (combinar los 3 temas)
2. **D√≠a 4-5:** Optimizaci√≥n y medici√≥n de ROI
3. **D√≠a 6-7:** Documentaci√≥n y presentaci√≥n

**Hito:** Pipeline de extracci√≥n completo y optimizado ‚úÖ

---

## üéì Competencias Desarrolladas

Al completar este m√≥dulo, habr√°s dominado:

### Competencias T√©cnicas

1. ‚úÖ **REST APIs:** GET, POST, PUT, DELETE con `requests`
2. ‚úÖ **Autenticaci√≥n:** API Key, Bearer Token, Basic Auth, OAuth
3. ‚úÖ **Web Scraping:** BeautifulSoup (est√°tico) y Selenium (din√°mico)
4. ‚úÖ **Parsing:** HTML, CSS Selectors, XPath, JSON
5. ‚úÖ **Rate Limiting:** Fixed Window, Token Bucket algorithms
6. ‚úÖ **Caching:** Memoria, disco (`shelve`), TTL strategies
7. ‚úÖ **Async Programming:** `aiohttp`, `asyncio`, concurrency control
8. ‚úÖ **Manejo de Errores:** Exponential backoff, reintentos, timeouts
9. ‚úÖ **Paginaci√≥n:** Offset/Limit, Cursor-based
10. ‚úÖ **TDD:** Test-Driven Development aplicado a extracci√≥n de datos

### Competencias Profesionales

11. ‚úÖ **√âtica del Scraping:** Robots.txt, rate limits, t√©rminos de servicio
12. ‚úÖ **Performance Tuning:** Medir throughput, latencia, optimizar 10x-20x
13. ‚úÖ **C√°lculo de ROI:** Justificar optimizaciones con datos econ√≥micos
14. ‚úÖ **Documentaci√≥n:** README, docstrings, ejemplos ejecutables
15. ‚úÖ **Debugging:** Logging, manejo de errores, troubleshooting

---

## üìä M√©tricas del M√≥dulo

| M√©trica                     | Valor         | Detalles                                            |
| --------------------------- | ------------- | --------------------------------------------------- |
| **Temas completados**       | 3/3           | 100% ‚úÖ                                              |
| **Teor√≠a (palabras)**       | ~12,200       | APIs: 4,500 / Scraping: 4,200 / Optimizaci√≥n: 3,500 |
| **Ejemplos**                | 14 ejemplos   | Tema 1: 5 / Tema 2: 5 / Tema 3: 4                   |
| **Ejercicios**              | 42 ejercicios | Tema 1: 15 / Tema 2: 15 / Tema 3: 12                |
| **Proyectos pr√°cticos**     | 3 proyectos   | TDD estricto en todos                               |
| **Tests totales**           | 210 tests     | Tema 1: 98 / Tema 2: 71 / Tema 3: 41 (ejecutables)  |
| **Cobertura promedio**      | 93%           | Tema 1: 100% / Tema 2: 90% / Tema 3: 88%            |
| **Funciones implementadas** | 55 funciones  | Tema 1: 19 / Tema 2: 19 / Tema 3: 17                |
| **Calificaci√≥n pedag√≥gica** | 9.3/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  | Tema 1: 9.2 / Tema 2: 9.3 / Tema 3: 9.4             |

---

## ‚úÖ Criterios de √âxito del M√≥dulo

### Nivel B√°sico (M√≠nimo)

- [ ] Consumo APIs REST con `requests` (GET, POST)
- [ ] Manejo b√°sico de status codes (200, 404, 500)
- [ ] Autenticaci√≥n con API Key
- [ ] Scraping est√°tico con BeautifulSoup
- [ ] Extracci√≥n de texto, enlaces, tablas HTML
- [ ] Rate limiting manual con `time.sleep()`
- [ ] Cache en memoria con diccionarios

### Nivel Intermedio (Recomendado)

- [ ] Autenticaci√≥n m√∫ltiple (API Key, Bearer, Basic Auth)
- [ ] Manejo robusto de errores (try/except, reintentos)
- [ ] Paginaci√≥n autom√°tica (Offset/Limit)
- [ ] Scraping din√°mico con Selenium
- [ ] Validaci√≥n de robots.txt
- [ ] Almacenamiento en SQLite
- [ ] Token Bucket rate limiting
- [ ] Cache persistente con `shelve` y TTL
- [ ] Async requests con `aiohttp`

### Nivel Avanzado (Opcional)

- [ ] Pipeline ETL completo: API/Scraping ‚Üí Transform ‚Üí Storage
- [ ] Exponential backoff para reintentos
- [ ] Cursor-based pagination
- [ ] Scraping masivo (100+ URLs) optimizado
- [ ] Integraci√≥n async + cache + rate limiting + m√©tricas
- [ ] Monitoreo de throughput, latencia, cache hit rate
- [ ] C√°lculo de ROI (tiempo, costo, mejora de velocidad)
- [ ] Dashboard de m√©tricas en ASCII art
- [ ] Optimizaci√≥n 10x-20x en velocidad

---

## üîó Integraci√≥n con Otros M√≥dulos

### Pre-requisitos

- **M√≥dulo 1:** Python fundamentals, funciones, tipos de datos
- **M√≥dulo 2:** SQL b√°sico para almacenar datos extra√≠dos
- **M√≥dulo 3:** Conceptos de ETL/ELT

### Complementa con

- **M√≥dulo 5:** Bases de Datos Avanzadas (PostgreSQL, MongoDB) para almacenar datos scrapeados
- **M√≥dulo 6:** Apache Airflow para orquestar scrapers peri√≥dicos
- **M√≥dulo 7:** Cloud (AWS/GCP) para desplegar scrapers en producci√≥n

---

## üìÅ Estructura de Archivos

```
modulo-04-apis-scraping/
‚îú‚îÄ‚îÄ tema-1-apis-rest/
‚îÇ   ‚îú‚îÄ‚îÄ 01-TEORIA.md
‚îÇ   ‚îú‚îÄ‚îÄ 02-EJEMPLOS.md
‚îÇ   ‚îú‚îÄ‚îÄ 03-EJERCICIOS.md
‚îÇ   ‚îú‚îÄ‚îÄ 04-proyecto-practico/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/                 # 5 m√≥dulos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tests/               # 98 tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ejemplos/            # Ejemplos ejecutables
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ REVISION_PEDAGOGICA.md   # 9.2/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ tema-2-web-scraping/
‚îÇ   ‚îú‚îÄ‚îÄ 01-TEORIA.md
‚îÇ   ‚îú‚îÄ‚îÄ 02-EJEMPLOS.md
‚îÇ   ‚îú‚îÄ‚îÄ 03-EJERCICIOS.md
‚îÇ   ‚îú‚îÄ‚îÄ 04-proyecto-practico/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/                 # 5 m√≥dulos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tests/               # 71 tests
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ejemplos/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ REVISION_PEDAGOGICA.md   # 9.3/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îú‚îÄ‚îÄ tema-3-rate-limiting-caching/
‚îÇ   ‚îú‚îÄ‚îÄ 01-TEORIA.md
‚îÇ   ‚îú‚îÄ‚îÄ 02-EJEMPLOS.md
‚îÇ   ‚îú‚îÄ‚îÄ 03-EJERCICIOS.md
‚îÇ   ‚îú‚îÄ‚îÄ 04-proyecto-practico/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ src/                 # 4 m√≥dulos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tests/               # 55 tests (41 ejecutables)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ejemplos/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ REVISION_PEDAGOGICA.md   # 9.4/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îî‚îÄ‚îÄ README.md                    # Este archivo
```

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Extracci√≥n de Datos

- `requests` - Cliente HTTP para APIs REST
- `beautifulsoup4` - Parsing HTML (scraping est√°tico)
- `selenium` - Automatizaci√≥n de navegador (scraping din√°mico)
- `aiohttp` - Cliente HTTP as√≠ncrono
- `urllib.robotparser` - Validaci√≥n de robots.txt

### Almacenamiento

- `sqlite3` - Base de datos local
- `pandas` - Manipulaci√≥n de datos
- `shelve` - Cache persistente

### Testing y Calidad

- `pytest` - Framework de testing
- `pytest-cov` - Cobertura de c√≥digo
- `pytest-asyncio` - Tests as√≠ncronos
- `black` - Formateo de c√≥digo
- `flake8` - Linting

### Utilidades

- `python-dotenv` - Variables de entorno
- `typing` - Type hints

---

## üí° Buenas Pr√°cticas Aplicadas

### Seguridad

- ‚úÖ **HTTPS obligatorio** - Rechazar URLs HTTP
- ‚úÖ **Variables de entorno** - Nunca hardcodear API keys
- ‚úÖ **Validaciones** - Inputs, URLs, status codes
- ‚úÖ **Timeouts** - Evitar requests colgados

### √âtica

- ‚úÖ **Respetar robots.txt** - Siempre verificar permisos
- ‚úÖ **Rate limiting** - No sobrecargar servidores
- ‚úÖ **User-Agent** - Identificarse correctamente
- ‚úÖ **T√©rminos de servicio** - Cumplir legalmente

### C√≥digo

- ‚úÖ **TDD estricto** - Tests escritos primero
- ‚úÖ **Type hints** - 100% de funciones tipadas
- ‚úÖ **Docstrings** - Documentaci√≥n completa
- ‚úÖ **Funcional** - Sin efectos secundarios
- ‚úÖ **DRY** - No repetir c√≥digo
- ‚úÖ **KISS** - Soluciones simples

### Performance

- ‚úÖ **Caching** - Evitar requests redundantes
- ‚úÖ **Async** - Concurrencia para velocidad
- ‚úÖ **M√©tricas** - Medir throughput y latencia
- ‚úÖ **Optimizaci√≥n basada en datos** - ROI calculado

---

## üêõ Troubleshooting Com√∫n

### Problema: `ConnectionError` al consumir API

**Causa:** Timeout, URL incorrecta, servidor ca√≠do

**Soluci√≥n:**
```python
try:
    response = requests.get(url, timeout=10)
except requests.exceptions.ConnectionError:
    print("Error de conexi√≥n. Verificar URL y conectividad.")
```

---

### Problema: `aiohttp` no se instala en Windows

**Causa:** Requiere compilador C

**Soluci√≥n:**
1. Usar Docker (recomendado)
2. Instalar Microsoft Visual C++ Build Tools
3. Usar WSL2 o Linux/Mac

---

### Problema: Scraping bloqueado (403 Forbidden)

**Causa:** User-Agent no configurado, rate limit excedido

**Soluci√≥n:**
```python
headers = {"User-Agent": "MiScraper/1.0 (contacto@email.com)"}
time.sleep(2)  # Rate limiting
```

---

### Problema: Selenium no encuentra ChromeDriver

**Causa:** ChromeDriver no instalado o no en PATH

**Soluci√≥n:**
```bash
pip install selenium webdriver-manager
```

```python
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager

service = Service(ChromeDriverManager().install())
driver = webdriver.Chrome(service=service)
```

---

## üìö Recursos Adicionales

### Documentaci√≥n Oficial

- [Requests Documentation](https://docs.python-requests.org/)
- [BeautifulSoup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
- [Selenium Documentation](https://selenium-python.readthedocs.io/)
- [aiohttp Documentation](https://docs.aiohttp.org/)

### APIs P√∫blicas para Practicar

- [JSONPlaceholder](https://jsonplaceholder.typicode.com/) - API de prueba gratuita
- [OpenWeather API](https://openweathermap.org/api) - Datos meteorol√≥gicos
- [GitHub API](https://docs.github.com/en/rest) - Repos, issues, users
- [CoinGecko API](https://www.coingecko.com/en/api) - Criptomonedas

### Herramientas √ötiles

- [Postman](https://www.postman.com/) - Probar APIs manualmente
- [httpbin.org](https://httpbin.org/) - API de testing HTTP
- [Scrapy](https://scrapy.org/) - Framework avanzado de scraping (opcional)
- [Redis](https://redis.io/) - Cache distribuido (avanzado)

---

## üéØ Proyecto Final Integrador (Opcional)

**Desaf√≠o:** Pipeline completo de extracci√≥n de datos optimizado.

### Requisitos

1. **Fuentes de datos:**
   - Consumir 1 API REST (con autenticaci√≥n)
   - Scrapear 1 sitio web (con Selenium si es din√°mico)

2. **Procesamiento:**
   - Validar datos extra√≠dos
   - Transformar a formato estructurado
   - Almacenar en SQLite

3. **Optimizaci√≥n:**
   - Implementar cache con TTL
   - Rate limiting configurable
   - Async para requests paralelos
   - Monitoreo de m√©tricas

4. **Calidad:**
   - TDD con >80% cobertura
   - Type hints y docstrings completos
   - Logging estructurado
   - Manejo robusto de errores

5. **Documentaci√≥n:**
   - README con instrucciones claras
   - Dashboard de m√©tricas (antes/despu√©s)
   - An√°lisis de ROI

### Entrega Esperada

- C√≥digo fuente con tests
- README con m√©tricas comparativas
- CHANGELOG con decisiones t√©cnicas
- Demo ejecutable (video/screenshots)

---

## üèÜ Logros al Completar el M√≥dulo

Al finalizar este m√≥dulo, habr√°s:

‚úÖ **Extra√≠do datos de 20+ APIs y sitios web** diferentes
‚úÖ **Implementado 3 proyectos pr√°cticos** con TDD (210 tests)
‚úÖ **Optimizado scrapers** 10x-20x m√°s r√°pidos
‚úÖ **Dominado 10+ tecnolog√≠as** profesionales
‚úÖ **Escrito 12,000+ palabras** de documentaci√≥n t√©cnica
‚úÖ **Desarrollado 55+ funciones** robustas
‚úÖ **Aplicado √©tica y legalidad** en extracci√≥n de datos
‚úÖ **Calculado ROI** de optimizaciones con datos reales

**¬°Felicitaciones!** üéâ Est√°s preparado para roles de:
- Data Engineer (extracci√≥n de datos)
- Backend Developer (integraci√≥n de APIs)
- Web Scraping Specialist
- ETL Developer

---

## üîú Pr√≥ximos Pasos

Despu√©s de completar este m√≥dulo, contin√∫a con:

1. **M√≥dulo 5:** Bases de Datos Avanzadas (PostgreSQL, MongoDB)
2. **M√≥dulo 6:** Apache Airflow y Orquestaci√≥n
3. **M√≥dulo 7:** Cloud Computing (AWS/GCP)

---

**√öltima actualizaci√≥n:** 2025-10-25
**Autor:** DataHub Inc. - Equipo de Data Engineering
**Calificaci√≥n pedag√≥gica promedio:** 9.3/10 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê
**Estado:** ‚úÖ **COMPLETADO (100%)**
**Duraci√≥n real:** 3-4 semanas
**Nivel:** Intermedio
