# ğŸš€ Proyecto PrÃ¡ctico: Scraper Masivo Optimizado

**MÃ³dulo 4 - Tema 3:** Rate Limiting y Caching
**Enfoque:** Test-Driven Development (TDD)
**Cobertura objetivo:** >80%

---

## ğŸ¯ Objetivo del Proyecto

Implementar un **scraper masivo optimizado** capaz de descargar 500 URLs en menos de 30 segundos, integrando:

- âš¡ **Async requests** con `aiohttp` (concurrencia)
- ğŸ’¾ **Cache inteligente** (memoria y disco con `shelve`)
- ğŸš¦ **Rate limiting** (Token Bucket y Fixed Window)
- ğŸ“Š **MÃ©tricas en tiempo real** (throughput, latencia, cache hit rate)
- ğŸ”’ **Seguridad** (validaciones, timeouts, error handling)

---

## ğŸ¢ Contexto Empresarial

**DataHub Inc.** necesita actualizar su catÃ¡logo de 500 productos cada hora consultando una API externa. El scraper actual tarda **8+ minutos** y hace requests redundantes.

**Requisitos del negocio:**
- âœ… Reducir tiempo de ejecuciÃ³n a **<30 segundos**
- âœ… Cachear respuestas para evitar requests duplicados
- âœ… Respetar rate limit de la API (50 requests/segundo mÃ¡ximo)
- âœ… Monitorear mÃ©tricas para optimizaciÃ³n continua
- âœ… Manejo robusto de errores (timeouts, 5xx, etc.)

**ROI esperado:**
- â±ï¸ Tiempo: 8 min â†’ 25 seg (**19x mÃ¡s rÃ¡pido**)
- ğŸ’° Costo: $5/ejecuciÃ³n â†’ $0.50/ejecuciÃ³n (**90% de ahorro**)
- ğŸ“ˆ Throughput: 1 req/seg â†’ 20 req/seg (**20x mejora**)

---

## ğŸ“ Arquitectura del Proyecto

### Estructura de Archivos

```
04-proyecto-practico/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ rate_limiter.py          # Rate limiting (Token Bucket, Fixed Window)
â”‚   â”œâ”€â”€ cache_manager.py         # Cache (memoria, disco, TTL)
â”‚   â”œâ”€â”€ async_client.py          # Cliente HTTP asÃ­ncrono
â”‚   â””â”€â”€ metricas.py              # Monitoreo (throughput, latencia, hit rate)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_rate_limiter.py     # 15 tests
â”‚   â”œâ”€â”€ test_cache_manager.py    # 18 tests
â”‚   â”œâ”€â”€ test_async_client.py     # 12 tests
â”‚   â””â”€â”€ test_metricas.py         # 10 tests
â”‚
â”œâ”€â”€ ejemplos/
â”‚   â”œâ”€â”€ 01_rate_limiting_basico.py
â”‚   â”œâ”€â”€ 02_cache_con_ttl.py
â”‚   â”œâ”€â”€ 03_async_requests.py
â”‚   â””â”€â”€ 04_scraper_optimizado_completo.py
â”‚
â”œâ”€â”€ datos/                       # Cache persistente (*.db)
â”œâ”€â”€ logs/                        # Archivos de log
â”œâ”€â”€ README.md                    # Este archivo
â”œâ”€â”€ requirements.txt
â””â”€â”€ pytest.ini
```

---

## ğŸ§© MÃ³dulos a Implementar (TDD)

### 1. `rate_limiter.py` - Rate Limiting

**Funciones (4):**

```python
def crear_rate_limiter_fixed_window(max_requests: int, window_seconds: int) -> dict
def crear_rate_limiter_token_bucket(capacidad: int, tasa_reposicion: float) -> dict
def puede_hacer_request(rate_limiter: dict) -> bool
def esperar_disponibilidad(rate_limiter: dict) -> float
```

**Conceptos:**
- **Fixed Window:** LÃ­mite fijo de requests por ventana de tiempo
- **Token Bucket:** Permite bursts controlados, reposiciÃ³n gradual
- **CortesÃ­a:** No sobrecargar APIs de terceros

**Tests (15):**
- âœ… Crear rate limiter Fixed Window con parÃ¡metros vÃ¡lidos
- âœ… Validar lÃ­mite mÃ¡ximo de requests por ventana
- âœ… Reseteo automÃ¡tico al cambiar de ventana
- âœ… Crear Token Bucket con capacidad y tasa
- âœ… Consumir tokens gradualmente
- âœ… ReposiciÃ³n automÃ¡tica de tokens
- âœ… Permitir burst inicial (consumir todos los tokens)
- âœ… Bloqueo cuando no hay tokens disponibles
- âœ… Esperar hasta que haya tokens disponibles
- âœ… Calcular tiempo de espera correctamente
- âœ… ParÃ¡metros invÃ¡lidos lanzan ValueError
- âœ… Rate limiter persiste estado entre calls
- âœ… MÃºltiples rate limiters independientes
- âœ… Manejo de clock drift (cambios de hora)
- âœ… Performance con alta concurrencia

---

### 2. `cache_manager.py` - GestiÃ³n de Cache

**Funciones (5):**

```python
def crear_cache_memoria(max_size: int = 1000) -> dict
def crear_cache_disco(archivo: str, ttl: int = 3600) -> dict
def obtener_de_cache(cache: dict, clave: str) -> Optional[Any]
def guardar_en_cache(cache: dict, clave: str, valor: Any) -> None
def limpiar_cache_expirado(cache: dict) -> int
```

**Conceptos:**
- **Cache en memoria:** Ultra rÃ¡pido pero volÃ¡til (dict con LRU)
- **Cache en disco:** Persistente con `shelve`, sobrevive reinic

ios
- **TTL (Time To Live):** ExpiraciÃ³n automÃ¡tica de datos obsoletos
- **Cache Hit Rate:** MÃ©trica clave de eficiencia

**Tests (18):**
- âœ… Crear cache en memoria con tamaÃ±o mÃ¡ximo
- âœ… Guardar y recuperar valor simple
- âœ… Retornar None si clave no existe
- âœ… Sobrescribir valor existente
- âœ… LÃ­mite de tamaÃ±o (evitar memory leak)
- âœ… Crear cache en disco con archivo vÃ¡lido
- âœ… Cache en disco persiste entre ejecuciones
- âœ… TTL: dato vÃ¡lido retorna valor
- âœ… TTL: dato expirado retorna None
- âœ… Guardar con timestamp para TTL
- âœ… Limpiar cache expirado (retornar cantidad eliminada)
- âœ… Cache vacÃ­o no genera errores
- âœ… Valores complejos (dict, list) se almacenan correctamente
- âœ… Caracteres especiales en claves
- âœ… Claves muy largas (>1000 chars)
- âœ… Valores grandes (>1MB)
- âœ… Concurrencia: mÃºltiples escrituras simultÃ¡neas
- âœ… Manejo de errores de I/O (disco lleno)

---

### 3. `async_client.py` - Cliente HTTP AsÃ­ncrono

**Funciones (4):**

```python
async def crear_sesion_http(headers: Optional[dict] = None) -> aiohttp.ClientSession
async def obtener_url_async(session: aiohttp.ClientSession, url: str, timeout: int = 10) -> dict
async def obtener_urls_batch(urls: List[str], max_concurrente: int = 20, timeout: int = 10) -> List[dict]
async def cerrar_sesion(session: aiohttp.ClientSession) -> None
```

**Conceptos:**
- **Async/Await:** Concurrencia sin multithreading
- **aiohttp:** LibrerÃ­a HTTP asÃ­ncrona
- **Semaphore:** Limitar requests concurrentes
- **Context managers:** GestiÃ³n automÃ¡tica de recursos

**Tests (12):**
- âœ… Crear sesiÃ³n HTTP con headers por defecto
- âœ… Crear sesiÃ³n con headers personalizados
- âœ… GET request async exitoso (200)
- âœ… Retornar JSON parseado automÃ¡ticamente
- âœ… Timeout si request tarda >N segundos
- âœ… Manejo de error 404
- âœ… Manejo de error 500
- âœ… Obtener batch de URLs en paralelo
- âœ… Limitar concurrencia con semÃ¡foro
- âœ… Batch con URLs mixtas (algunas fallan)
- âœ… Cerrar sesiÃ³n correctamente
- âœ… Performance: 50 URLs en <5 segundos

---

### 4. `metricas.py` - Monitoreo y MÃ©tricas

**Funciones (4):**

```python
def crear_monitor_metricas() -> dict
def registrar_request(monitor: dict, fue_cache_hit: bool, tiempo_ms: float) -> None
def obtener_reporte_metricas(monitor: dict) -> str
def exportar_metricas_json(monitor: dict, archivo: str) -> None
```

**Conceptos:**
- **Throughput:** Requests por segundo
- **Latencia:** Tiempo promedio por request
- **Cache Hit Rate:** % de requests servidos desde cache
- **Dashboard:** VisualizaciÃ³n de mÃ©tricas en tiempo real

**Tests (10):**
- âœ… Crear monitor inicializado en cero
- âœ… Registrar cache hit incrementa contador
- âœ… Registrar cache miss incrementa contador
- âœ… Calcular cache hit rate correctamente
- âœ… Calcular throughput (requests/segundo)
- âœ… Calcular latencia promedio
- âœ… Reporte incluye todas las mÃ©tricas
- âœ… Reporte formateado legible (ASCII art)
- âœ… Exportar mÃ©tricas a JSON vÃ¡lido
- âœ… MÃ©tricas con alta carga (1000+ requests)

---

## ğŸ“Š Resumen de Tests

| MÃ³dulo             | Funciones | Tests  | Objetivo Cobertura |
| ------------------ | --------- | ------ | ------------------ |
| `rate_limiter.py`  | 4         | 15     | >85%               |
| `cache_manager.py` | 5         | 18     | >90%               |
| `async_client.py`  | 4         | 12     | >80%               |
| `metricas.py`      | 4         | 10     | >85%               |
| **TOTAL**          | **17**    | **55** | **>85%**           |

---

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos

- Python 3.8+
- pip

### Instalar Dependencias

```bash
cd modulo-04-apis-scraping/tema-3-rate-limiting-caching/04-proyecto-practico
pip install -r requirements.txt
```

### Dependencias Principales

```
aiohttp==3.9.1        # Cliente HTTP asÃ­ncrono
pytest==7.4.3         # Testing framework
pytest-cov==4.1.0     # Cobertura de tests
pytest-asyncio==0.21.1 # Tests asÃ­ncronos
```

---

## âœ… Ejecutar Tests (TDD)

### Todos los Tests

```bash
pytest tests/ -v
```

### Con Cobertura

```bash
pytest tests/ --cov=src --cov-report=html --cov-report=term-missing
```

### Output Esperado

```
tests/test_rate_limiter.py::test_crear_fixed_window âœ“
tests/test_rate_limiter.py::test_token_bucket_burst âœ“
...
tests/test_metricas.py::test_exportar_json âœ“

======================== 55 passed in 3.2s ========================

---------- coverage: platform win32, python 3.11.5 -----------
Name                    Stmts   Miss  Cover   Missing
-----------------------------------------------------
src/rate_limiter.py        45      2    96%   78-79
src/cache_manager.py       58      3    95%   102, 156
src/async_client.py        38      4    89%   67-70
src/metricas.py            32      1    97%   89
-----------------------------------------------------
TOTAL                     173      10    94%
```

---

## ğŸš€ Uso del Proyecto

### Ejemplo BÃ¡sico: Rate Limiting

```python
from src.rate_limiter import crear_rate_limiter_token_bucket, puede_hacer_request, esperar_disponibilidad

# Crear rate limiter: 20 requests/segundo
limiter = crear_rate_limiter_token_bucket(capacidad=20, tasa_reposicion=20)

for i in range(100):
    if puede_hacer_request(limiter):
        print(f"Request {i+1} OK")
        # hacer_request_http()
    else:
        tiempo_espera = esperar_disponibilidad(limiter)
        print(f"Esperando {tiempo_espera:.2f}s...")
```

### Ejemplo Intermedio: Cache con TTL

```python
from src.cache_manager import crear_cache_disco, obtener_de_cache, guardar_en_cache

# Cache persistente con TTL de 1 hora
cache = crear_cache_disco(archivo="datos/cache_productos.db", ttl=3600)

# Intentar obtener de cache
url = "https://api.example.com/productos/123"
datos = obtener_de_cache(cache, url)

if datos is None:
    # Cache MISS: hacer request real
    datos = requests.get(url).json()
    guardar_en_cache(cache, url, datos)
    print("ğŸŒ Request real")
else:
    print("âœ… Cache HIT")
```

### Ejemplo Avanzado: Scraper Optimizado Completo

```python
import asyncio
from src.async_client import obtener_urls_batch
from src.cache_manager import crear_cache_disco, obtener_de_cache, guardar_en_cache
from src.rate_limiter import crear_rate_limiter_token_bucket
from src.metricas import crear_monitor_metricas, registrar_request, obtener_reporte_metricas

async def scraper_optimizado(urls: List[str]):
    # ConfiguraciÃ³n
    cache = crear_cache_disco("datos/cache.db", ttl=3600)
    limiter = crear_rate_limiter_token_bucket(capacidad=50, tasa_reposicion=50)
    monitor = crear_monitor_metricas()

    # Separar URLs en cache vs no-cache
    urls_no_cache = []
    for url in urls:
        datos = obtener_de_cache(cache, url)
        if datos is None:
            urls_no_cache.append(url)
        else:
            registrar_request(monitor, fue_cache_hit=True, tiempo_ms=0.1)

    # Async batch para URLs no cacheadas
    if urls_no_cache:
        resultados = await obtener_urls_batch(urls_no_cache, max_concurrente=20)

        for url, datos in zip(urls_no_cache, resultados):
            guardar_en_cache(cache, url, datos)
            registrar_request(monitor, fue_cache_hit=False, tiempo_ms=500)

    # Mostrar mÃ©tricas
    print(obtener_reporte_metricas(monitor))

# Ejecutar
urls = [f"https://api.example.com/productos/{i}" for i in range(500)]
asyncio.run(scraper_optimizado(urls))
```

**Output esperado:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸ“Š MÃ‰TRICAS DEL SCRAPER               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ â±ï¸  Tiempo total:        24.3s                 â•‘
â•‘ ğŸ“ Total requests:       500                   â•‘
â•‘ âš¡ Throughput:           20.6 req/seg          â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ âœ… Cache HITS:           350 (70.0%)           â•‘
â•‘ ğŸŒ Cache MISSES:         150 (30.0%)           â•‘
â•‘ ğŸ’° Requests ahorrados:   350                   â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“Š Latencia promedio:    48ms                  â•‘
â•‘ ğŸ’µ Costo estimado:       $0.15 (vs $0.50)     â•‘
â•‘ ğŸ’° Ahorro:               70% (cache)           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“ˆ Ejemplos Incluidos

### `ejemplos/01_rate_limiting_basico.py`
Demuestra Fixed Window y Token Bucket con comparaciÃ³n de rendimiento.

### `ejemplos/02_cache_con_ttl.py`
Implementa cache con expiraciÃ³n automÃ¡tica y calcula ROI.

### `ejemplos/03_async_requests.py`
Compara scraping sÃ­ncrono vs asÃ­ncrono (mejora de 20x).

### `ejemplos/04_scraper_optimizado_completo.py`
IntegraciÃ³n completa: async + cache + rate limiting + mÃ©tricas.

---

## ğŸ“ Conceptos Aprendidos

Al completar este proyecto, habrÃ¡s dominado:

### Nivel BÃ¡sico
- âœ… Rate limiting con `time.sleep()`
- âœ… Cache en memoria con `dict`
- âœ… Medir tiempos de ejecuciÃ³n
- âœ… Calcular throughput

### Nivel Intermedio
- âœ… Token Bucket rate limiting
- âœ… Cache persistente con `shelve`
- âœ… TTL (Time To Live) y expiraciÃ³n
- âœ… Async requests con `aiohttp`
- âœ… Semaphore para limitar concurrencia

### Nivel Avanzado
- âœ… IntegraciÃ³n completa async + cache + rate limiting
- âœ… Monitoreo de mÃ©tricas en tiempo real
- âœ… OptimizaciÃ³n de pipelines (10x mejora)
- âœ… Dashboard de mÃ©tricas
- âœ… CÃ¡lculo de ROI (Return on Investment)

---

## ğŸ› Troubleshooting

### Error: `ModuleNotFoundError: No module named 'aiohttp'`

```bash
pip install aiohttp
```

### Error: `RuntimeError: Event loop is closed`

AsegÃºrate de usar `asyncio.run()` para ejecutar funciones async:

```python
# âŒ MAL
loop = asyncio.get_event_loop()
loop.run_until_complete(mi_funcion())

# âœ… BIEN
asyncio.run(mi_funcion())
```

### Tests fallan con `TimeoutError`

Aumenta el timeout en `pytest.ini`:

```ini
[pytest]
asyncio_mode = auto
timeout = 30
```

### Cache crece sin lÃ­mite (memory leak)

Usa `crear_cache_memoria(max_size=1000)` para limitar tamaÃ±o.

---

## ğŸ“Š MÃ©tricas del Proyecto

| MÃ©trica                    | Valor | Objetivo | Estado |
| -------------------------- | ----- | -------- | ------ |
| **Tests totales**          | 55    | 50-60    | âœ…      |
| **Cobertura**              | 94%   | >80%     | âœ…      |
| **Funciones**              | 17    | 15-20    | âœ…      |
| **LÃ­neas de cÃ³digo**       | ~600  | 500-800  | âœ…      |
| **Ejemplos**               | 4     | 3-4      | âœ…      |
| **Tiempo ejecuciÃ³n tests** | 3.2s  | <10s     | âœ…      |

---

## ğŸš€ PrÃ³ximos Pasos

DespuÃ©s de dominar este proyecto:

1. âœ… **Integrar con Tema 2:** Combinar scraping + optimizaciÃ³n
2. âœ… **Redis:** Reemplazar `shelve` con Redis para cache distribuido
3. âœ… **Monitoring:** Integrar con Grafana/Prometheus
4. âœ… **Multiprocessing:** Combinar async con procesos paralelos
5. âœ… **Cloud:** Desplegar en AWS Lambda con API Gateway

---

## ğŸ“š Recursos Adicionales

- [aiohttp Documentation](https://docs.aiohttp.org/)
- [asyncio Python Docs](https://docs.python.org/3/library/asyncio.html)
- [Rate Limiting Algorithms](https://en.wikipedia.org/wiki/Rate_limiting)
- [Cache Strategies](https://www.cloudflare.com/learning/cdn/caching-strategies/)
- [Token Bucket Algorithm](https://en.wikipedia.org/wiki/Token_bucket)

---

**Ãšltima actualizaciÃ³n:** 2025-10-24
**Autor:** DataHub Inc. - Equipo de Data Engineering
**Licencia:** MIT
**Nivel:** Intermedio-Avanzado
---

## ğŸ§­ NavegaciÃ³n

â¬…ï¸ **Anterior**: [03 Ejercicios](../03-EJERCICIOS.md) | â¡ï¸ **Siguiente**: [MÃ³dulo 5: Bases de Datos Avanzadas: PostgreSQL Avanzado](../../../modulo-05-bases-datos-avanzadas/tema-1-postgresql-avanzado/01-TEORIA.md)
